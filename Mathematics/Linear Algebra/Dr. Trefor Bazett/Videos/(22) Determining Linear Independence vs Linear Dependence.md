---
Source:
  - https://youtube.com/watch?v=OFALIHBY5Bw
Reviewed: false
---
- ![[Screenshot 2023-07-16 at 10.48.46 PM.png|300]]
	- Demonstrating linear dependence/Independence
	- A linear combination of vectors are interpreted as a matrix vector product
	- In this scenario, the coefficients are going to become the vector in our matrix are $a_1, a_2, a_3$
		- Columns of the matrix are called $\vec{v_1}, \vec{v_2}, \vec{v_3}$
	- We see that we have a homogeneous system of linear equations
	- Since the augmented matrix has a leading 1 in every single row and column. In other words, it has a unique solution 
	- Since all 3 scalars are equal to 0, it's linearly independent
	- If it's homogeneous and unique, the only possibility is 0 because the 0 solution is always the solution to a homogeneous system
	- If we are given any list of vectors, you put them into matrix form, you put it into its row echelon form, you solve that system, and that will tell you if it's linearly independent (and there is the one trivial solution) or linearly dependent (when you can find families of non-trivial solutions)