---
Source:
  - https://www.youtube.com/watch?v=szw54UbPJRE
---
- ![[Screenshot 2024-11-28 at 3.15.56 AM.png]]
	- Introduction
		- hello everybody, I am back for another video and uh yeah this one is kind of bittersweet in the sense that i kind of initially made a list out of all the problems that i wanted to eventually cover and i think this may be the last one. Let's talk about distributed locking.
	- Distributed Locking (Functional Requirements)
		- Description
			- Build a distributed lock to support cases like exclusive file modification or de-duplication of compute workloads
		- Apologies everyone for the sudden change in outfit. I actually recorded a functional requirements section, however the file seems to have gotten corrupted. So now it seems you're seeing me in my going outfit before i get zero play. Anyways let's go ahead and get into these requirements. Basically we want to be building ourselves a distributed lock where a distributed lock is more or less the same thing as a typical lock on a single computer system. The main difference being that multiple different nodes in a cluster can be accessing it and locking or releasing that lock. Why is this useful? Well there are a couple reasons that we tend to use them for. The first is kind of like a file modification situation. So imagine you know, we have like S3 and all these different nodes in a cluster want to be able to edit some files in S3 and they want to be able to edit the same files. If two of them are editing one file at the same time, that's going to be a problem. That file is going to get corrupted. So what they'll do instead is actually go ahead and grab a distributed lock to basically say, hey, I'm going to be editing the file now, and that way no other one of the nodes in the cluster can do the same. Another example of using a distributed lock would be, let's say there are a bunch of resources. So we've talked about this in the past with something like our Netflix or YouTube video onboarding where all these nodes in a cluster are pulling elements from a queue and going ahead and processing them and then uploading them to S3. Well, we don't want to basically be doing double the amount of work necessary, so what you can do is, actually every single time that you want to basically process a chunk of video footage, you grab a lock corresponding to that chunk and then that way, every other node in the cluster will know that they're not able to go ahead and grab that distributed lock and as a result, no double work will be done. You won't be wasting any compute. Anyways, those are just two examples of basically when distributed locking is important but nonetheless, let's go ahead and get into some capacity estimates. 
	- Distributed Locking (Capacity Estimates)
		- Description
			- 1000 machines trying to grab the lock at once
		- All right in terms of the capacity estimations for our service, I'm not going to give any specific you know disk or memory requirements because that's not really too important for something like a distributed lock, but rather what i will give a requirement for is the number of machines that actually may be trying to grab the lock and i'll explain why that is in a little bit but let's imagine that we can have up to a thousand nodes in our cluster trying to grab this lock at once. And you know basically that could even be more than that. Think around a thousand at one time.
	- Distributed Locking (API Design)
		- Description
			- Grab_lock()
			- Release_lock(fencing_token)
			- Do_external_operation(fencing_token)
		- For our api design, I can think of three operations. The first is going to be to go ahead and grab the lock and that's not going to take in any parameters, it's pretty simple. The next one is going to be to release a lock and we'll touch upon this more later, but we may have to use something like a fencing token there to ensure that it's the right machine actually doing the releasing, and then finally, we also want to be able to do the operation on you know probably some sort of third-party system like you know for example S3 if we're writing a file, and to do so, we may have to pass in a fencing token as well to ensure the validity of that operation and i'll touch upon that more in a little bit.
	- Distributed Locking (Database Schema)
		- As far as our current database scheme is going to go, uh not really too much to keep track of. Just mainly who's holding the lock. We may have to add stuff to that in the future and we'll talk about that later in the video but at least at a bare bones minimum, we just need to know who has the lock so other computers can basically say okay, am i holding the lock or am i not.
- ![[Screenshot 2024-11-28 at 3.32.03 AM.png]]
	- Distributed Locking (Architectural Overview)
		- Okay so let's actually get into the design of this thing. I will say i actually watched a couple of videos on distributed locking before making this one myself and they were pretty alarming how many flaws there were in them. So i'm going to make sure to point those out when i kind of go through this video because you know i was looking at videos with hundreds of thousands of views and they had pretty blatant flaws so we'll talk about that in a bit but for now let's just get started by framing the requirements again. So basically, we need to be able to ensure that we have something that basically allows for exclusivity, right. Only one machine can be holding this lock at a time and the others are going to have to go kick rocks. Basically what that means is that in the face of fault tolerance, whether it is you know the locking server that's down or the machine holding the lock that's down, things are still going to have to keep working. So let's start with what happens if the current lock holder is down. Well, let's imagine you know i'm a computer and i'm holding the lock and then all of a sudden I die, right. So now i can't ever release the lock. How's our system going to progress. How's anyone else ever going to be able to grab it. Well basically what we can do is we have a couple of options. First of all, we can imagine that let's say we have some sort of lock server right that's keeping track of everything, the lock server can basically put a time to live on the lock and as a result, you know, say after five minutes, you go ahead and release it automatically. Obviously it's going to depend on the type of work and you know the expected amount of time that you think it's going to take for the process to end to configure that TTL but that's one option. Another is to periodically have your machine basically send a heartbeat over to the locking service and if the locking service stops receiving those heartbeats, then we can basically assume that our machine is dead and release the lock. Now this should be ringing alarm bells in your head because you should be saying to yourself, well i can't know for certain that the machine that's currently holding the lock is actually done with it. It may still be doing work and that's correct, it may still be. It may be having something like a process pause and garbage collection. It may just be taking longer than normal for whatever reason or maybe there's a network delay. 
		- (1) But the point is, this machine might still be thinking it's holding the lock because it never actually called release on its own. So then for example, it might go right over to S3, try and edit a file and then boom, there's corruption because someone else has already grabbed the lock and now they're editing at the same time. 
		- So what is it that we can actually do to get over this discrepancy. Well i've mentioned this in the past in some of my concepts videos but this is where something known as fencing tokens comes in. 
		- (2) To summarize it, basically fencing tokens are just some sort of monotonically increasing sequence number that you know S3 is going to keep track of all the fencing tokens it's seen when machines edit files on it, and so let's say you know i had a process that had the lock. Um, you know it got TTL'd which means that basically the lock server freed up the lock, another process grabbed it. So let's say the original fencing token was 34 for the one that expired and then the new machine that grabbed the lock after it expired got 35. And the new machine starts editing files on S3. Well now what's going to happen is S3 is going to say, okay, I've seen the fencing token 35 so when basically the delayed network packets from the machine with number 34 get to S3, S3 can go ahead and disregard those saying, oh wait, that's an old fencing token, I don't want to worry about those. This is invalid and it's going to mess things up. 
		- So that's how we would go ahead and use fencing tokens but the question is now, how do we actually assign them. It's very important that they're like gradually increasing and so that way, you know a service can keep track of what's the last one I've seen, and to only accept greater numbers than that. Well generally speaking, you definitely don't want to be using something like timestamps and this is where i've seen videos talk about this and i was just in shock that they would actually suggest this because timestamps in a distributed system are unreliable. Sure you can have that one centralized lock server assign timestamps but we can't just have one centralized lock server because the entire point is we're building a fault tolerant system. So if we're only relying on one single server to be in charge of all of our distributed locking, keep track of the state of who has the lock and who doesn't, well what happens if that machine goes down. Then another one has to take over and because these timestamps aren't reliable, the other one might start giving out timestamps that were actually lower than the timestamps given out by the first lock server even though you know we know that this is actually after that and so then we're going to have another issue with fencing tokens. So timestamps are not actually going to be feasible. What's another option to potentially assign fencing tokens. Well, what if we use some sort of like DynamoDB type system, right? With quorum reads and writes. So just to remind everyone, a quorum is when you have an odd number of servers or database servers, let's say three, and basically to achieve a quorum, you have to write to $\frac{n+1}{2}$ where n is the number of servers you have and you also have to be reading from $\frac {n+1}{2}$ where those are the number of servers you have and what you're writing and reading is you know, you're basically writing and saying, hey i'm grabbing the lock and then those servers are going to assign a version number to that which is effectively going to be your fencing token. Now the reason that something like this works is because in quorums in particular, you know that uh by performing a quorum write and a quorum read, they're always you know imagine we have three nodes. I'm going to write to three and then another one is going to read so as long as kind of two out of those three nodes are written to and two out of those three nodes are read from, you know that the most up-to-date value is always going to be on at least one of the nodes. So you can kind of ensure strong consistency but the truth of the matter is that you really can't because what if someone tries to grab a lock and they're only able to write to one of the three nodes and then another machine is basically going to read from the three nodes and say, okay, well is the lock available or is it not and then they read from two of the three nodes and they actually, one of the two nodes that they read from is the one where the write from before was successfully written to. So now one out of the two nodes is going to say the lock is already grabbed. So even though no one has actually successfully grabbed the lock, it's going to look to this other server like the lock is grabbed and now the other server is not going to be able to progress so basically quorums are not the move here. Ultimately what we're really going to need to do is use consensus and i've spoken about this plenty in the past. I have a dedicated video to it and i highly recommend that you watch that. It's on raft. However, you know for the sake of kind of getting everything in here in one video, I'm basically going to do a quick summary of what consensus is and why it's so useful for distributed locking. So basically what Raft does or Raft which is this you know fault tolerant highly available consensus algorithm is it allows us to build a distributed log and think of the distributed log as just basically a list of writes where each write is just basically an event and then on top of that log, you're building a key value store and basically you know the events of the log could be you know put this key here, delete this key, get the value for this key or something along those lines but the point is you're just building this distributed log and this log is going to be replicated in a fault tolerant manner over the other raft systems. So basically here's how it works. Raft is always going to probably use an odd number of nodes and then one of those nodes is going to be designated the leader. Every single time a write is proposed, it is first sent to the leader. The leader is then going to propose it to all of the follower nodes. As long as a majority of the follower nodes are able to basically say, he, I'm cool with this write, i can accept this, they're going to send that back to the leader and if the leader sees that the majority of the followers have accepted that, it is going to go ahead and commit that write locally and then tell all the follower nodes to commit that write. This way, it's never possible that you can have any sort of contradiction within the Raft system because we know that for every single write in that distributed log, a majority of nodes has agreed upon it and this is a little bit different than quorums where uh you know even though you're getting a majority, there's no like commit phase like there is in raft and because of that commit phase, we know that there can never be any sort of conflicts. Only committed writes are valid and that works very nicely. Another important element of Raft is that there is automatic leader election if that leader were to go down and this is kind of what differentiates it from something like single leader replication. Basically the way this is done is the machines send heartbeats to one another and if one of the machines determines, hey, I think the leader is down right now, it's going to start a new leader election with something known as a new epoch number and that epoch number is going to be one higher than what it was before and this kind of acts like a fencing number for epoch elections but basically if one of the raft followers that is completely up to date with what the leader was determines that there needs to be a new election, then it is basically going to ask all of the other followers to vote on if it's valid and if it gets a majority of votes saying yes from the follower nodes, then that election is going to be complete and then the system can move on with the new follower being elected as the leader. Okay, so now we've established this system basically where we have all these nodes and they are able to have a fault tolerant consensus between them and what that means is that if one node can basically convince raft that it is holding the lock, every single other node that reads from that raft leader is going to agree, okay, this first node is currently holding the lock. So what can we do to kind of speed this process up and make sure that it's really scalable because there are two big things. The first is pretty simple. All of our raft nodes should probably be running using memory as opposed to disk. Raft is inherently fault tolerant so it's okay if we do use memory however there may be more individual machine failures and lost data as a result but it should be able to recover. Additionally and more importantly we have to consider the thundering herd problem. So let's imagine right now that our current system is you know one machine says i'm grabbing the lock and then when it releases it, the thousand other machines that wanted to go ahead and grab the lock are all going to make network calls to the raft leader and only one of them is going to win. This is very very bad because it's known as the thundering herd problem. It means that every single time one resource is released, you have a ton of other machines trying to basically put a ton of strain on your single raft instance and that's really bad for it. It's going to slow things down a lot. So how can we basically go ahead and approve this? Basically the idea is as follows and if you've ever kind of heard of something like a queue lock on just a normal operating system, this is pretty similar to that. As opposed to just telling a machine that wants to grab the lock when the lock is not available no and letting it you know just go away and try again later, what you can actually do on Raft is effectively keep a linked list of all the requests for the lock so that way, if the machine currently holding the lock is basically going to release it, you can promote the next person in the linked list to the head node and then use something like some sort of real-time event such as a server sent event or a long polling to alert the corresponding node that they are now holding the lock and additionally, you can even assign them a new fencing token that is one higher than the previous one, so that works really nicely. Additionally, if there are basically machines that want the lock that are in the linked list but for some reason their heartbeat with the consensus service times out, you can just go ahead and remove them from the linked list, it's no big deal and so by doing this, we can avoid the thundering herd problem because every single time that lock is given up, we only are notifying one single machine that it's their turn to connect as opposed to basically telling you know a thousand machines hey come back here and give it another try because most of them are going to fail and that's a lot of wasted network latency. So yeah i hope that makes sense but to make sure to visualize everything properly and make sure you guys get it, let's go ahead and take a look at a diagram.
- ![[Screenshot 2024-11-28 at 3.32.39 AM.png]]
	- Diagram
		- All right this diagram is pretty small but let's get into it anyway. So imagine we have two clients both trying to grab a lock and let's imagine that client one is going to win. So client one is going to be reaching out to our raft server which as you can see in those raft instances, we have basically the distributed log on the bottom and that's going to act as kind of like a write ahead log for the key value store on top where the value is just going to be a linked list of all the machines trying to go ahead and grab that lock. So client one is first going to write grab and as a result, it's going to go to the head of the linked list. Afterwards, client 2 is going to try and grab the lock as well. However, since client 1 already has it and we can clearly see that by virtue of it being at the head of the linked list, as opposed to just telling client two to go away and then having it try again at some random arbitrary time using an exponential back off, what we're going to do is actually append client two to that queue or to that linked list so that when client one goes ahead and releases the lock, client two can be notified using something like a server sent event. As you can see, while client one actually is possessing the lock, it can go ahead and speak to S3 and gain exclusive access to whatever file it is that it wants to be writing to. It can do this with something like a fencing token. So let's imagine that you know since client one is the first one to ever grab the lock, it gets a fencing token of one. Similarly, once client two goes and gets the lock next, it'll have a fencing token of two. If for some reason client one was never able to write to S3 in time and were to time out, then client two would get its fencing token of two, start writing to s3, and then client one's request would finally get over the network to S3 with a fencing token of one and S3 would politely tell it to go away.
		- All righty fellas i hope you enjoyed this one. We went back to our roots on this channel a little bit with the real uh in-depth distributed systems on this which personally makes me happy because i think it uh involves a little bit more thinking than some of these systems design questions where it's just kind of like throw in a message queue, see what happens. But uh yeah i enjoyed it and I've had a ton of fun making videos on this channel but i think it is time for a change and i'll explain why more in my next video but i still plan on posting consistently. Some of it may not be as educational and i still do plan on doing educational stuff in the future so again if you have any more topics that you'd like me to cover especially as it pertains to system design and distributed systems, please do tell me. I feel like i've covered like a lot of it within like current level research at this point so, you know, I feel good about what i've given to the community. 