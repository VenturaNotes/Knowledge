---
Source:
  - https://www.youtube.com/watch?v=e2iK8pUP9Vs
---
- ![[Screenshot 2024-11-28 at 6.10.01 AM.png]]
	- Introduction
		- As a result, we've resulted in what i can only call a low effort message broker design video which i am going to get into imminently. A little redundant to the channel and i'm going to kind of gloss over some of the stuff that i covered in my message broker concept video so i would recommend just going and watching that if uh you know you're more curious about like kind of the conceptual part of this and less of the distributed systems design but yeah let's just go ahead and get into it.
	- Message Broker (Functional Requirements)
		- Description
			- Build a distributed, reliable, fault tolerant message broker
		- Okay so as per usual, we'd be starting off with functional requirements. The functional requirements for this video are pretty simple. Someone's just going to say to you, build me a message broker, and you're going to say fine i'll do it. So you know the point of the message broker generally speaking is to go ahead and decouple the publishing and consumption of messages because sometimes the producers messages and the consumers may be from different parties, they don't want to directly connect, and as a result it's good to have some kind of intermediary buffer servers which can go ahead and hold kind of that communication between them so the consumers can eventually pick that up and do work later. It doesn't have to be done instantly by establishing an actual connection between those two types of servers. 
	- Message Broker (Capacity Estimates)
		- Description
			- Millions of messages per minute
			- Hundreds of bytes per message
		- Okay next up, we have our capacity estimates. I'm not going to give anything too concrete here because the entire point of building a message broker is so that it can actually scale out to pretty much anything. You know you can just go ahead and add more of them and that should allow you to be able to scale to pretty much any level of usage, but let's imagine that we are eventually going to have to be supporting millions of messages sent per minute or something along those lines where each message is going to be a couple hundred bytes in size. You know nothing like too huge of static files or anything, but you know still big enough that it's not just like a single character in an array 
	- Message Broker (API Design)
		- Description
			- PublishMessage(userId, msg)
			- ConsumeMessage(acknowledgement?)
		- Okay, for our api design i think we're just going to have two main endpoints. The first one should be pretty obviously to actually go ahead and publish a message. That should take in something like the user ID. The reasoning being to just ensure that you actually can publish the message as well as you know rate limiting if we're doing that and then additionally the actual contents of the message. You could add things like topics but i'm just going to imagine that there's something actually contained in the contents of the message that's going to allow you to do some sort of partitioning of the messages or you know send them to a certain topic or something along those lines. The second endpoint that we're going to have is to actually consume a message and i'm going to add an optional parameter here as an acknowledgement where basically what that acknowledgement will allow you to do is say, I'm ready to consume a message and here's the one that i just finished consuming so now give me a new one please.
	- Message Broker (Database Schema)
		- Okay finally, the last part of this puzzle before we actually get into the design itself is uh basically what database schema we need. Well, in this case we're building a message broker which itself is kind of a database but the question is, are we going to be using any internal databases. I'm going to argue that we are writing things to disk but i wouldn't really call that a typical database engine because truthfully a database engine is going to allow you to do a lot more things than we're really going to need. In a message broker, typically you're only writing and deleting messages and databases allow messages to actually be mutable. You know you can write a row and then you can change it and the truth of the matter is that's functionality that we don't really need in our message broker and as a result, it's better to kind of you know use different implementations that are going to allow us to be a little bit more efficient without being as complex as a database engine and so we'll get into that in a little bit.
	- Message Broker (Architectural Overview)
		- Okay, so let's start talking about this design. I want to preface this with if you're just watching this video and haven't yet watched my dedicated stream processing concepts video, I really do highly recommend that. I'm gonna go over all that stuff at least you know the most important parts of it in this but i go into more detail in that video, and so whatever, let's get started, I hope you watched it, but if you haven't, who needs to listen to it my advice anyways. It's not that important. Okay, so basically there are two different types of message brokers mainly and we're going to talk about how we might build both of them but they have a lot of parts in common and then the main difference is how they actually store those messages. So the first one is going to be an in-memory message broker. So an in-memory message broker (Examples: SQS, Rabbit MQ) basically does the following. It takes in all the messages that you're receiving and as opposed to putting them on disk somewhere or something durable, it's actually going to keep them in RAM in the server that's receiving those messages. So why would you go ahead and do that? Well they're actually really useful when you basically don't really care about the order that these messages are being sent in and you don't really care which consumer is receiving them (multiple consumers per partition, message sent to any available consumer) but what's more important is the fact that they're just being processed as quickly as possible. By keeping all of these messages in memory, we can read them and write them much faster and as a result, we should expect to have better performance. At the same time, this is really good for you know certain use cases that we've spoken about in the past. In the Netflix and YouTube video for example we, didn't really care what consumer it was received a message saying you know encode this video a certain way. We just cared that it got done because the status update was going to some external database. On the other hand, there are certain times where it's very important which consumer does actually get that message and it's important that all the messages in the same partition actually go to a given consumer. It may also sometimes be important that messages are durable because like i mentioned here, all of these messages are going to be in memory. If that server were to crash, we could potentially lose those messages and that would be very bad. In theory yeah we could avoid this by doing something like replication but even if it's um asynchronous replication, there's no guarantee that that message is going to be replicated before the server goes down and if it's synchronous replication, then we're going to be seriously detracting from our performance and possibly even you know dealing with cascading failures if the connection between you know the queue and its replica were to go down because then you couldn't do a synchronous replication and you couldn't accept the actual writes. Another option would just be to go ahead and locally write those messages to disk on something like a write ahead log but at that point, we would just be turning ourselves into the second type of queue which i'm about to talk about which is called a log based message broker. In contrast to the memory message broker, a log-based message broker takes advantage of the fact that sequential writes to a disk are very fast. I've covered this in many of my videos but the general gist is because mechanical disks have basically a spinning arm, when it's the case that you are you know doing writes that are very close to one another, the mechanical disk doesn't have to do a lot of spinning and it can be relatively fast. Even though this is the case, it is still generally slower than memory though. So again, we're taking advantage of those relatively fast sequential rights and every single incoming message that is going to be produced is going to then be written in this log and this log is going to be an append only log. We're never even going to delete messages from it. Unlike that, in the in memory message broker, the second that a message is acknowledged as handled by the consumer, that message is actually going to be deleted from the in-memory queue. So you know that's an important difference to keep in mind. Not only are we actually making these messages more durable by putting them in disk, we're making them more durable by literally not deleting them until you know perhaps down the line we need more space and then we'll have to transport some of them to you know s3 or something, but we'll talk about that at a different time. So anyways, the point now is that for every single partition of this log-based message broker, we have all of these messages that are written down on disk and so for the consumer that's actually going to be pulling from this queue, what that log based message broker does is it keeps track of the last message that that consumer has read and this way you know if the consumer were to go down or something, it can make sure that the log base message broker knows exactly what the next message is that it needs to be read and that way can ensure that every message is going to be delivered at least once. This is also really useful for replaying messages, you know. Let's say that we add a new type of consumer which cares about all those messages that were sent to our log-based queue and what we can basically then do is since we still have access to all those messages, we can go ahead and replay them for our consumer. So this is a pretty high level overview of how something like a log based message broker works and again the reason this is so useful is twofold. One is that those messages are durable mainly meaning we can replay them later and two, which is that um because we're basically waiting on an acknowledgement from the log based message broker before we send another element of the queue to the consumer for it, it means that all the messages from one partition are actually going to be going to the same consumer and as a result of that, we can take advantage of having stateful consumers. This means that you can do things like, you know, counting certain aspects of the messages that have come to the actual consumer, for example. You know we want to count all events within a certain partition and you know sum up the numbers in the messages. We can do that because all of these messages are going to the same consumer. You know that's a really nice advantage of the log based message broker. The biggest disadvantage compared to the in-memory one is basically that by using disk, we are you know giving up a lot of latency and not only that but by waiting for actual acknowledgement of the messages before sending out another one, we're basically allowing one really slow message to be processed to be a bottleneck for all of the other messages. So whatever, again like i said that's not really the main point of the video. I'm assuming that we already know this at this point and now the question is how do we actually go ahead and build these queues and so the point is generally this. Like i mentioned, uh one of these types of queues is going to have messages in memory, the other is going to have them on disk, but other than that, pretty much everything else between them is going to be in common. So what are some things that we're actually going to have to implement within our service in order to make sure that they work properly? Well for starters, we're going to need some sort of front-end service that's going to do things like user authentication and it's also going to do things like rate limiting. That's very important, we don't want to be abusing our message brokers and we also want to make sure that nobody that's sending messages to our broker is unauthenticated and not supposed to be sending them. Additionally we're going to need some sort of load balancer. It's very important that you know when we want the ability to be handling millions of messages, we have to be able to kind of partition our queues in a way that certain messages are going to certain queues and other messages are going to other queues. In theory this could be done randomly but the truth of the matter is oftentimes we want to partition messages in a certain way. You know by topic, by user id, something along those lines and that's very important for things like stateful consumption like i mentioned you know using things like flink. Actually building up state as you receive those messages and so that load balancer is really important. It means we can use something like consistent hashing to make sure that the right messages are going to the same partition and then you know kind of built into that concept, we need some sort of coordination service. I guess we could be using a gossip protocol to do all of this, but it's probably easier to just have something like zookeeper which is going to manage all of this for us. Zookeeper is basically going to tell the load balancer how to do consistent hashing based on you know which of the actual nodes holding queues are alive or not and zookeeper can tell which of those nodes are alive based on which ones it's receiving heartbeats from and we don't have to worry about things like split brain or leadership election or any of that because zookeeper is a consensus-based system and it's also fault tolerant so it's really important to have something like that in our system. Then finally, I guess kind of the last aspect here is we're going to need some type of real-time communication protocol. Once the actual message broker itself has these messages, it's responsible for making sure that they actually go ahead and get to the consumers. So there are a few ways of doing this and i've mentioned them the past there's WebSockets, there's service and events, there's long polling. Personally i think that long polling is probably going to be the best solution to this problem for the following reason. A lot of these messages potentially can take very long to process, right? I gave the example of you know doing a ton of like video processing and you know uploading it to some server like s3 but what's nice about long polling is that once um you know a consumer long pulls our queue and receives a message from it, that long poll is going to be terminated while it's actually doing the processing of the message whereas on the other hand, if we were to use something like a WebSocket or a server sent event, that connection would be maintained even though nothing would actually be sent on it. So as a result of that, it seems like long polling would be a little bit better as i would think that it would decrease the load on our actual queue server as opposed to doing something like a you know kind of persistent connection. Um another kind of interesting point i wanted to touch upon a little bit were things like two-phase commit protocols. There's obviously going to be a lot of emphasis on the ability to you know potentially only deliver a message once when you have a message queue because it's possible the message queue never receives the acknowledgement from the consumer saying i'm done processing this message and then ends up sending it out again and really the only way to ensure that as best you can is by using something like two-phase commit with a coordinator node to ensure that both message delivery is successful and message processing is successful. However, that adds a ton of latency to the system. It requires some sort of transaction coordinator and ultimately it's probably not worth it. Perhaps what would be better is you just attach some sort of message ID or you know request ID to every single message and that way the consumers can actually go ahead and check whether they've seen them before when they're actually going ahead and processing those messages. You can have some sort of external table called like seen messages table or something like that and that way you can double check to make sure that you've never processed this message before. Obviously that's going to add extra complexity and latency too but if it's a requirement that you're only processing messages once, then that's something to note. As far as ensuring that messages are processed at least once, that's really easy to do with a log based message broker. However, with an in-memory one, it can be problematic because like i mentioned, they're not very fault tolerant. If the server were to go down, your message gets lost because it was just in memory, so you could do things like replication to help guard a bit against that and you could also use something like a write ahead log but at the end of the day, again, your messages are just going to be less durable unless you take extra measures to make sure that they're stored elsewhere somehow. Another thing that i wanted to note here is this, as our message broker is effectively just an HTTP server, it's going to inherently be handling multiple connections at the same time and that means it might be both receiving multiple messages at the same time and trying to send out many messages at the same time and as a result of this, it's kind of important especially for the in-memory message broker to basically use locking. The reasoning for this being if you're trying to push a bunch of things onto the same queue and you know you're implementing that queue for example is like a linked list or something, you may have a race condition where you write to the wrong end of the list and now you've basically cut out an element from your list (Need locks for both enqueuing and deleting messages) and so it's very important again to use a thread safe queue and one that's actually using some sort of mutex lock or something like that to ensure that you're not dealing with race conditions. Um the final topic that i want to touch upon which we've danced around a little bit is replication. I think that single leader replication is probably going to be the best here. The reasoning being that it kind of allows you to just publish messages the fastest. Um they're definitely going to be advantages to using something like a multi-leader or leaderless replication but, I don't know. It just doesn't really sit right with me the idea of having potentially multiple sources of truth with the queue and especially the idea of just having to you know deal with potential write conflicts, I don't know it just it just doesn't really sit right with me. I guess in theory you could do it but then, you know, you really have to reason a lot more about the type of messages that are going through your queues
- ![[Screenshot 2024-11-28 at 6.14.31 AM.png]]
	- Diagram
		- All right, time to get into this diagram. Okay so message queue architecture. Basically you start out with a client, and you're going to hit a load balancer because our authorization service which again is doing you know authorization, rate limiting, anything along those lines. It's very important that that's scaled out horizontally because otherwise it becomes a single point of failure and it's fine if that load balancer is just distributing requests randomly, the reasoning for that being is because we have a second load balancer between our authorization services and our actual queue servers. So you see i have the actual partitions of queues that the load balancer fans into where, you know, we would use some sort of consistent hashing algorithm that is kind of upheld or decided by our zookeeper coordination service and the zoo people coordination service is you know both sending and receiving heartbeats from all of those queues from the authorization service, from the load balancer,  just really making sure of what's alive and what's not alive in our system and then using basically that zab algorithm which is effectively the same thing as raft, it's just a consensus algorithm that's fault tolerant in order to go ahead and keep everything in order. And then finally the three queues can basically be in memory or they can be on log on disk if we're doing our log based approach and then the final piece of the puzzle is of course now that we've dealt with actually producing those messages, we have to have consumers. I mentioned that i thought long pole was kind of the best option because it doesn't keep persistent connections when those messages are actually being handled, and like i mentioned we're just going to have an api endpoint where the consumer can reach out to any of those queues, and say hey i just handled a message basically giving it the acknowledgement, give me a new message please and especially if you're going to be the in-memory broker, that incurs basically deleting a message as well 
		- Alrighty, not bad for another video here. Hope this one was informative. Again like i said, I'm trying to plan more types of videos for this channel especially just beyond systems design at this point. I'll definitely get to the algorithm stuff but it may just you know take a little while as i personally brush up and also i feel like there are a couple more systems design topics to cover so we'll do those and yeah, fun collaboration hopefully coming up.