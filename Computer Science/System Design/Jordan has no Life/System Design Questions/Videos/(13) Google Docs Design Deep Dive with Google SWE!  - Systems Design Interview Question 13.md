---
Source:
  - https://www.youtube.com/watch?v=WXxExjI9FnM
Reviewed: false
---
- ![[Screenshot 2024-11-25 at 4.08.25 PM.png]]
	- Introduction
		- welcome back nerds, if you've lasted this long in the series give yourself a pat on the back. Additionally, you're now pretty much assuming you watched all of those videos up to snuff with like 90 percent of applicants who basically just skim through "grokking the systems design" with that being said though, at this channel we're alphas, and we're going to get really good at this which means i'm going to keep doing problems until i get bored or until i become a higher level of software engineer. So with all of that aside, let's go ahead and talk about google docs. I've spoken pretty extensively about this problem already in terms of my concepts videos so i recommend watching the CRDT video and the collaborative text editing video, but i am still going to add quite a bit to that in terms of the actual computer architecture that we should be using for supporting those algorithms that i'm going to cover again in this video although probably in just a little bit less depth. So let's get into it guys and thanks again for watching, let's keep going strong  
	- Google Docs (Functional Requirements)
		- Description
			- Edit text documents, support concurrent editing (both online and offline)
			- All clients eventually see the same version of the document
		- Alrighty so as per usual, we are going to do our typical four to five step process in order to discuss this video and what that means is we'll be starting out with the functional requirements of a real-time text editing platform that allows for collaboration such as google docs. So what are our actual functional requirements? Well first of all, we want to be able to edit some text document and have others be able to edit it concurrently assuming they have access, additionally it's important that if concurrent editing does occur and concurrent editing here, keep in mind the actual definition of concurrent means that the two people editing the document basically don't know about each other's changes, basically what we want to have is that all people who are editing or accessing the document eventually will see the document in a convergent state. It may be the case that for a split second, there are some differences between the two, however eventually we want it to be the case that everyone who has access to that document will see the same document and there won't be any differences between what everybody is seeing. 
	- Google Docs (Capacity Estimates)
		- Description
			- 1 Billion documents per day
			- 1kb per document on average
			- 1 Tb of storage per day
		- In terms of capacity estimates for this problem, I'm actually not going to rip these estimates from grokking because they don't have this problem because they blow, but anyway, let's assume the following, maybe about a billion documents per day, i don't think that's that unreasonable considering they're about 8 billion people and like the entirety of the country uses google docs and you know makes a couple documents per day. Let's say each document is about a kilobyte to store or something like that, I don't think that's too unreasonable considering file sizes and what they typically are for text documents and then additionally that basically comes out to around a terabyte of storage per day, you know extrapolate that, do the math, 365 terabytes per year and even over basically a petabyte for five years so we obviously are going to need some sort of sharding but if you think about it a little bit, you can easily just shard on a document id itself in terms of the actual you know storage of a given document and that's pretty self-contained so it shouldn't be a big deal having to do that. Obviously there's going to be things like a user's table and you know other tables that i'm probably not going to focus on too much but generally speaking, uh you know those are relatively easy to shard as well and the main thing is just how we're going to shard these document storage and again just do it by "documenting?"  
	- Google Docs (API Design)
		- Description
			- FetchDocument(docId)
			- InsertChar(docId, position, char)
		- Okay, next let's talk about our API design. So i'm basically only going to discuss two endpoints and the truth of the matter is, I don't really even want to give parameters for these endpoints because our implementation of how we might use them, it may not necessarily even be something like an actual HTTP endpoint, you know. We may use WebSockets or something along those lines or some sort of other way of communicating with our server so it doesn't necessarily make sense to me in terms of parameters, but at least for one endpoint, it's pretty clear we'll probably use it at rest endpoint and that's going to be the fetch document where you just give it a document id and it'll load you some sort of document state which we can talk about how we might represent a document a bit later. Additionally there can be a second endpoint called make edit where we basically just list the character that we're inserting in the position that we're inserting it at but again like i said that may not actually be going over an HTTP server connection. May just do something like WebSockets so we'll talk about that in a bit.
	- Google Docs (Database Schema)
		- For a database schema, we are going to want like a users table and also something like document users table where for each document, you just list out the users that have permissions for it, but more importantly, the most crucial thing is actually going to be a documents table and let's not necessarily assume that this is going to be in any sort of relational database because we'll talk about how we can represent a document itself such that we can kind of best handle this collaborative real-time editing aspect that we need to be able to satisfy for our solution. So i'm going to leave the database schema kind of vague as well and let's actually just talk about the algorithm so i don't leave you guys hanging. 
- ![[Screenshot 2024-11-25 at 4.33.16 PM.png]]
	- Google Docs (Architectural Overview)
		- Alrighty, so before i go any further and discuss how we can actually use certain algorithms in order to enable real-time text editing, let me quickly give credit to the goat [[Martin Kleppmann]] for all the work that he does in this field because he is a big um kind of influence for me in terms of learning distributed systems and i'm stealing a lot of his images here so i should probably give credit where it's due. But anyways, let's talk about two algorithms that we can use in order to build a product like google docs. The first is the one actually used in google docs and that's known as something called [[operational transform]]. Operational transform is basically just saying the following and i'll bring up an image here so you guys can follow along with me.  
		- (1) If we have two concurrent editors of the same text document and they're both basically making their own edits, it's going to be the case that if both of these edits are first basically applied locally, and then sent from the server back to the other client with their write, what's going to happen is these two documents aren't necessarily going to be in the same state. Now let me provide an example for that so it's a bit more concrete. As you can see on screen we have the following document. So they start out consistent in the sense that they're both spelled h-e-l-o at h0,  e index 1, l index two, and o index three. After making those two edits that are shown on screen, you can see that one of them is going to become hello and the other is going to become `helo!` but with an exclamation point. Then both of those edits are going to be sent to the server. As you can see if the write from the right side aka inserting that exclamation point at position 4 was done on the document at the left after inserting l at position 3, we would actually get the wrong document. We would have `hel` but then an exclamation point and then o, and instead, what we want really to do in order to make everything correct is to be inserting that exclamation point at position 5. Unlike that on the right side of the equation, you can still insert l at position 3 and everything will be fine but the point is the, way that operational transform works is all of the writes that every single client is doing regardless of whether or not they're concurrent, has to be routed through one single server and by doing so, the server can basically take in all of these writes and say okay, how do i have to transform this write to pass it back to other clients based on the state that they have. What is it that i need to actually change about this operation. What is it that i have to transform about this operation so these clients can actually stay in a consistent state. So in the example on screen, you'll see that what's being changed is the position where the exclamation point is inserted. Now this is actually a viable algorithm. Like i said google docs has very much implemented this and it works well for them. However it does have its downsides. So what is the biggest downside of operational transform? Well the biggest thing is that all the writes have to go through a single server. So why does that limit us? Well for starters, it certainly limits the write throughput that we can handle. If you have a bajillion clients trying to write to one document, it's probably going to overload that server. Additionally, if you just want to do something where you know writes don't necessarily have to go to a server but could go over say bluetooth or maybe some sort of mesh network where all the clients are kind of connected to one another like a graph, that's not feasible here. But even though operational transform works, like i said, it is a lot less flexible in terms of the abilities that you have with it and the kind of network topology that you can deal with and so if we want some sort of decentralized application, operational transform is very much not an option. So what alternative do we actually have? Well, if you recall and maybe you've watched my concepts video on this, there's something known as CRDTs. Now CRDTs stand for conflict-free replicated data types and in particular i've shown off in the past that they're pretty easy to implement for types like a counter, a set that either just grows only or you can even remove things from the set and there are a few like relatively basic data structures that work well with CRDTs where a CRDT is basically saying you know every single possible place that can write, so let's say you have um like a leaderless database, every single instance of the database is going to hold its own CRDT and then they can pass the CRDT or operations on the CRDT between all the instances of the database and eventually converge to the same state. So let me kind of specify a little bit more so what i mean. In terms of CRDTs, there's two main types. There's state-based CRDTs and operation-based CRDTs. A state-based CRDT is basically saying okay every single one of our databases or anything with the ability to kind of be a write is holding the entire state of the thing that we care about and every single time that we want things to converge, the entire state of that CRDT is sent over the network whereas an operation based CRDT is saying, only send over the network the actual operation that impacted the state holding the CRDT So i know that's all very abstract but how can i put this in terms of a document? So if we had a state-based CRDT, that would basically be every single client is holding the document and every single time they make a change, they send the entire document over the network. An operation based CRDT is saying, every single client has a copy of the document, however, when a change is made they're only sending the actual change that they made. So you know, insert `l` at position three. So obviously in the case of a document, an operation based CRDT is going to be better because documents can get really large and you don't want to have to send the entire document over the network every single time a change is made. So with that in mind, we are going to use an operation based CRDT but it does come at the following cost which is that it's rare that operations are idempotent, which means that if for some reason i send an operation, you know from my client to my friend's client, and then my friend without even realizing that i've seen that operation before, sends it right back to me, i'm probably not going to realize that that operation came from me, and i'm going to apply it twice, whereas state-based CRDTs typically tend to be associative which means that no matter how many times that i encounter that same state, it's not going to have an impact if i encounter it multiple times. There are ways to kind of get over the actual issues dealing with idempotency with operation based CRDTs and a lot of that is probably somehow based in actually like numbering the operations or giving it some unique id so that you know if you've encountered that operation before but again it just requires having some extra storage. Another key important part of a CRDT to make everything work is that the operations that you're sending around, in this case, you know insert `l` at position three and insert exclamation point at position four, the CRDT will work if these operations are commutative meaning that it doesn't matter which order i see all of the inserts, assuming i see all of them, i'm going to eventually have the same state on my client even if they saw the operations in a different order. If you think about that, that's absolutely huge because it means that no longer do all of the writes have to be routed through one single server, but they could basically be sent in any possible configuration as long as all of those inserts get from every single node in the network to every other node in the network (think gossip protocols). So with that being said, I've kind of tried to give an overview of what a CRDT actually is but you know if you want a better one, i highly recommend watching my CRDT video and my real-time collaboration video, but more importantly, now that we know what a CRDT is, how can we actually represent a document in a way such that we can then have operations on this document and they are commutative and will help all of these nodes replicate the same state. 
		- (2) And the answer is, this is where the text editing CRDT comes up. So the way we do it is the following. We basically take all of the characters in our document and we uniformly assign them indexes from the range zero to one. So let's say, you know, our document has four characters like h-e-l-o as you can see on the screen. We're going to give them the indexes 0.2, 0.4, 0.6, and 0.8 and this way, whenever a client wants to basically insert a character somewhere, say i want to insert an `l` between `l` and `o` in `helo`., what i'll do is i will take the index of basically the outer characters which in this case are going to be l and o, you divide that by two and perhaps add a little bit of randomness so that you know two inserts to the same position, don't get the same exact number, and then basically pass that over the network. So if i want to basically say i'm inserting l, i would put it at 0.7 because of the fact that it's between 0.6 and 0.8 so you basically take the average of those two and maybe add a little bit of randomness. The great part about this is that if another client wants to go ahead and add an exclamation point between o and the end of the document which is at index one, you can split those in two and say the exclamation point is coming in at 0.9. So this way, no matter whether you receive the operation to insert l first or to insert the exclamation point first, you're going to have the same document state which is huge. However, even though this is a general idea that works very well, there are definitely some problems with CRDTs that make them tough to implement. 
		- (3) One possible problem which is kind of the most important one which i've outlined up here on the screen is this concept of interleaving. So what if we're trying to basically have two clients insert two different words into our document and those two different words are just ever so slightly different lengths. So as you can see here, the client on the left is trying to insert space "Alice" and the client on the right is trying to insert the word space "Charlie". So the issue with that is that space `alice` is six characters long and then space `charlie` is actually going to be eight characters long. When you actually do all the math and find the indexes that all of these characters should be inserted in such that they kind of follow this concept of splitting in half and then going from there, the biggest problem is ultimately going to be that they're going to get interleaved So you have these two clients updating at the same time and what you end up getting is this completely jumbled text. Now basically researchers have been able to fix this problem but the general concept here is that even though this CRDT seems relatively simple on a surface level where you know you're just splitting indexes in two and that's where you're putting new characters, there's a lot of nuance to text editing and a lot of these edge cases which make them relatively hard to implement. That being said, like i mentioned, people have done a really good job with these and in practice they've been shown to work quite well. 
		- So ultimately, if you're actually going to build um a real-time text editing platform like google docs, do you want to use operational transform? Do you want to use CRDTs? Well we know that operational transform is capable of working at scale, right? Like we've all used google docs. It has tons of users. It works. But at the same time, the crazy thing about CRDTs that make them so scalable is the fact that as a client, you can basically route all of your writes anywhere and as long as they're eventually sent to all the other clients, things are good to go because all of these operations, all of these insert operations, are commutative which means i can receive them in any order and as long as i eventually get them, we're good. On the other hand, operational transform like i mentioned earlier is limited to the write throughput of just one server, so even though you could replicate that server to make sure that you know if it were to go down, that another server could quickly take over its load, the point is, you can't basically just route all of the writes to a bunch of different partitions of servers and then have all of your clients interested in the document just be listening to all of those partitions because that's what would really speed up the write throughput. So with all of this in mind, let's take a look at a possible diagram. I'll discuss i guess what an operational transform diagram might look like and then also possibly a CRDT diagram as well. 
	- Diagram of Operational Transform
		- Alrighty, into the diagrams we go. Of course my pen just died on me when i needed it the most, which means we're going to the computer today to create a diagram. So a decently simple one for operational transform but we'll talk about it and you know what we can obviously do in order to make this as quick as possible. So let's imagine we have say three clients. All those clients for every single write like i mentioned for a given document at least has to go through the same server, so i'm basically buffering those all via a Kafka queue at which point these writes are all going to be handled by the operational transform primary server. As you can see, I'm doing a sort of state machine replication where i have an operational transform backup server also listening to those Kafka messages so that in the event the primary dies, the backup can take over. Perhaps you could use something like zookeeper or some other coordination service in order to determine if the primary is indeed dead. The primary is going to kind of take all of these lists of events and in addition, it can probably maintain some sort of in-memory hash map of kind of the states or all of the messages that have been acknowledged by every single client that it has seen and that way it's able to tell hey this client has seen this message or it hasn't seen this message and that way it knows how to make the proper transformation for a given client. Furthermore once those changes have actually been figured out, they can be propagated back to the clients using either a WebSocket or a server sent event, something that allows for real-time push so you don't have to go ahead and deal with long polling and further put a burden on the primary server. Another thing to note is that even though you might say oh there's only one primary for operational transform, ideally this is probably going to be sharded out on the hash range of IDs for documents because otherwise that primary server would be super overloaded. Additionally, in order to provide some persistence for every single document so it's not just living locally on all the clients, every single time that primary server makes a change, it should also probably be uploading a persistent version of the document to our document database. In order to do so, I think something like hbase would probably work really well here for a couple reasons. First of all, hbase is a single leader based thing so you don't have to worry about kind of eventual consistency and things like that. You can actually read from the leader if need be to get the most up-to-date document if you're kind of a new client that wants to fetch that. In addition to that and more importantly by virtue of having an LSM tree, hbase means that you're writing to an in-memory buffer and so those writes are going to go hopefully a little bit quicker and take some load off of our primary server and then finally the fact that storage is going to be column oriented means that if every single row in our hbase database which might be partitioned again by document ID, every single row can be something like an index and then the corresponding character at that index and so if that's going to be the case, then we can really easily take advantage of the fact that we have column oriented storage to pull all of the characters from one given column and so that's really nice and additionally if we use that kind of index as the sort key, we have an already pre-sorted list of characters that we can just rip the entire column for and that in theory should be a pretty quick query. So i think hbase makes sense here but i'm curious to hear if you guys have any other ideas. Additionally, keep in mind that hbase basically replicates automatically because every single SSTable that hbase flushes out the memory to is automatically replicated over the Hadoop file system. So that's operational transform as you can see, we're very much limited by the fact that all these writes are going to one primary server, but doing things like sharding and additionally caching, if we want to cache from that hbase document db, is going to make this a lot more feasible. 
- ![[Screenshot 2024-11-25 at 4.41.01 PM.png]]
	- Diagram 2
		- Overall though something like a CRDT can allow for much faster performance and we will now see why that is. Okay as for this next CRDT diagram, it is a freaking mess, but that's kind of the point is that you have all this freedom to come up with these wacky network topologies of documents and just do so in a way that maximizes the actual write throughput that you can get and also minimizes read latency. So let's actually take a look at this diagram and keep in mind this is all actually stuff made by me at this point, not even grokking the system's design, so it's pretty out there, but uh yeah let's take a look at it. So again let's assume we have three clients, but this time instead of all the clients having to write to the same place, they can basically write to multiple different Kafka queues and the way that they choose who to write to doesn't really have to be chosen in any particular way because like i said, all of the insert operations that we're trying to propagate, we can take those in a commutative matter which means that it doesn't really matter which queue all of the writes are going to as long as they eventually get to where they need to go. So we can basically have all three clients actively getting server sent events from all three of those Kafka queues and in addition in order to persist our information, we can have you know a primary and a backup server which are also getting the information from all three of those Kafka queues in the same Pub/Sub type of way, probably through server sent events and then furthermore, actually propagating this information to Cassandra. You'll notice that as opposed to using HBase this time around, I actually chose to use Cassandra. Now why would i do that? Hbase as i mentioned before is kind of a single leader database type of model and Cassandra on the other hand is leaderless. So the nice thing about Cassandra here is the fact that it's dynamo style database means that we can get much higher write throughput. So why do we actually care about um the lack of you know strong consistency here and getting higher write throughput? Well it's more so that in the other case with operational transform, when you read a document you know, you've never seen it before, you want to be as up-to-date as possible so the operational transform server can actually you know send you the right updates, you know, like it knows the state that um a new client is actually reading from and it can send the proper updates. On the other hand, Cassandra is eventually consistent but that's not really a huge deal because even if a new client reads a stale version of the document, what you can do is every single time you store a version of the document in Cassandra, you can also store the indexes of the the queues that you had read up to because they're log-based message brokers because i said Kafka. So you have the index of every single queue that you've basically ingested and you know anything beyond that index, you haven't ingested, so you have to process all of those inserts, so that way, every single time a new client wants to access a document and it's never seen it before, it can pull from the document database, then basically say okay, I know the indexes up to which i've read in all of the log base message queues and from then on, just start pulling from those queues from those indexes and then it can because all of these messages are commutative re-establish the same state that all the other clients are going to be seeing.
		- So this is just one way that you could do something like a text editing CRDT real-time editing system. Obviously like i mentioned it could be totally decentralized. We don't even need any servers. Every single thing could just be sent over a mesh network or something like that, but uh i hope this just kind of goes to show the type of capabilities that you have when the operations don't have to be ordered and they don't all have to go through the same central place. It gives you a lot more flexibility in the type of system that you're going to be able to build. 
		- All right everybody well i hope you enjoyed this video. Um now that we're out of the grokking the systems design content, i really don't have anyone to blame if my designs are bad and they definitely could be because the truth is i'm in `l3` and i'm kind of just spitballing based on what i know, but i do think they're generally reasonable designs and if you came into a you know systems design interview and spit what i just spat out, I don't really think it would be the end of the world and it would probably be pretty solid compared to what other candidates have to say. All this being said, I'm looking forward to making more of these videos. I think there are a lot more interesting you know websites and concepts to talk about now that we're kind of done with the very cookie cutter, like oh build twitter, build facebook messenger, et cetera et cetera and so i look forward to kind of tackling those videos with you guys. Anyways, thanks for all the support, means a lot and enjoy the rest of your day