---
Source:
  - https://www.youtube.com/watch?v=erusCJu6CQY
Reviewed: false
---
- ![[Screenshot 2024-11-25 at 9.13.25 PM.png]]
	- Introduction
		- hey everybody and welcome back to the channel, if you're here it means that like me you have such little life that you literally have nothing better to do than study systems design in your spare time but since you're here, let's go ahead and do some. A quick announcement, please subscribe to this channel. I'm starting to get desperate. Anyway as i digress let's get back to systems design. Today we're going to be doing a stock exchange and I've watched a few stock exchange videos and read some stuff in order to prepare for this. One of the things i noticed is that a lot of the um stock exchange videos from like non-actual trade youtube channels like non-financial ones will insinuate that there's going to be a lot of disk related activities going on. You know, using databases, using message queues, things along those lines and the reality of the situation is that none of that is true and so i feel like you know anyone who actually builds a stock exchange as i've learned at this point, will pretty much be doing everything in memory and we're obviously going to discuss that in more depth but it's just interesting to see that uh i don't know the people who are kind of existing making these videos did it kind of wrong, so i just want to put that out there and let's take a look at what's actually done right. I copied a lot of this from a Jane street talk so if what i say isn't sufficient, feel free to look at that and you know get a better sense of it and understand it better but i've tried to add some details of my own to that and uh yeah let me stop wasting your time, let's get into it. 
	- Stock Exchange (Functional Requirements)
		- Description
			- Buy and sell stocks at low latency according to limit order book
			- Cancel open orders, get volume of open orders at limit price
		- Okay, so as per usual, let's quickly do some functional requirements and all the other steps that we're going to have to do in order to start really talking about some design here. So as far as the things that we're going to have to implement in order to build our stock exchange, we want to be able to buy and sell stocks according to the spread which means basically that stock should be sold when the highest potential buying price crosses the lowest potential selling price and we'll discuss more about this algorithm in a little bit. It's called a limit book but like i said we'll discuss it in a bit, don't worry about that, and then additionally we want to be able to cancel orders if a client has already placed one and furthermore for those who are just generally inspecting market data, we want to be able to quickly see basically the amount of volume at a given limit price that people either want to sell at or buy at. So we'll discuss kind of some of the best algorithms to do that. 
	- Stock Exchange (Capacity Estimates)
		- Description
			- 100k messages per second at peak
			- On average 20 bytes per message
			- On average around 20gb/day
		- Okay, as far as some capacity estimates go, empirically the stock market has proven to be you know very popular and there are often 100,000 messages per second and if they're about 20 bytes per message that means we're dealing with you know say 20 gigabytes per day or something on that scale.
	- Stock Exchange (API Design)
		- As far as a pretty rudimentary API goes for our stock exchange here, some of the things that you probably want to be able to do are to go ahead and buy a security at a given price, sell a security at a given price, cancel an existing order with an order ID that's been provided to you and then finally you also want to be able to get the prices or the volume at a given price and then in addition to that, you know, if we're not only just building a stock exchange but also acting as if we're kind of like the broker as well like a robin hood or something, then you want to be able to see your past orders and things like that and you know that's where we would be adding kind of a database to this whole mix but for now i'm just kind of abstracting everything away and really just thinking about building a very low latency stock exchange and we'll talk about how we're going to do that. 
	- Stock Exchange (Architectural Overview)
		- (1) Okay, so let's start talking about an algorithm. The reason again why i'm skipping our database schema here is because the database schema itself is not going to make sense when we have no database. In actual stock exchange, we need to be executing orders on the order of magnitude of nanoseconds basically and that's obviously not going to be suitable if we're reading from disk, so everything is going to be done in memory here and ideally a lot of it in cache, so let's start by actually talking about something called our matching engine. So the matching engine is basically going to encapsulate all of the functionality of the limit order book, so what is a limit order book? Because this is basically the algorithm of how we're going to determine when an order should actually be placed. So you know as a client, I can place buy orders, I can place sell orders and what i'm going to do is i'm going to place them at a certain price, now let's say i have a stock and i want to sell it at 20 bucks and my friend wants to buy it at 15. Obviously things aren't going to work out between us and no order is actually going to be executed because we can't agree on a price. On the other hand, if i'm willing to sell my stock for twenty dollars and someone else comes along and you know names a price that they're willing to buy it at that's greater than or equal to $20, then an order is going to be executed. So i'll paste an image of a limit book on the slide but generally the point is this, the limit book keeps track of all open orders for buys and sells of a given stock and once that spread is crossed, basically meaning that someone is willing to buy at a price greater than or equal to someone else willing to sell, then you go ahead and fulfill that order and it may not be at all the volume that either the buy or seller wants, it may just be a partial order but the point is that things are going to start to get fulfilled.
		- So because we need to actually be running this order book algorithm so quickly, it's extremely important that everything is happening in memory and not only that but even within memory, you want to be avoiding locking basically as much as possible and doing this algorithm as quickly as possible such that every single time a new order comes in, we can quickly determine if there should actually be some buying and selling transaction and if so, send it out such that everyone knows it. So i've kind of said that this entire algorithm is going to be running on something called our matching engine. So before I actually go into kind of the whole distributed design of our system, let's quickly talk about the data structures and algorithms that might be running in our matching engine. 
		- (2) So based off one paper that i read online, a really interesting data structure and algorithm that could be used for our magic engine is a type of basically tree and this tree can be organized in a way such that you have two separate trees for all the open buying orders and all the open selling orders and that at each node of a tree, we have a linked list containing all the potential orders at a given limit price. This way, every single time that an order comes in, you basically put it in the proper node of this probably binary search tree or potentially even a self-balanced tree at the proper limit price node and in addition to the trees, we have two sets of hash maps. One hash map that basically points to every single start of the linked list at a given limit and then a second hash map for within each limit pointing to each node. So what's the point of these hash maps. Well let's say you want to get the volume of all the orders at a certain price, you can use the first hash map to quickly fetch that linked list and then iterate through it finding out all of the open orders at that limit. Secondly, and more importantly, if you want to cancel an order because cancellations are actually a very significant amount of the messages that go into a stock exchange, you can use the second type of hash map to basically go ahead and pull that element right out of the linked list. So those are basically going to be more or less constant time operations, however, in addition to that, we also have buying and selling. If we chose to use something like a heap here instead of just binary search trees, then we could quickly um in you know peak from an element of the the buy tree and the sell tree and that way we could see if any new order actually went ahead and crossed our spread and then in addition to that on inserting a new order, all you have to do is use the hash map to quickly find the correct limit linked list that it goes into and then basically put the order at the end of that linked list making it a constant time operation. So as you can imagine, I'm sure because this is a very important system here, this algorithm for kind of implementing an order book you know in memory has been very well thought out but chances are in an interview especially if it's not for something like a high frequency trading company and it's more so from the perspective of distributed systems, something like that is going to be a little bit less important. 
		- But now that we understand what our matching engine is, what is it that we're actually doing with this matching engine or what functionality do we need to have? Well every single time a matching engine you know executes an order or more or less even just confirms that a client put in an order, it has to go ahead and broadcast that information out to all of the clients to any people in the public who care about that information, to any third parties that have to clear the trade which basically means they're responsible for the actual financial transaction going down the transfer of the money and so this matching engine is not only responsible for doing the logic, but also for actually broadcasting everything out that it does to all interested parties, and not only do we have to broadcast this, but we have to broadcast it in a fair way which means that everyone who's interested should generally be getting all this information at the same time. So how can we go ahead and do this? Well the technology that we would actually use is something called UDP-multicast. Now you may be asking well why use UDP when something like TCP exists? Well there are a couple of reasons. One because multicast makes sure that all that information that's being sent over the network is being sent out at the same time, so you're achieving maximum fairness whereas TCP, you can only get basically two nodes to connect at the same time so you have to do all these handshakes in a sequential order and then it's completely unfair because one client is going to have its handshake done first. In addition to that, UDP multicast is generally faster because like i said, it doesn't have to establish a handshake but it comes at the cost of not having sequence numbers and it also comes at the cost of not doing any flow control so if you're not really sure what these things are, I recommend you watching my video about TCP versus UDP but basically what this means is that when i'm the matching engine and i say oh you know what, this order has just been executed, um here are the two parties involved, here's what happened, I can't be sure that basically all of my client nodes are going to be receiving that message and i'm you know there's no telling that they didn't just drop a message and now they have no idea that their order was placed. So how can we actually ensure that everyone is keeping track of all the messages being sent out from the matching engine? Well we can actually create a couple of other nodes in our system known as retransmitters and i'll show these in a diagram in a little bit but the point of these retransmitters is to basically take in all of the outgoing messages from the matching node that say you know, I received this order, I received this order, this transaction has just been executed and the entire job of the retransmitter node is to basically keep a log of all those outgoing messages so that if any of the clients or interesting parties or anything like that realize that they missed a message, they can just ask the retransmitter node for it and then the retransmitter node can send that message. This is also really useful if you know say you're a new client or a new server in our system that needs to kind of be up to speed, the retransmitter node can basically just send you all of these messages. So now we've kind of dealt with how one would deal with dropping UDP messages but at the same time, we don't have any fault tolerance in our system. Why? Because all these messages are going through our matching engine and the big issue with that is what if the matching engine crashes? Well in order to kind of deal with this, what we need is obviously going to be some sort of secondary matching engine. Now the secondary matching engine is basically also just going to sit right alongside the matching engine, probably going to be on a different machine, and it's also just going to be running in memory. So now in the past when we've seen single points of failure, what will typically happen is you know we might use something like zookeeper or coordination service running some sort of consensus algorithm in order to keep a distributed log between them so that they can have the same state, but that's completely infeasible for this type of solution because as we know, consensus takes a long time. It takes multiple network round trips between multiple nodes and it's probably all going to be over disk and so as a result, we don't have the luxury here of using something like a coordination service so that the primary matching engine and the backup matching engine stay in sync. Rather instead, we can really only do the following, you might think at first oh hey actually what's going to happen is all the messages being sent to the primary matching engine should also just be sent over multicast to the backup matching engine and that's kind of the right intuition however in reality it doesn't work because all of these messages are going over the network and as a result, there's no um guarantee over their ordering more or less. So we know that there's this kind of arbitrary ordering of all the messages being received from the clients and especially due to all these high frequency traders, they're all kind of trying to be the first one but only one of them really is going to be first and the kind of node determining the order of all the messages being received is the matching engine. The secondary matching engine as long as it is the secondary should not be the one deciding the order, it shouldn't have the ability to do so and in addition, the only thing it can really do is default back to the primary matching engine for the ordering of all the messages in the stock exchange. So how can it actually go ahead and take account for all of this and then be up to date if the primary matching engine is to go down? Well the only real option is when the primary matching engine is broadcasting all of its messages back to all the clients or to any of the interested parties, the secondary matching engine is also listening to these and not only is it listening to these, but it's updating its local state where its local state is going to be that limit order book. So basically, the secondary matching engine in tandem is updating its limit order book as the primary matching engine does and sends out messages and that way if the primary matching engine were to fail uh you could use some sort of consensus system between them like zookeeper in order to basically determine if the primary went down and if so the secondary matching engine is going to take over and it is going to have an up-to-date state which is really good. 
		- Now the final kind of piece of this puzzle is can we make this thing any faster because obviously that is the main concern of any stock exchange, how fast can we make it because the faster stock exchanges get, the more accurately the prices are reflected, the less opportunities there are for people to kind of arbitrage individuals and take advantage of them in the stock market so speed is kind of everything here, but the only other thing we can really do is kind of shard it and so how can we shard? Well the obvious way to do it would be on tickers right? There are a bunch of different stocks out there, you know there's apple, there's google, there's facebook, there's Microsoft, all these things, and we can make it such that you know we take our diagram, our entire system of you know clients connecting with our couple of matching engines and a couple of pre-transmitters and all that and we just duplicate it you know 100 times over for all the tickers or something like that but the truth of the matter is, even though this will make things more efficient, we would also lose some abilities. A lot of places um you know want to kind of make conditional trades where they're going to say, well i'll do this order if you know both of these ticker uh transactions go through but otherwise cancel or something like that and if we were to shard our system this way, then people kind of lose the ability to do multi-ticker transactions so that's something to keep in mind but um generally it has been shown that this like relatively simple design of keeping everything in memory using state machine replication because you know the secondary matching engine is basically just replicating all of the operations that are causing state in the primary matching engine and by doing all of these things and kind of handling the pitfalls of UDP, we can make sure that we actually have a very functional and quick stock exchange and in terms of achieving high throughput, really the only thing that we're limited by is the latency of our operations. The reasoning for this is that, you know, because UDP has no congestion control, if there are too many operations and we can't process them all in time, a single one of these nodes that our servers are going to get overloaded, so the faster that we can process these messages the more actual network messages we can take in and then we won't have congestion issues over the network so in you know the stock exchange, latency is throughput. 
- ![[Screenshot 2024-11-25 at 9.13.51 PM.png]]
	- Diagram
		- Anyways let's get to a diagram so i can make this more concrete for everyone but i hope at least what i was saying is starting to make sense and then looking at the diagram will kind of hammer it down for all of you. Okay so as far as the diagram basically at the core of this we'll show off more or less a couple of clients and the clients are connected to our order services which are just you know typical web servers and all they're going to do is place an order to our order service and then once that's done, the order services are more or less just starting to you know hammer the matching engine proposing messages to it. Now the matching engine is more or less going to be choosing one of them putting it in its limit book and then performing the necessary operations in accordance with the limit book algorithm. As the matching engine more or less sends messages back up kind of the chain of command towards all of those order service servers towards the re-transmitters towards the backup matching engine, the backup matching engine can go ahead and update its state in order to replicate it and then furthermore, the re-transmitters can keep track of that message in the event that any of the other nodes in the system drop it so that they can send that message right back to them. You'll note that there's a cancel process here and the entire purpose of this cancel process is basically just to decouple all the cancel functionality from the actual matching engine itself. I'm not sure if this is necessary but it is something i've noticed in prior diagrams. I guess you could have a separate thread running in order to basically remove an element from those linked lists and then i guess you would probably need a lock for something like that and then yeah, I mean basically the point is from here, even though this is kind of the atomic building block of this whole stock exchange, this is where other relevant kind of micro services are going to do stream processing on all the transactions that come out, you can have a MySQL database to deal with the actual exchange of money, like i said, there's gonna be some stream processing, uh, you can use that to run through some sort of machine learning model to see if there's fraud or fraud detection. Put things in a time series database and all that good stuff, but generally speaking the important part is you want the matching engine doing as little as possible other than dealing with the order book and sending out those messages over UDP and that's kind of the important part of this and it is the main thing to note. Then obviously the clients can go ahead and receive new data through those order services and perhaps that could be through TCP but the point is you know within kind of our network is the exchange where our network is our servers and the matching engine and the re-transmitters, everything is unordered with no flow control and so we have to manually keep track of the order of messages 
		- So yeah that's about all i got there. Anyways i hope this video was useful. I think a lot of the stock exchange videos that you'll see online are probably more a little bit robin hood focused and uh i think this one's a little bit more practical in terms of how you know the big ones like nasdaq really want to be doing it because i mean just latency is everything. That's really all it comes down to for these guys, latency is everything. So it'd be interesting to see if people really ask a question like this in distributed systems interviews because it's not as much distributed systems, but i guess it does require you to know things about network protocols, state machine replication, and you know just kind of handling dealing with UDP or anything like that in general and i guess i could see them you know asking for kind of the layer that you would add on top of the stock exchange as far as keeping track of transactions via database, things like WebSockets to alert a client when their transaction has gone through and even though i didn't really touch upon that too much, um you know these are things that we've spoken about in other videos that are pretty similar like you know i've talked about getting real-time notifications in facebook messenger and if you know, if you need to just throw all the results of an exchange in a queue and then alert the necessary clients when you have to, but yeah i mean overall i think the exchange part is kind of the biggest thing to focus on here so i hope that made sense. Anyways guys i hope you enjoyed.