---
Source:
  - https://www.youtube.com/watch?v=TuKjdj9YXns
---
- ![[Screenshot 2024-11-28 at 5.19.01 AM.png]]
	- Introduction
		- Today we're going to be doing another systems design video which i'm excited for because you know at first i thought i was out of them but as i get desperate, ideas just keep coming up. Looking forward to making this one and uh, yeah, let's get into it before they come back. 
	- Number of Unique Website Users (Functional Requirements)
		- Description
			- Count number of unique website users both live and historical numbers
		- Okay, let's get into these functional requirements. So anyways, um if you guys have seen from the thumbnail, today we are going to be counting the unique number of users on a given website. This problem could also be expanded to something like counting the unique number of search terms on google. Basically just counting the number of unique items where there are a ton of items such that this problem becomes tough at scale. Um let's also go ahead and assume that you know, we want to be able to kind of keep track of this historically so that, you know, we want to see the number of unique users from say an hour ago or 10 days ago, we can find that by inputting a timestamp. Additionally, it's important to know that there could be many devices per user. So that's obviously going to make things a little bit more challenging. It's not like we're just counting the number of users total. That would be easy.
	- Number of Unique Website Users (Capacity Estimates)
		- Description
			- Up to 1 billion unique users
			- Up to 10 devices per user
		- Okay so as far as our capacity estimations, let's imagine that we can have up to a billion users. Like i mentioned, this is not going to be something that is at small scale. It's going to be tough and we're probably going to have to distribute our computation over many devices. Otherwise, this problem would be pretty simple. Let's also imagine that each user can have something up to like five or ten devices and it's very much possible that as a result, you know, you may have duplicates in the number of things that we're trying to count.
	- Number of Unique Website Users (API Design)
		- Description
			- GetNumUsers(timestamp - default to now)
		- Okay, there should probably be only one API endpoint here when we're doing our api design and that's going to be to actually get the number of unique users. So let's imagine that we can pass in a timestamp which can be let's say normalized to like 10 seconds just we're not processing this too often but also perhaps if you know you don't pass in a timestamp, then imagine that we're going to have to get the number of unique users currently and have some sort of real-time endpoints. So this isn't just going to be like a batch processing problem.
	- Number of Unique Website Users (Database Schema)
		- Description
			- `UserStatus[deviceId, userId, onlineStatus]`
			- `ActiveUserCounts[timestamp, count]`
		- Okay, as far as the relevant tables and databases that we might need during our problem, one of them is probably just going to have to be a users table because we're going to have to store the actual status of a user for whether they're online or offline and that's going to help us actually make the calculations of how many users are currently using our service and then additionally because i mentioned that we want to be able to return historical results, we should probably have some additional database that's going to actually keep track of the number of unique users at a given time. So i can just have a timestamp and the number of unique users.
- ![[Screenshot 2024-11-28 at 5.35.12 AM.png]]
	- Number of Unique WebsiteUsers (Architectural Overview)
		- Description
			- (1)
				- HyperLogLog - approximate number of elements in a set
				- Given UserIDs
					- Max number of rightmost zeros at UID 10001000 = 3
					- Since there isa $\frac{1}{2^3}$ = $\frac 18$ change of 3 rightmost zeros, we estimate that there are 8 elements in the set
		- Okay, so let's do this architectural overview. So the first thing i'm going to start with is kind of a bad implementation of how we might actually be able to build a service like this. So i mentioned right off the bat that we have some sort of database. Let's just imagine it's a relational table where we have rows and each row has a user id and perhaps a status that tells you whether they're online or offline (and a deviceId, userId not unique here). You can just update that status when they first log into your app for example. So a bad implementation might be to actually do an entire scan on the database and then go ahead and return basically the number of unique users. So why is this bad. Well for starters, (A) it's going to basically take up a lot of capacity of our database to handle other requests because we're doing a full table scan and especially if this is a relational database that's going to be really bad if we're doing something like two-phase locking. Additionally it requires that we're potentially going to have to use a lot of time because like i mentioned, full table scans always take very long. Even if you do have an index, you're still scanning through the entirety of the table and lastly this is especially if you don't have some sort of index on your database where you have basically rows of devices and their corresponding user id (If the table isn't sorted by userIds, you need extra space to see if a given userId is unique) then you're going to have to basically keep some sort of amount of user ids in memory that you've seen before to see whether or not they're unique. So overall this takes a lot of time, it takes a lot of space and it's going to bog down your existing database. So we probably want to do something a little bit better than that. Well what if we built kind of a dedicated service with a hash map or a set, right? And then every single time that a device logged in, we would take its user id, we would plop it in the hash map or the set and that way we could get constant time accesses to see if a given device was unique. Then every single time that we wanted to go ahead and get our kind of data returned in terms of the number of unique users, we would just go ahead and say, tell me the cardinality of the set, aka the number of elements in it, and that would be pretty simple and pretty easy but there are a couple of problems with it. The first one is this, um because of the fact that there are up to a billion users, that hash map is going to be pretty huge and as a result, there's no guarantee we could even fit it on one single system. In addition, it's possible that the load from the actual number of calls to that kind of hashmap server would be too high for one single system (Because every log in and log out have to be sent to the server) so in theory we could shard this out right and we could basically do it such that, now you have all of these basically distributed maps on different nodes but then you run into the problem of saying, okay well i have basically a part of the hash map on every single node, but it's possible now that a user id might go to different nodes in the cluster (Problem: distributing hashmaps may mean that the same userId is counted twice on different nodes) and as a result when we try to add up the sizes of all the hash maps, we basically have duplicates across nodes and this can actually be fixed pretty easily. We've talked about consistent hashing in the past and if we use consistent hashing to ensure that the same user id is going to go to the same node every single time, now we've basically found a way to implement hashmaps across nodes in a manner such that you can have basically consistently hashed user ids across the board and then you could go ahead and aggregate the size of all those sets. So that works really nicely but now let's make things even harder. Your product manager says to you, you know what, we don't have the budget for this. We're using too many servers. We need to use less space because the time complexity of our hash map solution is really great, right. It's completely linear time, you're literally just combining a bunch of sets that are contained in a bunch of different nodes. However, what if we want to somehow decrease our space and the truth of the matter is decreasing space is not easy here because how are we going to count the number of unique things without actually keeping track of the number of unique things themselves and if you've watched my top k leaderboard video, this is the part where you may start thinking to yourself, okay we probably have to use some sort of approximation algorithm. So how can we actually go ahead and approximate the number of unique users.
		- (1) So i'm going to give you kind of a sense of a coarse algorithm and i'll make sure to put a visualization up on the screen here so that it makes a little bit more sense but we're going to be using something called [[HyperLogLogs|HyperLogLog]]. So hyperloglog basically does the following. It says, we have basically a bunch of user IDs or a bunch of numbers and we're going to calculate how many of those numbers are unique and the way that it does this is by doing the following. It looks at all of these numbers, let's imagine there's 64 bits, it looks at the right most bits of those numbers and it's going to find the number in the set with the basically the most number of zeros as the right most bit. So why would you actually do this. Well let's imagine that we have a set of user ids and over that entire set, one of those user ids has three rightmost zeros as in it ends with three zeros. What hyperloglog would then say is okay, the chance that any of these user ids has three zeros ending it is going to be one over eight right because each of the zeros can be a one or a zero and as a result, it's one half times one half times one half. So there's a one-eighth chance that one of those user ids is actually going to be ending with three zeros and so that's kind of the course approximation that hyperloglog takes. So it goes through all those user ids, finds the one with the most ending right most zeros and then it says okay, if there are n right most zeros and that's kind of the uh user id with the most of them, then we imagine that there are two to the n elements in the set so if there's a user id that has five ending zeros, we're going to guess that there are 32 elements in that set that are unique.
		- Now obviously that's a pretty coarse approximation and over just one set of elements, it's probably going to be pretty wrong. So what can we actually do to not only make that better but to even speed up our approximation a little bit and make sure that our server that's performing the hyperloglog algorithm isn't getting overloaded with a huge amount of network requests. Well obviously we're going to be doing some distributing. 
		- (2) So instead of basically having all of the user ids going to just one server, we're going to run multiple separate instances of hyperloglog on multiple different servers and we can just have a load balancer that you know randomly assigns every single user id to each server. We don't have to use consistent hashing here because the entire point is that we're randomizing where the user IDs are going to decrease the actual variance of our answer. So now let's say we have multiple different sets running hyperloglog and so on server one, you have the rightmost zeros or the most rightmost zeros being five and on server two, you have the most right most zeros being three. What you would end up doing is you would take the average of the number that hyperloglog returns which in this case would be four because five plus three is eight over over two is four and then you would ultimately guess that there are two to the fourth user ids which is going to be 16. 
		- So that's kind of how hyperloglog would work in a distributed setting and basically by going ahead and doing this, we can ultimately perform an approximation that is going to allow us to in real time take in all of these user ids and spit back at least a semi-accurate approximation. Based on the research that's been done about this topic, there are actually mathematical bounds that you can establish on how accurate or inaccurate hyperloglog can be but for our purposes we're not going to go into that too much. I'm just going to explain that, you know, we basically have all of these servers that are taking in all of these user ids and the only thing that they have to keep track of is the user id that they've seen with the most number of rightmost zeros and as a result of that, all of the servers are only having to store one user id at a time and it basically uses constant space complexity and so as a result of that, we've basically satisfied our request not only to do these real-time queries but more importantly, to decrease the amount of space used in order to get at least an approximate solution to our answer. Okay, finally the one last piece of the puzzle is this, you in addition to having an approximation can use kind of like a separate but parallel um batch process that runs in the background where the batch process since we don't really care about the amount of time that it takes to run can do an actual exact algorithm just using the actual data that we have in our database and as a result of that, we can you know kind of perform approximations in the moment when someone needs a number in real time but then over time we can run a batch job in the background and by doing so where we're basically pulling from the database, we can go ahead and actually populate a more accurate time series database of the actual user numbers over time 
- ![[Screenshot 2024-11-28 at 5.35.27 AM.png]]
	- Diagram
		- Anyways, let's go ahead and get ourselves into evaluating this diagram. As per usual, we're going to be starting with our client where the client basically has two functions. The client can either go ahead and you know do something where they are coming online or offline or this is probably going to be a different client that's querying this, they can also query our count service in order to actually figure out the number of users that are currently online. So let's start with the status service because the status service is for users as they come online or offline. So the first thing that's going to happen after hitting the status service is you're going to reach into that user status table which we can just use MySQL for (Can be sharded based on userId, just use consistent hashing) and all that's going to basically say is you know you have rows where you have something like a device id, a user id, and whether they're online or offline. In addition to that, we also are taking our change data from basically the changes going into the status table and streaming it into Hadoop. The reasoning being so that we can efficiently do batch processing later because we'll have greater data locality to basically go ahead and find the exact count of the number of unique users. In addition to our status service like i mentioned, every single time that a user ID is either coming online or offline, those changes should be pushed through a load balancer to one of our hyperloglog instances and we can call those buckets but the point is they're generally just being run on different nodes in memory and as a result of that, we can aggregate those averages really quickly back on our count service and return them back to the client. In addition to basically pulling numbers from hyperloglog, the count service can also pull numbers from a time series database which are going to be exact numbers that were actually calculated by our Hadoop cluster on a batch job using something like spark. Hadoop can, you know, say run that every 10 seconds or maybe every minute or something, but the point is, frequently enough that we actually have accurate counts and the reason it can do this is because we don't have that kind of SLA where we need to return real-time results but rather Hadoop can do a longer more complicated query over effectively a copy of the MySQL table local to Hadoop because it's being streamed over there by that Kafka queue and then that way you can get those accurate results while simultaneously providing approximate results in real time. This is really useful and if you again watch the top k problem video, it's very similar to kind of the parallel processing between stream and batch. One for approximate results, and then the other for actual fine grained course results. 
		- Okay guys, I hope you enjoyed the video. I think i'm probably leaning towards doing some more competitive programming and just maybe even a little bit of leetcode related stuff in the sense that i'm realizing, I personally am a little bit weaker at it and would like to get better. Um, there are probably going to be some future announcements for the channel that i look forward to talking about, maybe a future collaboration that's in the works, and yeah I just continue to look forward to everything that i hope to post on here. You guys have been amazing and uh have been super nice in terms of interacting with me. One of you guys specifically a guy named Alex messaged me on LinkedIn and I responded to him but you know that's that's the type of interaction you want with the people who enjoy your content. So all you guys are amazing. I literally you know only have the best things to say about all of you. Amazing to interact with all of you in the comments and I, you know enjoy doing so and i appreciate doing so and I hope things continue to be that way. So have a great day everyone.