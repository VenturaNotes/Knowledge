---
Source:
  - https://www.youtube.com/watch?v=vNDz6jqtR40
Reviewed: false
---
- ![[Screenshot 2024-11-27 at 1.28.34 AM.png]]
	- Introduction
		- We're going to be doing a systems design of amazon. Fun fact, as you can see I actually worked at amazon for a very short amount of time, and uh, I on the other hand worked for AWS. Here is a word of advice as well, if anyone ever asks you to design AWS in a systems design interview, you should probably do two things. The first should be to get upset and then second to wonder why that is an expectation of you in a 45 minute session. So with that out of the way, let's do some uh amazon and we'll think about this. It's actually a decently complicated design, wouldn't you know. And uh yeah, this might be a little bit of a longer video but let's get into it and let's learn together.
	- Amazon (Functional Requirements)
		- Description
			- Quickly search for products based on text
			- Complete an order with a given list of products
			- Deal with concurrent cart updates
		- Okay, so firstly, we can start off with some functional requirements. So they're going to be three that i'm going to focus on and these are all going to kind of be three key services that amazon allows you to do on their kind of ecommerce website and i guess [[Flipkart]] would be the same if you're Indian, but um yeah let's just talk about three main ones. So the first is we want to be able to search for products, the second is that we want to be able to go ahead and purchase products, and then the third is that um if we basically have a cart that we're updating, you know we're adding items and saying we eventually want to buy this, it should be the case that if you have basically another user on your account, you know, maybe it's a family account or something, you're concurrently adding items to the cart, you want it to be the case that another person's updates aren't being lost and in an ideal world, that eventually all of those things are getting merged in together. So we'll talk about how we can do all of those three things. Anyways let's get into the capacity estimates.
	- Amazon (Capacity Estimates)
		- Description
			- 1 billion users around the globe
			- 100 million products, 1 kb per product = 100gb
			- 100 million orders per day
		- Okay, in terms of the estimated scale that we can expect for a product like amazon, we know that pretty much the entire world is using this thing, so i basically said let's imagine we have about a billion users and with those billion users, maybe something like 100 million products where if each product you know requires about let's say a kilobyte of data to store all of the associated metadata and the name and perhaps even like a url and s3 or something like that, then we're probably looking at around 100 gigabytes of product data which is certainly enough to store on one machine but for the sake of making things faster, we'll probably end up partitioning something like a product table down the line. Additionally if we have something like 100 million orders a day which i think is pretty feasible considering the fact that maybe you know 10% of all customers will place an order on a given day, then we're going to have lots of concurrency when placing orders, and we're going to have kind of a huge amount of i guess writes that we have to deal with and make sure aren't messing each other up when we're dealing with kind of inventory and having to make sure we have enough of it. So we'll think about that later, but uh yeah, time to get into the api design 
	- Amazon (API Design)
		- Description
			- searchProducts(queryString)
			- addToCart(userId, productId)
			- placeOrder(userId, productIDList)
		- All right, so for our api spec, i've kind of mentioned three main functional requirements that we want to touch on and as a result, I basically have three main APIs that we want to be implementing. The first is going to be to search products that can be a get endpoint and it'll probably just take in something like a query string. In an ideal world, I'm sure that amazon has a lot more logic built into this because they're going to be using something like a recommendation engine based on a bunch of parameters about your account and probably something like your past history but i think that's something that's a topic i'd rather touch upon in future videos as it requires a lot more thinking about ml and stuff like that and i feel like for now, i'd rather just focus on a pretty simple ecommerce website. Additionally we have an endpoint to do an add to cart where basically we have a user's account id and then also the product id that they're going to be putting in their cart object. Then finally, we want the ability to be able to place an order where for a given order, you know, you basically just have an account id of you know the placer of the order and then additionally kind of a list of product ids or a set of product ids that you're going to be purchasing 
	- Amazon (Database Schema)
		- Description
			- Accounts(email, `pw_hash`, address)
			- Cart(accountId, productsSet)
			- Products(id, name, metadata)
			- Orders(`acctId`, productIds, price)
		- All right, moving onwards, we now are going to quickly touch upon the database schema and for this i can think of four main ones that i'd like to touch upon but i'm sure as we go through the design there are going to be all sorts of databases that have to pop up just by virtue of kind of the complexity that we're going to be doing, but first off we have an accounts table which is basically you know just a given user and that can have an email, a password hash, an address, a bunch of other stuff that you know you need to be storing with any given account. Additionally we want to be having something like a cart database because like i said we want the cart to kind of persist on the network in the event that multiple users from many accounts are going to be updating that and we don't want that to get lost and additionally if you're just going to be updating your card over multiple sessions, I think it's better that the cart is something that's persisted as opposed to you know just local and being kind of kept in browser storage or in cookies or something like that. Next, we want a products table. This is obviously going to be very important because it's the bread and butter of what we're selling, and then finally we want to be having something like an orders table where an order is going to be associated with a given account, have a list of products, probably a total price, maybe some payment information, whether it was cancelled or confirmed or the expected delivery etc etc, and yeah that's kind of the basic database schemas that we would probably need for a problem like this. Let's actually start getting into the design because that's going to take a while to cover.
- ![[Screenshot 2024-11-27 at 1.47.25 AM.png]]
	- Amazon (Architectural Overview)
		- Okay, so let's start getting into this architectural overview. It's gonna be a bit because i'm gonna go through all three of these main features that i'm talking about and try and break them down to really make sense as much as possible. So as i'm sure you can already start to think about, we are going to have an ability to search for products and while it is possible that we could just use a query on our database, that's probably not going to be the best option here because generally speaking we're going to be searching for a product based on certain keywords associated with it or anything like that or you know possibly spelling a term wrong here and there and so what should come to your head is probably a search index and as i've covered in the past, the search index is effectively just an inverted index where you have this concept of basically a term and then a mapping of a bunch of different product ids that correspond to it and in an ideal world, we would be able to shard this in a way such that for each term, for example, you know what if i'm searching for a mattress. I would want it to be the case that for mattress in our search index, all of the possible document ids for our mattress are going to be on that same node in our search index cluster. It might not be the case that we're able to do that because amazon has a ton of products. Like i said, we're estimating 100 million products here and it's possible that not all of those are going to be able to fit on the same instance of a search index. So maybe we won't be able to partition our search index by term but in an ideal world, we would be able to because then we would obviously be able to have faster queries for a given term. If it is the case that we have to partition our search index by basically document ids where in this case the documents are actually just going to be the names of the products and some information about them, then we would have to do an aggregation over a bunch of nodes in our cluster which is going to slow down search times and is not ideal. If that's the case, we could greatly increase kind of the search speed and reduce the latency of our service by adding a cache in front of it. So we could introduce that and just have it such that you know if a ton of users are going to be searching for a given product or a given query term, we can quickly cache all of those results in order to kind of feedback all the products that are going to be relevant there. So basically every single time that um you know a vendor is going to be onboarding a new product, what they'll probably end up doing is first on boarding it to the database and then you can go ahead and stream those changes using something like change data capture in order to place them into a distributed search index. Okay, so we've covered product searching, now let's go ahead and try to cover the cart functionality. So i've mentioned already that what we want to be able to do is if i'm on my computer and i'm adding things to a cart and then you know say my mom is on her computer and she's also adding things to the cart, we want to be able to at least not clobber each other's updates, right? Because if the database is just storing the set of products that are in my cart and then i make an update, what's going to happen is my front end is basically going to tell the server side application, hey here the list of products in Jordan's cart, let's update the database to show that and now i've just clobbered any of the products that my mom has added. So we certainly don't want that to be the case, right. So there are a few options for how we can try and mitigate this. For one, we could just you know have a single database where all the writes are going to and then maybe we could use something like a real-time update. So you know on my computer, I'm sitting there and every single time she adds something you know we're both uh connected to basically the same back-end server through something like a web hook and every time she makes an add because you know we're basically connected to the same server we can use consistent hashing to do this um, i would go ahead and receive that product on my front end and then now every single time i make an add, her product is you know properly propagated to my front end, we won't have any issues. However i don't really think this is a great solution because it opens up the possibility of race conditions where i basically add a product right around the same time that she does and as a result, I still end up clobbering her add because basically her WebSocket never ended up propagating to my computer in time and so you know in this case real time updates are a little bit dodgy. So instead what other types of options do we have? Well in the past in some of my concepts videos, I've mentioned this idea of using something called version vectors or version numbers so i'll kind of explain this in the setting where we're just using a single leader database and then i'll explain how we can scale it out to a leaderless architecture. 
		- (1) So let's imagine that i have my version of the cart in the database and that has something like a version number 2 where the version number is a monotonically increasing sequence which means it only goes up one every single time there's a new write. However, every single time that i make a write to the database, I have to say my last seen version number. So if i make a write because my cart is already version number 2, i know that i've seen version number two and i'll be telling the database that. However let's say my mom has you know version number 1 and that's her cart and she hasn't seen my write yet, so if she makes a write from her front end, they're going to be passing version number 1 to the database. Basically what we can then do on the database is say, okay, by virtue of the fact that she has not seen my version number, we know that these two writes that are being made are actually concurrent and as a result of that, we can store them not where they're clobbering one another but we store both of them as siblings in the database and eventually when i refresh and i load my version of the cart, what's going to happen is it's going to show me both versions of our carts and then i would have to merge them together somehow. 
		- And this can easily be scaled out to multiple databases where it's not just version numbers anymore but now it's version vectors where each version vector is basically the version number on each of the potential database replicas that you could be writing to and this allows you to scale this out such that you can deal with multi-leader replication or even leaderless replication and greatly increase the write throughput of your service. I think truthfully it may be a little bit overkill for the cart service in the sense that you're probably not needing such high write throughput for carts because um you know generally speaking there's only a few people updating the same cart for the same account but you know if an interviewer was pushing you about this and they really wanted to say well what type of concurrency could you deal with here or you know how good could you get this right throughput theoretically, you could be using something like a version vector in order to store those siblings and eventually merge them back together. Additionally, kind of on this a similar tangent or a similar idea is you could use a CRDT. Now this is something i've mentioned in my CRDT concept video but basically CRDTs are a way for a bunch of nodes in a cluster, any of which can accept writes, to go ahead and have this eventually consistent state between them. 
		- (2) And there's a version of this where you can implement a set and the way it's done is rather than just having the set of items stored in the database, what's instead stored is all of the adds to the set and all of the removes to the set. So you're never actually going to be clock clobbering anything. You're just you know putting more adds in the database or putting more removes in the database and so when those two CRDTs are eventually merged together because you know those leaderless databases are performing their anti-entropy process and kind of you know exchanging writes with one another, then you can merge those sets together and merge all of the adds and merge all the removes and not clobber anybody's writes, so that's a really useful way of potentially you know kind of scaling out this write throughput a lot for our cart and something you know a database like Riak can easily support this out of the box. They have support for CRDTs and that's basically just a leaderless key value store, so that could work really well here. 
		- Okay, and then the last piece of the puzzle is when you're actually placing an order. So placing an order itself shouldn't be that hard. For the most part, this is just kind of a rest endpoint but there is a decent amount of complexity in the sense that when placing an order, we want to know if all of the items that you're trying to order are actually in stock and this is a lot harder than it seems because the truth of the matter is, when you have so many people placing orders, we said there might be 100 million orders a day, we have a lot of concurrent orders and as a result of that, it's very hard to get an accurate representation of what the count of the stock really is. I mean on one hand, we could use something like atomic operations, we could use a lock in the database to keep track of all these orders but then that's going to make this operation very slow. We want to generally be avoiding atomics and locks whenever we can. One possible solution and this is what i've seen certain systems design videos about amazon do is they basically use something like a write back cache where you know you'll use a Redis instance and basically use that in order to keep track of the stock because it's a lot faster to use something that's based in memory and you know just keep it single threaded or something like that so you don't have race conditions to update your stock than have a counter in a database and so that's a viable option and you can do it and the truth of the matter is, I actually pretty much have an entire video devoted to how you would kind of scale one of these types of things out. I mean if you look at my TicketMaster video, basically the entire premise is you need to know the stock in real time and the only way you can really do that and keep it relatively fast is by doing this in something like a write back cache and if you want to even establish a wait list of people, so if someone cancels their order, you can basically also add a linked list with a hash map to that cache in order to keep a list of the people that want that product and if you know the current order is cancelled, you can go ahead and basically um potentially let the next person in that linked list try and get the product. But i think that personally for amazon this might not necessarily be necessary and the reason for that is that the majority of the time there is going to be stock and you're obviously going to have to do some sort of statistics or math for this. I'm sure amazon has plenty of supply chain people figuring this type of thing out but the truth of the matter is that a lot of the time, it's actually acceptable if people place an order, amazon says in the moment, hey this is okay, and then if it turns out one of those items are out of stock, you can go ahead and send them an email after and say listen, I'm sorry, we thought we had this, it turns out we didn't, and here's your money refunded and this is a pretty common occurrence that happens on amazon which makes me think they probably lean a little bit closer towards this design because the truth of the matter is, as long as you know this kind of bad case of having to retroactively correct for your mistake is relatively unlikely, it's not really a huge deal if you'll occasionally be out of stock and then let people place their orders. So if this is the route that we decide to go, it actually becomes a lot easier because now we can have a much lower latency endpoint in the sense that we can do something like batch or stream processing. So for every single order that we're going to place, what we instead do is we can either place it into some distributed log or you know put logs in S3 or we can just put every single order in something like a Kafka queue and then we can either in kind of a streaming capacity or in a batch capacity, but you know relatively frequently, maybe every 10-15 minutes or something like that, we can go ahead and update all of the product counts and by doing this in kind of a batch or streaming way, we don't really have to worry about race conditions because all of those counts are just going to be updated one at a time. There's not going to be any concurrency there that we have to worry about and then for all of those orders that you know just tried to buy an item that were out of stock, we would go ahead and update them in our orders db basically saying we have to cancel this and then we can email them and say hey i'm sorry about this, you're out of luck, but we'll alert you, you know say the next time this product is back in stock. So with that all out of the way, I hope i've explained kind of the overlying concepts of this type of video and ultimately let's take a look at the diagram.
	- Diagram
		- Okay, so starting to look at the diagram here, we basically have the following architecture. We have a client and the client can go ahead and hit the load balancer and once we do hit our load balancer, we basically have three horizontally scaled out services that we can go ahead and access. The first is the product service and you know if the client application in this case happens to be on the behalf of a vendor, what they might be doing is actually uploading a new product and if that's the case, they're probably going to be putting it in the products db. As you can see here, i've opted to use something like MongoDB. The reasoning for this being that products probably have a bunch of different possible schemas, you know, whether it's like clothes and you need a bunch of possible sizes or like colors or anything like that. You know products aren't going to have one set schema and so it makes a little bit more sense in my opinion to use NoSQL here. I guess another option is that you could perhaps do something like um Postgres with Json but I think that NoSQL tends to be a better decision here and MongoDB keeps everything in a single leader replication type of way and relatively simple and you have the option for secondary indexes if need be so i think it's a solid solution for this type of thing. From MongoDB, we can basically take all of the changes that are going to be added to this database and stream them to something like a queue which can then be ingested into our search index. Now the search index is basically in an ideal world going to be term partitioned but, you know, if there are too many products, which there may be here, then we may have to do a document partition and in the event that we have to do a document or product based partitioning, the best thing that we can do for ourselves is introduce a whole lot of caching on the product search and then that way when people are actually going to search for a given product, ideally we would pre-compute all of the products that they might be wanting. Next up, we can talk about our cart service. So i ultimately opted to go with something like a set-based CRDT here and as a result, we could use that in Riak. You'll see i've kind of drawn out the consistent hashing ring that Riak uses to represent their leaderless replication schema with sharding based on an account ID and then finally now that we've talked about the cart service, we can go look at our order service. So for the order service, I probably honestly didn't add enough detail here but i'm going to try and use my words to explain as much as I can. So let's imagine we place an order. Obviously first we're going to have to do some sort of payment validation which i didn't really draw out but that is either going to require some sort of external service or if amazon's handling that themselves, I'm sure they're going to need some sort of SQL database to handle kind of the the transactional nature of that. Then you can place the order into a Kafka queue and here what i've chosen to do is i think that it would be interesting if you actually broke the order basically down into its individual products. So you know if i'm ordering, i don't know like a playstation and a monitor and uh who knows like uh an SD card or something, we put all three of those entries into the Kafka queue but individually and that way the Kafka queue can actually be partitioned by product ID and the reason that this is really helpful if that Kafka queue is partitioned by product ID is that then you can go ahead and store all of the inventory information locally on our stream consumers. So if we know that all of the products kind of messages are going to the same stream consumer, we can keep that stock locally and it's going to speed things up by quite a bit. So i've chosen to use spark streaming here. The only reasoning for that being that we can just use mini batching instead and ideally keep the latency nice and low and basically now on all the spark streaming consumers, I can basically say, okay, spark streaming consumer (A) is responsible for product ID 1 and product id 1 has a stock of a thousand and then you basically go ahead and gradually update that and if you ever find anything that's problematic, oh you know what, product id 1 now has an inventory of zero remaining, but uh you know user Jordan just tried to order one more of it, then you can go ahead from the consumer, update the order DB to basically say this part of the order has been canceled and refund that amount and also go ahead and send out an email to Jordan telling him that this happened, and so i think that's like a decently elegant design of doing this kind of you know make a mistake now and apologize later method and you know if you decide ultimately or if your internal kind of business development people decide that this isn't a feasible risk and that they would rather not kind of over allow orders, then again you can always do that kind of write back cache solution where you allow open orders to stay in the cache until they're confirmed and then update the stock and if an order is not confirmed for say five minutes, you delete it from the cache and expire it. So yeah, I hope this design was relatively comprehensive and that it made sense.
		- Alright guys, well I hope you enjoyed the video and that it was decently useful, um you know i'm just trying to continue to make valuable content for you guys and i've gotten really positive feedback in terms of being relatively to the point and explaining myself and uh i hope that uh yeah it's relatively useful for you guys because i can certainly say when i was still teaching myself all this stuff and to an extent i still am teaching myself all this stuff, I'll watch a lot of these videos and people will just really brush through stuff and and make no detailed explanations as to their decisions. So i hope i can at least be a little bit better in that sense. Additionally thanks everyone for continuing to subscribe. It's honestly pretty scary in the sense that someone i know is probably going to figure out about this soon and when they do, it's not going to be great that i'm making all these jokes. So you know a little risky there but uh i'm kind of enjoying it, so i may actually uh start experimenting by making some youtube shorts for fun because uh, I'm getting bored and i have some uh fun like coding related comedy ideas i can try and do and you know if you don't like them, ignore them or whatever but uh, we'll see. So yeah, have a great day guys. Really happy everyone's uh been enjoying the channel for the most part and uh hope to learn 