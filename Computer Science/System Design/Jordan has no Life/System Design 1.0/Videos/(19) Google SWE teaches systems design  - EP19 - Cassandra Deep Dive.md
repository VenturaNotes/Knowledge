---
Source:
  - https://www.youtube.com/watch?v=VnLAyZHBO6o
---
- ![[Screenshot 2024-10-03 at 10.32.06 PM.png]]
	- Intro
		- All right everyone. I am home alone again which means I was faced with a very tough decision AKA either whip it out or record Another YouTube video and uh I guess I'm deciding to feel productive at the moment so I will be talking about Cassandra in this one. I've been looking forward to this video for a couple of weeks because I find that um you know like I said the whole reason I made this channel in the first place was that they don't go that in depth into actual Technologies in most systems design channels or resources. Looking at things like systems expert.io like you know there's just like no in-depth stuff about specific Technologies and I pretty much want to go through every popular database and compare its pros and cons because I think you're going to look pretty damn smart if in an interview you can actually compare why you might use something like Cassandra versus [[Riak]] or I don't know MongoDB or anything. So anyways, let's get into it um and then uh yeah we can uh keep going into more Technologies and more deep dives into concepts.
	- Cassandra Background
		- Description
			- Cassandra is a NoSQL, wide column database designed for both high read and write throughput. It was first created at Facebook, and then has since become open source under the apache license.
			- In these slides, we will see how it achieves this, as well as some of the best use cases for the technology.
		- All righty so episode 19 this one is about Apache Cassandra. So what is Cassandra? It is a NoSQL wide column database designed for really high read and especially write throughput. It was created at Facebook modeled after things like [[Amazon DynamoDB]] and Google's [[Bigtable]] and it's since become open source under the [[Apache License]]. um so yep like I said really high write throughput NoSQL database. Pretty simple stuff. I'm now going to get into how it goes ahead and does all of that because it builds upon all the concepts that we've discussed so far.
	- Cassandra Design Philosophy
		- Description
			- Recall: The reason that SQL databases tend to scale poorly are that many operations touch multiple partitions due to the tendency to have highly related data.
			- Instead, Cassandra has opted to optimize for single partition writes and reads, and make those very fast. Because it is NoSQL, the hope is that you can store all relevant information in one single low within a partition.
		- Okay so what is the general design philosophy of Cassandra? Well generally speaking obviously they want super high availability, you know the ability to scale at a linear rate meaning every single time you add a node, it's going to you know do that much work and you know get all of its possible throughput. Um but most importantly the thing with Cassandra is that unlike SQL, um it is designed solely for single partition reads and writes. It doesn't mean that you can't do reads over say multiple partitions or can't write to multiple partitions at a time,  but generally speaking the main usages of a database like this are to try and keep everything onto one partition so that you don't have that extra network delay and coordination overhead required of something like an atomic commit or having to do all these multiple partition writes. So like I said, Cassandra is optimized for a single partition operation. 
	- Data Organization
		- Description
			- Cassandra is a wide column database - rows of a table can have any number and type of columns, but they all must contain one primary key known as the partition key. Additionally, it can designate other rows of the row to be known as clustering keys
		- okay so in terms of data organization like I said this is a wide column store so what that means really is that you have a primary key or what Cassandra calls it is known as a partition key and a bunch of other columns which are basically arbitrary. You can also specify in your Cassandra setup some other columns known as clustering keys, but uh those are basically um acting as indexes and I'll discuss those later.
	- Storage Engine
		- As opposed to many traditional SQL databases (which use B-trees), Cassandra uses an LSM tree + SSTable based storage engine.
		- Recall:
			- Writes are extremely fast as they are first sent to memory
				- Depending on how often log compaction is performed, frequent updates or deletes of a row can take up a lot of extra disk space
			- The performance of reads can be a bit slower if you need to search for a key through the SSTables
				- However, Cassandra uses bloom filters as an optimization (approximates the contents of a set)
		- okay so in terms of the storage engine like I said Cassandra is optimizing for really fast writes because in certain applications with a ton of users, you need to be able to write quickly and SQL doesn't always support that especially because of the fact that it uses b-trees. So if you've watched my first video on this channel, I discuss the different ways that databases handle reads and writes and there are two main types of engines, B-tree based and also LSM tree based. Cassandra goes ahead and uses an LSM tree based table. The reason that these are so fast is because it means that writes get buffered to an in-memory tree. In addition uh you know the downside of this is that depending on how often log compactions performed, remember that every single write goes into this table even if it's just an update and then eventually we'll get compacted to only um contain the most updated version of a key. But again depending on how often log compaction is performed and this is something that uses a bunch of CPU resources in the back um you know obviously updates can take a decent amount of extra disc space as a result of that. Additionally performance of reads compared to b-trees can be a little bit slower if you need to search through a key through the SS tables but Cassandra does use an algorithm called Bloom filters which basically is an optimization on um doing these reads because it approximates the contents of a set and that way you can guess if an SS table contains a specific key.
- ![[Screenshot 2024-10-04 at 10.19.45 AM.png]]
	- Partitioning
		- Description
			- As we might expect, Cassandra uses the partitioning key, in conjunction with consistent hashing, to determine which replica to send a given row to. Each shard is replicated, with the number of replicas specified by the user.
		- okay in terms of partitioning, why is Cassandra good? Um well Cassandra uses the partitioning key in accordance with um consistent hashing. So I literally covered this two videos ago as a prerequisite for this video in order to basically say the consistent hashing tries to put all of the the partitions on machines in a way such that when new nodes are added or nodes are removed from a cluster, there's minimal rebalancing of rows. Okay so hopefully that makes sense.
	- Replication
		- Description
			- Dynamo style database: all writes are sent to every single replica for a given partition, and the administrator can choose how many replicas need to respond with a success before returning a success to the client (can use quorums). This means that there will inevitably be conflicting writes:
				- Handle conflicts using last write wins
					- Requires keeping server clocks close to in sync via something like NTP, will be lost data
				- Read repair on reads, if client sees a replica with an outdated value, it will update it
				- Anti-entropy process running in background ensures eventual consistency of replicas
			- Note: if for some reason replicas cannot handle writes in a given moment, the coordinator will store the write to be sent to them later, and then perform a hinted handoff.
		- In terms of replication, this is where Cassandra is really really making for good write speeds. It's a Dynamo style database, so what that means is that every single write as opposed to just being sent to one leader node is being sent to every single node in the cluster for that partition. So what that means though is that um you know obviously "A", that can introduce conflicts and "B", it's a question of well at what point after hearing from all of these nodes do we actually tell our client that a write was successful? And the answer to that second question is that writes are only reported back to the client as successful once a write reaches a number of nodes that is preconfigured by the database administrator. Cassandra has a ton of options for this so you can either just hit literally any one node. You can hit um you know say a quorum of nodes but only in your local data center. You can hit an actual Global Quorum of nodes and there are a bunch of options for this. So you know you can kind of configure that to get the consistency level that you want. Um additionally just by virtue of being a replication setup where there are multiple leaders, it means that they're going to be conflicting writes. So how do we handle these? Well, we use last write wins. Last write wins means that you know based on the higher Timestamp, whichever one was the more recent write is the one that is kept. However, the issue here is that if you've seen my videos in the past, clocks are not reliable in distributed systems. Servers are inherently going to be a little bit out of sync. Cassandra doesn't really have a great answer to this. All they basically say is keep your servers as close to the proper time as possible via the NTP network time protocol syncing mechanism and um that's really all you can do there. Another thing that means is that certain writes might just be lost if you're going to update a key and then someone else updates it literally a millisecond later. So uh that is just a downside of all this. There's no like merge handling or anything like that. Um additionally, there is read repair on reads in order to keep the data consistent. So if you have um two nodes where one of them is holding an older version of a row based on the time stamp and a client reads from both of those replicas because um all reads are going to multiple replicas, uh the client will go ahead and perform read repair and give the replica with the outdated version of the row the newer version of the row. Um additionally and this is what um is really done to guarantee eventual consistency is that Cassandra runs an anti-entropy process which means that in the background um the replicas are going to be uh kind of calculating the differences between them in terms of their contents and then one replica will help to update another to make sure it has the most up-to-date versions of all the data. okay. And then the final thing is that um you know in accordance with kind of replication, Dynamo style databases and just keeping things available, if for some reason the replicas can't handle writes in a given moment, perhaps um you know they are overloaded or they're down, the coordinator node that is going to actually be sending the writes to the replicas will just store the write for a period of time and then eventually store them in the replica when the replicas are back up. That's known as a hinted handoff. I've used that term in the past.
	- Fault Tolerance
		- Data stored on replicas
			- Each replica added should allow read and write throughput to scale linearly
			- Choose replication topology, number of replicas in addition to location such as different rack or data center
		- Faults detected via gossip protocol
			- Nodes keep track of heartbeats received by other nodes in the cluster and their timestamp and send these via gossip, if a node has not gossiped in a long time, it is presumed dead.
		- okay, in terms of fault tolerance. Well, like I said the data is stored on replicas which is generally the way that you do handle fault tolerance and that's in this case both good for writes and reads because writes only have to go to a certain percentage of the nodes. Reads only go to a certain percentage of the nodes and then the data is redundant via the replicas.  The replicas should allow read and write throughput to scale linearly with the number of replicas like I mentioned earlier and then also a cool thing about Cassandra is that you can actually choose the replication topology. So what that means is not only can you choose how many nodes is a given piece of data replicated to, but also the location of which nodes it's going to be replicated to. So say you want to ensure that um if an entire server rack or an entire data center goes down and at least one replica will still be standing with that data, you can actually use a replication topology that ensures that only nodes and say like different physical locations are being replicas one another. Additionally um in terms of detecting faults in nodes, we use a gossip protocol to do that. That was the subject of the last video on this channel and basically all that happens is nodes are going to keep track of heartbeats that they get from other nodes and then each node locally is holding what it assumes to be the last known heartbeat of every single other node which they pass around via this gossip protocol and if the time stamp takes too long or it's been too long since a node has sent out a heartbeat uh you know the local node will assume that other remote node to be dead. 
	- Indexes
		- Description
			- Cassandra uses the clustering keys to create indexes of the data within a partition - note that these are only local indexes, not global indexes. If you have many clustering keys in order to achieve multiple different sort orders, Cassandra will denormalize the data such that it keeps two copies of it, slows down writes.
		- Okay indexes uh indexes are a really important part of you know ensuring fast read performance and it's something I've talked about on the past in this channel. The thing is though in terms of indexes, Cassandra does not let you do any Global secondary indexes. what does that mean? It means that there's like I said no index to quickly um filter based on say some column that isn't the primary key and do so in a way that it touches all partitions. Those indexes are local only which means they only apply to one partition at a time. So in order to do these, Cassandra is allowing you to index based on those clustering keys and so what it'll do is it'll sort internally. If you have multiple clustering Keys such that you know you want to keep multiple copies of the sorted data, Cassandra will actually denormalize the data and duplicate it on a given node such that um now you have two copies of the data sorted in two different ways. The one issue with this is even though reads are now going to be faster for that value of the clustering key, the issue here is that now writes are going to take longer because we're updating two copies of the data at once.
- ![[Screenshot 2024-10-04 at 10.29.12 AM.png]]
	- Use Cases for Cassandra
		- Description
			- WRITE HEAVY APPLICATIONS!!!
			- If data is generally self contained, and only needs to be fetched with other data from its partition.
			- Examples: sensor readings, chat messages, user activity tracking
		- Okay so now let's actually talk about the use cases for Cassandra because like I said there are sometimes where it's not always the perfect solution. There's no database that's always the right answer but Cassandra can be the right answer a lot of the time. So let's discuss when it is. Big thing as you can see I've got it written in all caps right here "write heavy applications." So if data is generally self-contained which you should be able to do because or I shouldn't say you should be able to do but if there's little relationships uh within each piece of data and you know you can kind of keep it all into one row and keep in mind Cassandra allows you to use pretty complex data structures in the rows like arrays and sets and all of these things. So if you can keep all the data to one row and rarely have any associations with things in another partition or another table and in addition it only needs to be generally fetched by itself, then Cassandra might be the solution for you. So what are examples of this? Things like sensor readings. You would use the same partition key for the same exact sensor and then all the readings from that sensor are going to be on the same partition and then perhaps you would use a clustering uh you know like an ordering key like a Timestamp so that you could order them quickly by time and then filter that way. Same goes for chat messages. Perhaps a partition key would be like the chat ID and then Timestamp of the message again in order to sort them properly. And then the same goes for user activity tracking. Use the user ID as the partition key and then again timestamp furthermore. So as you can see all of these applications right here where you're just taking in like a huge list of data and you're really just going to basically grab chunks of that list, it's really great for Cassandra and of course in any application there's inevitably going to be many databases used. So it's fine if for say you just want to use Cassandra for say like let's do Facebook Messenger. Cassandra for the messages but then you use a relational database for actually like the users and the members of a given chat. So you know you would have a chat ID that's specified somewhere in the relational table and then you would actually be holding all of the chat messages in something like Cassandra. That would be a great place to use it.
	- Cassandra Conclusion
		- Description
			- Great for write heavy applications for millions or even billions of users with performance as the main concern
				- See messaging, sensor readings, activity tracking
			- Main pitfalls are the lack of strong consistency, lack of ability to support data relationships (outside of sorting data in a given partition), lack of global secondary indexes
				- In these scenarios, we will need other options!
		- okay, so in conclusion Cassandra is really good for write heavy applications at massive scale. It can scale a lot because you can just add nodes and then the fact that they're using this Dynamo inspired design just allows you to go ahead and make more writes to different nodes. You've got anti-entropy in order to keep everything eventually consistent. So like I said, messaging, sensory readings, activity tracking, great. The pitfalls on the other hand are the lack of strong consistency. Yes you can always use Quorum reads and writes, however, the issue there is like I said even quorums themselves aren't strongly consistent due to race conditions and the fact that there's hinted handoff and the fact that sometimes um you know if you make a write to um like a quorum of nodes, but you don't actually hit that like Quorum threshold of nodes, then do we revert the right on the existing nodes that the writes exceeded on or not? So quorums aren't perfect, just keep that in mind even if you do want strong consistency here and then secondly obviously if you want to support things like one to many relationships and many to many relationships especially spanning multiple partitions, Cassandra is probably not going to be the thing for you. Then finally we also have a lack of global secondary indexes. So in some very specific read heavy applications, where you really want to be optimizing on read performance and say like a cache isn't going to work for you, then Cassandra probably isn't the move and we're going to have to examine other options for those.
		- Well guys like I said I hope um this video is useful I really hope that uh these like actual specific technology breakdowns are kind of the differentiator between my channel and other existing systems design videos because I just don't think they go in depth enough in terms of actual real world applications and I think that being able to know these things would really set you apart in a real systems design interview