---
Source:
  - https://www.youtube.com/watch?v=xTHPZo8xQlY
Reviewed: false
---
- ![[Screenshot 2024-10-04 at 10.46.58 AM.png]]
	-  Intro
		- hey everyone uh wow welcome to all the new subscribers yet again uh hope you guys are looking forward to learning some more crap about systems design. Today i'm gonna kind of rush this video through since uh i'm in a little bit of a rush to get some stuff done but i just got back from the gym, feeling kind of smelly so it's a perfect time in my perfect computer science mindset and mentality to make another video. I know i've kind of been working up to talking about more technologies and stuff like that. I think what i'm going to do is probably [[HBase]] next which is another type of database but in order to talk about that, i have to talk about one or two different types of technology and then we'll probably go and get to that HBase video so enjoy that. Let's get into this 
	- [[Coordination Services]] Background
		- Description
			- In clusters of nodes, there is often some shared state or configuration between them that all of the nodes should be aware of. This includes the IP address of the nodes in the cluster, partitions residing on each node, which nodes are alive and which are not, distributed locks, etc.
			- To solve this problem, and make it both reliable and consistent, many more complicated technologies have chosen to use existing coordination services within their tech stack (the most popular ones are [[ZooKeeper]] and [[Etcd]]).
			- Meant for read heavy workloads
		- okay so a coordination service what is it? Basically in any type of distributed system that has a cluster of nodes, there's some need to have some sort of shared state or information about the configuration of the cluster. That includes things like the ip addresses of nodes in this cluster which partitions are on each node, the nodes that are actually still members so which are alive and which might be down things like distributed locks that require some consensus or coordination for one node to be grabbing them and others can't, so you know obviously there's this kind of need for a centralized system where you're keeping information or like metadata about the cluster. So to solve this problem, things called coordination services have come up and if you've ever heard of things like zookeeper or Etcd, these are examples of them and so basically i'm going to talk about those this video. I'm not going to do like super specific like zookeeper specific or Etcd specific details. I might do that in the future but for now i'm just going to try and give a sense of how coordination services in general work and then we'll i guess kind of see in the future how those work inside of other systems. Generally speaking by the way these are meant for read heavy workloads so we'll see why that's relevant in a bit.
	- Coordination Services
		- Description
			- Highly available key-value stores built on top of a consensus layer. As a result, writes are slower than if there were no broadcasting mechanism (do not use as a general purpose database)
		- Okay so what is a coordination service well i kind of touched upon this in my Raft video but the point is they're just highly available and by highly available all that really means is that they're replicated key value stores or in the case of zookeeper it's kind of like a file system but files can have child files built on top of some sort of consensus layer which really just means that they share a replicated log by virtue of having to use a consensus mechanism like i don't know paxos, raft or zookeeper uses something called zab. Obviously writes are going to be pretty slow because they all have to go through the leader and they all have to touch at least a quorum of nodes in order to actually successfully write.
	- Reads in Coordination Services
		- Description
			- Thus far, we have mentioned that coordination services use consensus mechanisms for replication. However, in order to achieve high read throughput, coordination services by default are not actually strongly consistent (recall that having a replicated log itself is not enough to be strongly consistent).
			- So what guarantees do coordination services make about reads?
		- In terms of reads and coordination services, well you might think that hey oh the fact that we're using a consensus algorithm might mean that we're going to have strong consistency. Actually that's not the case because like i said these are for read heavy workloads like probably ten to one is what it says in the zookeeper documentation. So what that means is that if you're reading ten to one, generally strong consistency isn't going to be efficient enough. You probably need to deal with eventual consistency and then you know if you need to go and make that even more consistent such that you get strong consistency, zookeeper will allow you to do something like that but generally speaking what do coordination services actually tell you about their reads because you can read from any replica and there's no guarantee that the data is going to be up to date?
	- No Monotonic Reads
		- Description
			- Recall: A monotonic read is when a client makes a read, then reads from a less up to date replica and it appears as if time is moving backwards.
			- Coordination services can avoid this by using their replicated log:
				- Every time a client makes a read or write, it stores the ID of the last point in the replicated log that it has seen
				- Therefore, if it reads from a replica with a less up to date log than that ID, it knows to either wait until the replica gets more updates, or try a different replica to read from
		- well first of all there's no monotonic reads. Monotonic reads is a term that i introduced probably like 15 videos ago but if you recall a monotonic read is basically when a client makes a read from one replica, then reads from another replica and the second one is more outdated than the first and as a result it looks like time is going backwards. So obviously we can't be having any of that. We want a service to see reads actually going forwards in time and so you can avoid this by using the replicated log. Basically the fact that each server has a replicated log where the IDs are the same for each slot in the log means that if a client makes a read or a write to or from some replica it's going to get the last ID that it's seen, so you know it knows the length of the log on that replica and then from then on it's only going to accept reads as valid if the log kind of supporting that read if the log on the replica where it gets the read from is more up to date than that last ID that it saw.
	- Ensuring Predicate Validity
		- Description
			- Recall: A [[predicate]] is information that you read from a database before making some other read or write
			- In coordination services, you can attach a "watch" to any key that you read, making sure that a client will receive a notification informing it of the fact that the read was outdated (kind of similar approach to serializable snapshot isolation)
		- okay, additionally these coordination services can ensure predicate validity. So basically what this means is uh predicate is also another term i've used in the past so if you want to recall. A predicate is basically just information that you might read from a database before making some other read or write. So you say you know for example i'm a doctor and I want to go off my shift but i can only do so if there's another doctor currently in the room. I'm going to read to see if there are other doctors in the room from my database table and if there are i can leave. But what if that predicate is no longer valid. It's important to be able to make sure that you know things are actually still the case that you thought they were before making some sort of change to a system. So in coordination services in particular, you can attach something called a watch to any key that you read or i guess any file or file name and what that's going to do is the replica is going to keep track of that watch and say okay if this file has actually been changed before that transaction is finished up, the client is going to receive some sort of notification probably through some stream of events that the file was changed and that way it can either retry that read write operation or it can just keep that in mind. That's actually kind of a similar approach to serializable snapshot isolation which if you remember is just like the database will keep track of almost the dependencies of every single read and write and if one of those dependencies becomes outdated, it'll have to cancel the write and do it again and that's like an optimistic concurrency control type of thing.
- ![[Screenshot 2024-10-04 at 11.54.18 AM.png]]
	- Strong Consistency
		- Description
			- While by default coordination services do not provide strong consistency, you can modify reads so that they become strongly consistent.
				- Read from the leader
				- Sync
				- Quorum Reads?
					- Interesting area of research but not completely perfect
		- okay, so what if we do need strong consistency because a lot of the times you know you really don't want to be for example say we're talking about the ip addresses of the nodes. Maybe it's unacceptable to you know be sending write requests to the wrong ip address and just getting no response. Perhaps we want strong consistency and to ensure that one client can read another client's writes pretty much instantly. Well how can we do this? There are three ways in these coordination services and i will talk about all three of them. The first and the most simple is just reading from the leader. So obviously that's always doable but it's got a couple of issues with it. For starters, the leader is already pretty bogged down by the fact that all the write operations are going through it and it has to handle the fact that it's communicating with all of the other nodes in the cluster. Remember that for every single write you need to hit a majority of nodes. So the leader is sending out tons of network data and the fact that now you're going to be hitting it with reads too is a lot to handle. It's really going to slow things down. Another thing is to use an operation called sync which i'll touch upon in the next slide and then this is kind of more of an upcoming research area but we'll talk about it a little bit are the concept of quorum reads.
	- Sync
		- Description
			- From a client node, write the command "sync" into the replicated log in order to get the current up to date ID of the last position in the log
			- Make a read from any replica
			- The replica will only be allowed to return data to the client if the sync has been propagated into its log
		- okay so what is sync? A client node will basically go ahead and write the command sync into the replicated log. So sync is not any sort of key value but it does take a position in the replicated log. Well what does that do? As i said, every single time you write and the leader responds back to you saying hey you just had a successful write, it'll also respond with the ID of what you just wrote in the log, so you know the position of your write in the log. So once i have the position of that sync, any replica that i'm going to read from recall because there's only monotonic reads allowed, it means that basically you're only going to be getting reads from replicas that have that sync included in their log. So it's basically saying every single time you write a sync, I will now only be reading from this point onwards. There's that. That's one way of doing things. 
	- Quorum Reads
		- Description
			- Note that in both of these scenarios, we are putting excess load on the leader, what if we just want to be able to get up to date reads from the replicas?
			- Recall: Replicated consensus algorithms require a majority of nodes to accept a write, so reading from a majority of nodes should have at least one node with the most up to date write
		- And then the other way is quorum reads. So in both of these scenarios keep in mind we're putting a ton of load on the leader. If you're reading from the leader well obviously you're putting a load on the leader and if you're using sync it means you're doing another write which means that you're putting even more load on the leader because the leader has to communicate with all these other replicas but what if we just wanted to be able to get up to reads from the replicas alone? Well this might actually be possible. So the first thing to recall is that all of these replicated consensus algorithms require a quorum of nodes in order to accept and eventually commit a write. So what that means is that if i am to read from a quorum of nodes, I should be able to get an up-to-date value basically for any key. However that's not necessarily true so let's look at this following race condition.
	- Quorum Reads Continued
		- Description
			- However, even these are not perfect - see the following race condition.
			- In this case, the leader (R1) sees that replicas 2 and 3 have accepted the write for x=4, so it goes and commits x=4 locally and tells R2 and R3 to commit x=4. However, our quorum read comes in before they commit x=4, and so we get both replicas saying x=3. We can see that there is a newer uncommitted entry on these replicas that will overwrite the value and try the read again, but there is no guarantee x=4 will be committed by then next time.
		- imagine i have the three nodes right here and as you can see the leader is the first one and then i'm going to be reading from the other two and the other two comprise a quorum because it's two out of the three nodes. So the way that these consensus algorithms work basically is let's look at the operation x = 4. As you can see all of the replicas have accepted x = 4 so the leader knows it can go ahead and commit x = 4. So what it first does is it commits x = 4 locally and then it's going to go ahead and say okay guys i'm now going to tell you to commit them. However this creates a race condition. It means there's a point of time where the leader has committed x = 4 but the other two replicas have yet to receive that network call and as a result they have not committed x = 4. So now if i read from those other two nodes which do technically comprise a majority, even though eventually they will have x = 4, at the moment it still looks like x = 3 is the most up-to-date value even though if we read the leader, we would see that's not the case. The one way we can kind of rectify this is by looking at those write ahead logs and saying oh i see that there's another value here in the write ahead log and you know x = 3 is probably going to be overwritten so we can retry our quorum read but there's no guarantee that retrying the quorum read is going to get us the most up-to-date value simply by virtue of the fact that hey maybe the the leader crashed after it committed locally and wasn't able to send the commits out to everyone else. Maybe there's a network partition between them so the leader can no longer reach these other nodes so there's just a variety of issues in terms of uh you know quorum reads not being exactly perfect but um studies have shown or some research has shown that they can take a significant amount of load off the leader and in certain situations greatly increase read performance. So it is something to i guess consider in the back your head. Maybe research here will improve a little bit and these quorum reads will get even better 
- ![[Screenshot 2024-10-04 at 11.55.43 AM.png]]
	- Coordination Services Conclusion
		- Description
			- Coordination services act as a very important subcomponent of many modern day data storage systems. Unlike gossip protocols which pass information directly from node to node, they use a centralized, replicated key value store built on top of a consensus algorithm
			- While coordination services are not built to handle strong consistency out of the box, there are some way of achieving strongly consistent reads, at the cost of significantly reduced performance.
		- okay in conclusion coordination services are a really important sub-component of a ton of modern day data storage systems. Unlike gossip protocols which i introduced in a previous video which basically have nodes randomly pass information from one to the other until it's propagated through the system, coordination services are a way of storing the data in a centralized location which is obviously replicated for fault tolerance and uses a consensus algorithm to ensure things like atomicity and a total ordering of the writes so that things never get completely out of whack. Even though coordination services don't handle strong consistency right out of the box because that would be too big of a performance hit for things like reads. You want to be able to scale reads linearly with the number of nodes in the system, there are ways of achieving strongly consistent reads that are built into the system still like that sync command, you can always just read from the leader and again keep in mind that quorum reads might eventually be a viable thing that a lot of people end up using. However another thing to note about strong consistency and this is always the case is that to achieve strong consistency, it is at the cost of significantly reduced performance.
		- Okay so i hope this makes sense for coordination services. Coordination services are something that we see used in literally a ton of other database technologies and so i think it's important that we introduce them now so you can see where they come up as useful later. All right have a good one guys