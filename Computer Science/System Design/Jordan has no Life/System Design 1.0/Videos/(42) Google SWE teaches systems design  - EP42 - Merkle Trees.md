---
Source:
  - https://www.youtube.com/watch?v=FaTB91EQGzM
---
- ![[Screenshot 2024-11-13 at 7.47.38 PM.png]]
	- Introduction
		- Today we're going to be talking about Angela [[Merkle trees]] aka merkle trees. They're not actually named after her. So let's go ahead and get into that because I want to get myself to the gym. 
	- Merkle Trees (Background)
		- Description
			- Merkle trees are an algorithm that we have brushed over a few times now - it is extremely useful for efficiently calculated the differences between sets of data or files, and determining where they differ in logarithmic time (as opposed to linear time).
			- Like Bloom filters, they heavily rely on hashing for their good performance, and we can see them being used in the Git revision system, anti entropy processes in leaderless databases, and also in blockchain/decentralized currencies.
		- Okay, so Merkle trees. What are they? Merkle trees are really just an algorithm that easily allows you to compute uh basically a set of differences over two similar sets of records. They do this really quickly and efficiently using basically something known as a hash tree and what this goes ahead and is really useful for are things like a git version control system or an anti-entropy process in some sort of leaderless database like Cassandra or DynamoDB and also in blockchain or decentralized currencies. Basically anytime you need to calculate the difference between two things and ultimately attempt to rectify them by sending some changes over a network, a Merkle tree is extremely useful for allowing you to calculate the smallest unit of difference between two sets of records. 
	- Merkle Tree Basic Algorithm
		- So let's look at the basic algorithm for a merkle tree. So we have these four files here a, b, c, and d and the first thing we're going to do is go ahead and calculate some hashes for them and these are going to be the leaf nodes in our tree. So i'm going to put these leaf nodes down here and now every single parent node of any node is going to basically incorporate the two hashes into its own hash and go ahead and use that. So basically to get the hashes of the parent node, I would say concatenate those two strings of each child node and then go ahead and take the hash of that. We would do the same thing all the way up to the root. 
	- Merkle Tree Basic Algorithm
		- Now imagine i wanted to make a change to one of the files, so i'm going to change c.txt. So you can see that the hash of c.txt has changed thus changing that leaf node, thus changing the parent node and ultimately changing the root. So now after i make that change, if i want to go ahead and compare the previous merkle tree with the current merkle tree to kind of see what file actually changed, I would do the following. 
	- Merkle Tree Comparison
		- Description
			- Start from the root, and traverse depth first finding differences in the hashes!
		- I would go ahead and look at these two, I would say okay well the roots different so i know that i have a difference between them somewhere, I'm going to have to traverse that. Then i would say, okay, the right node or the right child of the root is different, so i'm going to have to traverse the right path and then ultimately that child of `93pq` versus `4w12` is different and so that's where the differences lie between the two.
- ![[Screenshot 2024-11-13 at 7.56.10 PM.png]]
	- Merkle Tree Comparison
		- And so you know if i wanted to kind of propagate that change over the network now as opposed to having to propagate every single file and go ahead and do this kind of naive implementation where we waste a ton of network bandwidth, I can only go ahead and propagate the change file and even still there are optimizations to be made even beyond that where you basically only propagate the differences of the file and that's kind of what git does where you know you have the original file but then git calculates the diffs and then the diffs are propagated over the network but you use the merkle tree to actually go ahead and calculate where the diffs are in the first place. 
	- Merkle Trees in Git
		- Description
			- The way Merkle Trees are presented above means that they throw out all of the old hashes of files/chunks, but in Git we want persistence so that we can inspect old commits:
				- To fix this, each change to a file is treated as a separate file and hashed
					- If the hash is already in the merkle tree, nothing changes (good for file metadata changes)
					- If it is a new hash, add it as a leaf to the merkle tree and create a new branch/copy of the path from root to leaf
					- To go back in time to old commit, just start from the root hash of that commit
		- Okay, so how do merkle trees actually work in git. Well it's a little bit different than what i just showed in the sense that git is a versioning system which means that we want to be able to look at old commits as well as opposed to just seeing the updated merkle tree of any state because it's important to be able to kind of go back in time. So in order to do this, what we actually do is every single file that gets changed, almost gets treated like its own file and we go ahead and take the hash of it. So if the hash is in the merkle tree, even if it's under a different name like it has some different metadata, we just go ahead and don't change anything and you know that's efficient but if there is a new hash, then what we go ahead and do is instead of modifying the old hash that it corresponds to, we go ahead and add it as a leaf to the merkle tree and then create this entirely new branch of that merkle tree and ultimately go up and propagate those changes all the way to the root. However, the new root that we're creating and all those new intermediate nodes that we're creating are all going to be copies. We're not actually modifying the old merkle tree and what that means is that if we're to use an old pointer to a root uh representing an old commit, we can still go ahead and access those old hashes to the files and go ahead and retrieve the prior versions of those files. 
	- Merkle Trees in Cassandra
		- Description
			- Recall: Anti-entropy is the background process of making sure that all replicas are consistent in a multi-master replication schema.
			- Cassandra uses Merkle trees for this! But wait, isn't the data always changing? How can we be sure that the changes that one replica sends to another will still be valid by the time they travel over the network?
		- Okay, in Cassandra we have anti-entropy. So merkle trees are really useful for basically going ahead and determining the differences between two replicas as a result determining you know the basically the smallest unit of change that can be sent over the network and then doing so in order to ensure that they are eventually consistent with one another. However, if you think about this for a second, there's a little bit of an issue. Isn't the data actually always going to be changing. So as a result, you might go ahead and perform anti-entropy and by the time the data gets there, it's already stale so that could be the case. However Cassandra actually does this anti-entropy process not on the raw data itself, not on the keys and values, but instead on those immutable SSTable files that are part of Cassandra's LSM tree based architecture. 
	- Incremental Read Repair
		- Description
			- Recall: Cassandra uses immutable SSTable files. Hence, two replicas can easily perform comparison and anti-entropy in order to do this! In order to decrease duplicate data from being sent over the network, repaired SSTable files are marked as repaired, whereas ones that have not been marked as repaired are marked as unrepaired
				- Incremental read repair allows us to send less data over the network, because the Merkle Trees are smaller!
				- In order to avoid having to repair SSTables that have already gone through the anti-entropy process, we separately compact repaired tables and unrepaired tables! (Size tiered compaction)
		- So this is something known as incremental read repair. Basically Cassandra uses immutable SSTable files and as a result if two replicas have kind of these similar SSTable files and they have yet to be repaired, we can basically just go ahead and repair an SSTable file once because we know that once all of those replicas have agreed on the SSTable file, the fact that it's immutable means there will be no further changes to it and as a result we're not going to have to perform anti-entropy multiple times per the SSTable. So as a result, we can start marking off all of these SSTables as repaired and then once they've been repaired, we can go ahead and compact them in the background because we're gonna get you know consistency between all of these replicas. So instead, what we actually do is instead of sending an entire merkle tree that represents the contents of every single SSTable, we do this incremental read repair where we're sending these smaller merkle trees over the network only representing the contents of these unrepaired SSTables and as a result of that, we've lowered the overhead and the the network bandwidth and I/O that needs to be used so this makes everything more efficient. Another thing that has to happen here as a result of having these two types of SSTables both unrepaired and repaired is the compaction process between them kind of needs to be separated. For example, if we have a bunch of repaired SSTables, and then we were to go ahead and kind of perform log compaction and merge those in with a bunch of unrepaired SSTables, well then we would have all these keys uh mixed into our previously repaired SSTable that now perhaps may not be valid. So now we're going to have to perform anti-entropy all over again on something that we've already performed anti-entropy on. So the way the Cassandra tries to mitigate this problem which is pretty smart is that it has two types of compaction. Basically you can compact unrepaired SSTables with one another and you can compact repaired SSTables with one another and by doing this, we make sure that we're never performing duplicate anti-entropy by making sure that basically once an SSTable has been repaired, that data is never going to be sent in a merkle tree over the network again. 
- ![[Screenshot 2024-11-13 at 8.02.27 PM.png]]
	- Conclusion
		- Description
			- Merkle trees are a very clever way of detecting the differences between large sets of records by using a logarithmic tree of hashes. They are extremely applicable in multiple areas of system design, such as detecting the differences in files, as well as finding the smallest units of difference in order to propagate them over the network, such as in anti-entropy.
		- Okay, so in conclusion, merkle trees are a really cool way of detecting the differences between two sets of records using a hash tree. So obviously we can kind of detect those differences in logarithmic time by basically just going ahead and traversing down the tree. Once we've figured out those differences, it allows us to kind of send that minimal unit of you know file diffs over the network and it greatly makes things a lot more efficient. We can see these come up in a decent amount of system design problems such as you know git revision control systems and in addition anti-entropy or blockchain. Even though i'm not going to talk about the applications of merkle trees in blockchain at the moment, I am planning on doing some sort of blockchain or DeFi video in the future and hopefully we'll be able to kind of see how merkle trees come into play then.