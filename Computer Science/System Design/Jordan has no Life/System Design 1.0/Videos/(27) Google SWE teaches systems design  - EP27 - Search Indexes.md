---
Source:
  - https://www.youtube.com/watch?v=DTUSFVfjRQA
---
trac- ![[Screenshot 2024-10-10 at 5.04.45 PM.png]]
	- Intro
		- alrighty i am back. I'm gonna be a little bit behind schedule today just because my roommate would not leave bed all day and now i can finally record now that he's gone so uh we're gonna talk about search indexes which are a pretty important part of any large-scale company they pretty much all use them in one sense or another so i'll talk about the internals of those how they work and then we can get through this video and on to the next  
	- Search Indexes Background
		- Description
			- In most website, there is some functionality involving open ended search queries - see Google's search engine, searching for products on Amazon, searching Twitter for posts matching keywords, etc.
			- Generally speaking, in order to optimize for these types of use cases, which can be a very intense query (since we many have to scan through millions or more documents), it can be helpful to use a search index!
		- Alrighty search indexes what are they? Well a lot of companies have some sort of search functionality embedded in their application at one point or another. I mean if you're just taking Google for example, it's pretty much their entire business. Amazon has the ability to search for products based on a bunch of different filters and you know you can do the same on twitter for posts matching certain keywords but generally speaking databases aren't great for these search functionalities. Generally we want to use a different type of data structure or technology in general in order to optimize for search functionality and make it such that these very complex queries can actually run really quickly 
	- Lucene
		- Description
			- The most popular open source search index
			- Created in 1999
			- The index behind popular search services such as [[ElasticSearch]] and [[Solr]]
		- So what is Lucene? Lucene is what's known as a search index and it's probably the most popular one. It's been around since 1999 and it's been open sourced under the apache license. The actual search companies that people tend to use which are, you know, ElasticSearch and Solr use Lucene under the hood and as a result of that, I'm going to first explain Lucene, and then i'll go into ElasticSearch and kind of how it builds on that
	- Lucene Architecture
		- Description
			- Lucene is in part highly performant because it uses an LSM tree + SSTable for its format:
				- Writes first sent to an in memory buffer
					- Cannot be read just yet, need to be on disk first
				- Eventually the buffer is written to an immutable SSTable index file on disk
				- As SSTable files get larger, they are eventually merged and compacted with other SSTable files
				- Reads are sent to multiple SSTable files, and the results from them eventually need to be merged.
		- So let's talk about the architecture of Lucene. Generally speaking, it uses an LSM tree and SSTable architecture and that's one of the ways that it remains highly performant. So obviously first writes are going to be sent to an in-memory buffer. The one difference here which is a little bit nuanced for Lucene is that once the writes are sent to that buffer, you still can't read them just yet. They have to actually be propagated to the disk first and in Lucene this tends to happen once every second. It's called like a refresh period. So eventually the buffer is going to get written to an immutable SSTable index file and then once there are a bunch of SSTable index files, those are going to get compacted and merged together which is pretty typical for what we've seen. And then in terms of reads, reads actually have to be potentially sent to multiple SSTable files because each SSTable is kind of covering a different set of documents and then once you get the result of those reads, you're going to go ahead and merge them.
	- Lucene Architecture Continued
		- Description
			- When a document is first added to a Lucene index, it must be split into terms (this process is known as tokenizing):
				- The way that a document is tokenized has serious implications for how we may query it later
					- Handling punctuation
					- Handling case
					- Handling contractions
					- Handling common words like "the" or "and"
					- These are all problems that occur in natural language processing as well
		- okay, so let's actually go ahead and continue talking about this Lucene architecture because the SSTable part is only one aspect of it. So what actually happens when a document is added to Lucene? Well it has to be tokenized which means that you're taking all of the words or the terms in the document and splitting them apart based on some sort of rule. Typically you're just splitting based on the white space but then there are a few nuances as well in terms of how we actually want to handle the document because we don't want to be mapping it to a bunch of terms that don't really apply or that we don't care about. So obviously we have to handle the punctuation, we have to handle you know the case of words. Maybe it'd be better if we just treated all words if they were lowercase. Handling contractions such as like "it's" or "they're". Then also handling common words like "the" or "and". Maybe we don't really care about queries on these and we would rather just filter them out. These are all also problems that occur in natural language processing but just tokenizing in general obviously you want to be conscious of how you're actually doing that because you want to be able to search for these terms later and you know if there are nuances within the terms themselves, you just have to think about you know how am i actually going to be tokenizing this document  
- Image
	- Lucene Architecture Continued
		- Description
			- After being tokenized, the document is given an ID, and added to something called the inverted index, which maps terms to document IDs that contain them. Note that since these are on SSTables, they are sorted by term
		- Okay, so here's kind of the bread and butter of a search index and this is called an inverse index. So inverse indexes work by basically doing the following. Once the document has been tokenized, we know that now it applies to a list of terms. So instead of mapping a document ID to a list of terms, what we actually do instead is take each term and map it to a list of document IDs that contain it. Like i said, this is known as the inverted index and these are what the SSTable files are generally containing. So that means that they're going to be sorted by term by the way.
	- Lucene Architecture Continued
		- Description
			- What if we want to be able to go beyond finding just the term itself, and say also be able to get documents based on a similar query string?
		- But what if we want to just go beyond looking at just one term itself and say you know get all the terms with a prefix of "pe" in this case.  So let's start by finding all the documents with those terms or at least the terms that have that prefix and in order to do so, we can just run a binary search on this sorted table, and the way you would probably do this is do two binary searches where one gets the upper bound so "p-e-e" in this case then one gets the lower bound "p-e-n". So you know, that's how you would go ahead and do that and that way we can kind of find all the documents matching this prefix in log(n) time. 
	- Lucene Arcitecture 
- but generally speaking if we want to just do searches that are more complicated than just by term prefix we have to add some additional logic and here a couple of examples of that what if we wanted to search by term suffix so for example instead of searching by p e we wanted to search for all terms with e n well what we could actually do here is create a second modified index where instead of storing the terms themselves in the inverse index you store the reversed characters of the term so that way you can basically do the same prefix searching logic but just with the suffix and you go ahead and reverse that and then run your binary search another thing that's kind of similar is doing this with numeric terms where you actually look at kind of the the digits of the number itself and that way you can kind of say like oh you know like let's look at the number 120 123 well they're kind of similar because um there's actually or i don't know maybe like it's the fact that they basically have a bunch of digits in common in the same places and at the same start but i think actually in reality lucian does use a different data structure for things like numbers and geospatial data so maybe that's the topic for another video but ultimately the whole point here is that lucian can do a lot of really cool search functionality and it's not just on text but like i said numbers you can do text searching of similar words using something called levenstein distance which is you know done via some dynamic programming algorithm and then also on geolocation data which is a topic i will cover in another video  okay so what is elasticsearch well elasticsearch is basically taking leucine and scaling it across a multi-node cluster so the way that we do this obviously is going to be through some combination of replication and partitioning so we do have replication where each uh thing that's being replicated is an actual individual leucine index over a bunch of documents but also we have partitioning as well so each index um you know can be sent to certain nodes in the cluster and then other index might be sent to different nodes in the cluster and it's kind of in this way that the data set is divided up um so in that way elasticsearch basically creates a bunch of local inverted indexes keep in mind these are not global inverted indexes it's not like every single term or for a given term we have every single document id of it and then that index is term partitioned but rather it's document partitioned meaning that the index that's held on a given node is only relevant for the documents on that actual node so if you think about it this has you know obviously its advantages and disadvantages it means that if you want to search for terms across multiple shards then you're actually going to have to reach out to all of those shards and merge together those results but it also means that say we're you know trying to implement a search function on like a log functionality if we put all of those log entries from the same day on the same chart then we can really quickly go ahead and make rights to that shard and in addition to that query it super easily  another huge benefit of elasticsearch over just like plain old blue scene is that it implements caching really well and this is kind of how it achieves such fast performance so not only is there just like operating system caching of index pages in memory so if you think about it an ss table is just a page on disk and um you know the way that operating systems work is they actually will tend to cache frequent disk accesses so that way they can speed up the actual you know accessing of the index itself but in addition to that elasticsearch builds some functionality on top of that where for a query on a given shard basically it'll go ahead and cache the result of that so you're not just caching the index itself but say any logic that you're doing with the index or you know anything that you're adding on top of that in the event that you're going to end up doing that query again and then furthermore in addition to just caching the result of the query um elasticsearch will actually kind of cache components of each query so that you know if a separate query were to come along later for a given shard and try and reuse some of that data then you know this could go ahead and be really useful and you know if there are parts of the queries that kind of intersect we already have that in our cache so it's kind of in this sense that elasticsearch is able to achieve really high read throughput  okay ultimately search indexes are a super important part of many large applications and it means that they can basically find strings of text in a manner that's much faster than just a traditional scan over a database and kind of you know using substring logic to try and find the actual string itself using ss tables in conjunction with an inverted index turned out to be a really good strategy for building a fast search index and through you know technologies such as elasticsearch and solar people have been able to go ahead and scale out lucine in a manner such that it works in a distributed environment which is really great also i'm really happy that i made this video because i personally have looked like a bozo in the past when bringing up search indexes and then not knowing about exactly how they were implemented and then i felt like a real so hopefully you guys don't make the same mistake and i will be seeing you guys in the next one
