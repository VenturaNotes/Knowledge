---
Source:
  - https://www.youtube.com/watch?v=fQvSKpeABxQ
---
- ![[Screenshot 2024-11-11 at 8.14.37 PM.png]]
	- Introduction
		- But okay, actually though let's talk about the video for today which is going to be [[chain replication]]. Fun fact the guy who actually wrote this paper was my operating systems professor which is pretty sweet. But uh yeah let's talk about his work.
	- Chain Replication (Background)
		- Description
			- Invented in 2004, chain replication is a very interesting way to achieve both strong consistency as well as availability, while still maintaining decently high throughput!
			- It can be modified, using ideas from the CRAQ paper, in order to provide even better read throughput
		- Okay, chain replication so what is it. Unlike some of the other replication schemes that we've spoken about, um in 2004, the original paper for chain replication came out and basically said here's a way that we're going to achieve both strong consistency and high availability while maintaining pretty high throughput. Then there's kind of the subsequent paper that came out called CRAQ and basically that even provides more read throughput so i'm going to go through how all of these processes work. 
	- Chain Replication Writes
		- Description
			- Client $\to$ Head, Replica, Replica, Tail
				- (1) Client performs write to head of the list
				- (2) Write is passed through the chain of replicas until it reaches the tail
				- (3) Acknowledgements passed back from the tail all the way to the head
				- (4) One head receives the acknowledgement, it alerts client that write was successful
		- So for starters, let's talk about chain replication writes. Imagine we have this kind of chain of database nodes, right? So we have a head, two replicas, and a tail. And then we have a client and what the client does is it goes and first writes to the head of the list. The head is then going to propagate those writes such that the head passes to the first replica, first replica passes to the second replica, the second replica passes to the tail which is the last node in that list. Once the tail receives the write, it's going to go ahead and acknowledge that message, and pass it back through the chain. So as you can see now, we have a chain of acknowledgements going back through those replicas. Once the head receives the acknowledgement for that write, it's going to go back to the client and say, good job, the write was successful. It's propagated through the chain. 
- ![[Screenshot 2024-11-11 at 8.50.43 PM.png]]
	- Chain Replication Reads
		- Description
			- All reads are made from the tail, which ensures strong consistency! Recall that all writes are acknowledge as successful once they reach the tail node and propagate back, so the tail should have up to date data!
		- Okay, in terms of reads, all reads are actually going to be made from the tail, and so this is kind of the unique part of chain replication that ensures strong consistency. Remember that the second a client hears that it's write is successful or committed, it means that that write is actually in the tail so by reading from the tail, we can see only up-to-date data. 
	- Chain Replication Failover
		- Description
			- A chain replication schema generally uses an external coordination service (using some sort of fault tolerant consensus algorithm) to detect node failures:
				- If a head is believed to have failed, promote the next replica to head
					- May lead to some lost uncommitted writes from the head
				- If the tail is believed to have failed, start executing reads from the replica behind it in the list
				- If any middle node has failed, remove it from the chain
					- Requires each node keeping track of which writes that it has processed so that the node behind the failed middle node can update the crashed node's successor
		- Okay, so let's talk about failover because i mentioned that this schema was particularly high availability. Well, why is that? Generally speaking, we're not using something like a gossip protocol here because that has all sorts of potential issues where you know if two links can't communicate with each other, one might think that the other's down and the other might think you know the first is down and then the chain becomes completely babbled so what you do is you use an external coordination service like zookeeper which we've discussed in the past that uses some sort of consensus algorithm to determine which nodes are running and which nodes are not running. So anyways, here's what happens in certain failure scenarios. If a head fails, then you go ahead and just promote the head's next node to the head because that's going to have pretty much all the writes that the head had. It may have some uncommitted ones, but it's not a big deal if uncommitted writes are lost because the client never received an acknowledged message for that. If the tail has failed,  then we're going to go ahead and start executing reads from the replica right before the tail so that works well because again that should have all the writes that the tail had because it's quite literally giving them to the tail so we're not losing any data and then if any middle node has failed basically we would do the same thing that we might do in terms of removing a node from a linked list and we would just go ahead and have to kind of remove it from the chain and you know take each adjacent replica and make sure that the chain is put back together and then pass the write from the left replica to the right one and make sure everything is updated.
	- Chain Replication Analysis
		- Description
			- Pros:
				- Strong consistency/linearizability achieved through a total ordering of writes
				- Writes less expensive than single leader replication because head only has to replicate them to one node, as opposed to potentially many (same happens in consensus algorithms)
			- Cons:
				- Read throughput is limited to just one node (unless sharded)
				- One slow node in the chain can cripple write speeds (still not very fault tolerant, even if the node will eventually be removed from the chain)
		- okay, in terms of the analysis of chain replication and how it's good and how it's not so great, it's really strong or amazing that there is strong consistency and linear linearizability in this type of replication schema. We have a total ordering of writes. Everything is eventually going to be reaching the tail in some specified order which is great. Additionally writes are going to be less expensive in single leader replication. This is because even though every single write goes to the head and kind of in the same sense every single write goes to the leader in single leader replication, the leader in single leader replication is sending all of those writes to every single replica whereas in chain replication, there's only one write being sent from the head at a time so you know those operations are actually less expensive, we're less likely to overload the head node. And then also if we're looking at raft or paxos, kind of the same deal happens where you have that leader and it's sending out a bunch of network calls at the same time. The biggest con is obviously the read throughput is limited to just one node. I put unless sharded here on the slide and that's because you know if we have multiple chains for each partition so you know one chain per partition, then you can actually increase read throughput but even still you know you can't just say oh we have the same type of data being served from you know these two chains. That doesn't work. Basically if you want to serve some data, you're limited to one chain for it and as a result, you're limited to the read throughput of just the tail node. And then additionally, it's very easy to have bottlenecks meaning that one slow node in the chain is going to slow down the entire process of writes because writes have to go through every single replica.
- ![[Screenshot 2024-11-11 at 8.53.52 PM.png]]
	- [[CRAQ]]
		- Description
			- Modification of chain replication to increase read throughput while ensuring strong consistency!
				- (1) System starts in a consistent state
				- (2) Client performs write key: Jordan, value: hot
		- Okay, now let's talk about CRAQ. So CRAQ is kind of a modification to chain replication that allows you to achieve much higher read throughput by taking reads from any of the replicase So how can we actually do that? Well, let's imagine first that we have this kind of chain replication set up right here and then it's going to start in a consistent state. So everything that you see right here, every replica has the key Jordan and the value sexy and right now, see look at 1 and clean. 1 is known as the version number and clean i'll describe in a second. So let's imagine now that i perform a write. Now instead of Jordan being sexy, he's hot. So the head is going to take this write and it's going to increment the version number and it's going to put the parameter dirty next to it. Dirty basically means that the write has yet to be acknowledged. So it hasn't received the acknowledgement back from the next replica hence this is considered a dirty write and we'll see what that kind of means for the future. Okay so now we're going to go ahead and propagate that write through and all the replicas are going to have dirty as their state for um you know version number two. Until the write eventually reaches the tail node. The tail node can't have any dirty writes because it's supposed to be the source of truth. So it goes and overwrites the clean key which was sexy and now has version 2 for hot. It's going to start sending back acknowledgements now and as the acknowledgements go through every single replica, they're going to say okay now i can finally label hot as clean and as a result since this key is now clean or rather the key value pair is clean, I can go ahead and get rid of the older versions of that. So now replica 3 is going to say "hot 2 clean", replica 2 has "hot 2 clean", replica 1 has "hot to clean". Okay great so that all makes sense but how do we actually do reads. How does this increase read throughput. 
- ![[Screenshot 2024-11-11 at 9.09.49 PM.png]]
	- CRAQ
		- Description
			- Reads: If read(k) goes to a replica where the highest version number available of key k has a clean label, the replica can safely return the corresponding value!
			- Real(Jordan) from replica 2 = hot
		- Well, there are basically two possible scenarios. So imagine we're trying to read a key and that's going to go to a replica where the highest version number available of the key is clean and basically so as you can see since we're in a consistent state here, "hot 2 clean" is the same amongst all replicas, so it means that you know say the read went to this second replica here, it's guaranteed that it's going to return hot and we know that um that's the state that the tail has because it's labeled as clean. 
	- CRAQ
		- Description
			- Reads: If read(k) goes to a replica where the highest version number available of key k has dirty label, the replica must first ask the tail what the current version number of the key is, and then respond accordingly.
			- Read(Jordan) from replica 2 = hot
			- Note: Can't just return the highest clean value from each replica as it is possible the tail has committed the dirty value and the replica hasn't yet received an acknowledgement!
		- However, what if i went and made the write `thicc` and it got to the second replica and then we tried to read from the second replica. Well, something now is going to happen. The second replica is going to say oh shoot, now i realize that `thicc` is actually a dirty write and as a result of that i have to reach out to the tail to see what the greatest value of the current clean write is in order to go ahead and return that. So it's going to go ahead and contact the tail node and what's going to happen is the tail node says oh actually the highest version i currently have says that the value is hot, so the replica is going to say, okay i'm just going to return hot. Now you might say to yourself here, oh well just looking at this, why can't we just return the clean write? Well we can't return the clean write because it's possible that `thicc` did actually get written on tail, however the acknowledgement just hasn't been sent back to the replica yet and as a result of that, then we would return hot too and you know that thinking that was the right value, when in reality the tail had already processed the write `thicc`. So ultimately, it is important that we actually end up reaching out to the tail to get the proper version number. 
	- CRAQ Evaluated
		- Description
			- In mostly read heavy workloads, the majority of reads will be clean and as a result read throughput should be scaled linearly to the number of replicas!
			- Even if there are a lot of writes, this can still improve read performance because the tail just returning version numbers is likely less expensive over the network than returning the full value of a key (especially if we are storing things like large files).
			- Ultimately, CRAQ still suffers from the same problems as chain replication in a single node acting as a bottleneck for the whole chain.
		- Okay, so in terms of the evaluation of CRAQ or the analysis, in read-heavy workloads, this is actually going to be super useful. The majority of the reads are going to be clean and as a result, the read throughput should scale almost linearly to the number of replicas. If there are a ton of writes, well, we're going to have a lot more dirty reads and eventually have to contact the tail mode much more. That being said, we would have been contacting the tail node every single time anyway and this still does take some load off the tail node because instead of sending back a potentially super large file over the network to the client, the tail node just sends a version number back to another replica which it's probably closer in proximity to and the version number is going to be smaller than potentially a large file. So even though CRAQ still does suffer from the same problems as chain replication in terms of one node potentially acting as a bottleneck, using this allows for pretty high read throughputs in a chain replication scheme as well as still the ability to maintain strong consistency. 
	- Chain Replication Conclusion
		- Description
			- Chain replication is interesting in that it allows strong consistency while also displaying some degree of fault tolerance. While it is not the fastest replication scheme, it successfully reduces a lot of load on each node in the schema by limiting the amount of network calls that they make. CRAQ is a very interesting modification to chain replication that significantly increases write throughput!
			- Ultimately, it probably will not be overly useful to know about chain replication in a systems design interview, but you will look smart if you can mention it if strong consistency ever comes up!
		- Okay, so in conclusion, it's pretty cool that we finally discovered like a high availability strongly consistent replication schema that can achieve relatively you know high throughput. That being said, um you know it isn't used a ton in practice but there are some systems that use it. I think Amazon still ends up using it in something called [[Aurora]], but even though it's probably not the most useful thing to know about chain replication in something like a systems design interview, I think that it might very much impress your interviewer if you're able to kind of bring up chain replication as an option, you know if you ever might need strong consistency. Obviously one way to do strong consistency is to deal with um you know something like a consensus algorithm like paxos or raft and then you know just use sync commands in order to achieve strong consistency or you know putting your reads in the log. However again that really overloads that one leader node and in comparison chain replication kind of spreads out that load and so it's interesting to kind of have that discussion. Anyways, guys, I know this video was kind of short. I hope it was useful though and i think i'm going to start talking about object storage and CDNs in the next video.