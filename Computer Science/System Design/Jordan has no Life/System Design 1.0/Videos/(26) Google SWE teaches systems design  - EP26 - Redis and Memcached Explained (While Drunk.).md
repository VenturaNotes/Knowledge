---
Source:
  - https://www.youtube.com/watch?v=g1mLKeEPgWU
---
- ![[Screenshot 2024-10-10 at 2.05.19 PM.png]]
	- Intro
		- Hello everyone, it is uh i think 1:39 a.m on a Saturday morning. If you can't tell I am actively hammered. Why am i doing this right now. It's because my roommate is at his girlfriend's house and uh i have the free house to record so you know what screw it, let's get this done. Um, I'm gonna talk about Redis and Memcached today and assuming my brain can support it because i guess the Ballmer curve tells me that i can have a couple drinks and and you know talk about code then uh hopefully this video will be coherent. That being said i'm also about eight or nine drinks in so i'm a little bit past the Ballmer curve but you know what, I can still talk about computer science so let's get it done. 
	- MemCached and Redis Background
		- Description
			- When people speak of using Redis or Memcache, it is generally for highly performant data accesses such as needed in caching. This is because they both rely on using random access memory (RAM) as their main data stores, which is capable of reading and writing at orders of magnitude faster than a traditional hard disk.
			- However, as we will see, there are significant differences between the services.
		- Hey yeah so this is me from the next morning uh, I actually did record that video and uh I looked back on it and I was like damn I am slurring a lot of words right now so um we're gonna do a re-recording and uh hopefully i'll explain a little bit more concisely this time so let's do Memcached and Redis.
		- So basically in terms of what Memcache and Redis are, they're both solutions that are typically used for caching in large-scale distributed systems. The reason for this is that they generally speaking store their data in RAM, random access memory and that allows you to basically build something called a distributed hash map which can access keys and set keys at O(1) time which is great because obviously databases on disk can't do that. As we can see though there are pretty significant differences between the two services themselves mainly in the sense that Memcache is basically like a subset of Redis but you know sometimes it's good to have a more limited feature set because you can build out more.
	- Memcached
		- Description
			- An extremely simple service to run a bare minimum distributed string to string hashmap across many servers. Best for single key accesses and sets.
			- Features
				- Partitioning via a consistent hashing ring
				- Least recently used cache (entries can also be invalidated with an expiration)
				- Compare and set functionality
				- No failure handling or replication measures built in, need to manually make sure using some other service that all clients agree on the same list of memcached servers
		- So what is Memcache. Like i said, Memcache allows you to build a distributed hash map amongst a bunch of nodes. However, the nodes basically don't know about one another so generally speaking you're actually kind of just using this client library to go ahead and wire all those requests to the proper node. How do we wire each request to the right node? Well generally speaking, we're using consistent hashing so basically you give all of your you know application servers that are going to be using Memcache instances a list of all the nodes that are running memcached and then that will allow them to create a consistent hashing ring. Additionally, you have an LRU cache so if each memcache instance gets too big or basically there's too much data in there and you need to evict something in order to make room for a new element, you're using the LRU algorithm and then you know a couple of other features that are built in are you know basically just like compare and set. Um generally speaking there's not really any failure handling for Memcache. They don't have any built-in like replication or availability measures so um what actually a company like Facebook did and I'll link this lecture from like [MIT](https://www.youtube.com/watch?v=Myp8z0ybdzM&t=13s) basically in the video description is that they use something called like a gutter Redis instance where every time a Memcache instance failed, they basically go ahead and throw a new memcache instance in there to just take its place and then eventually it'll get repopulated over time but there's no like you know copying over of the data from one instance to another which is interesting.
	- (Single Node) Redis
		- Description
			- Redis is like a modification of Memcached (is also an LRU distributed hashmap with expirations), that allows it to be much more multifunctional.
			- Features:
				- Other data types such as strings, sets, maps, lists (with built in atomic operations)
				- Transactions on a single partition
				- Range queries on a single partition
				- Disk persistence via checkpointing or a write ahead log
		- okay so what is Redis. Well at least on a single node, Redis is a modification of Memcache that basically has the following features, so obviously it's an LRU distributed hash map, but it's got some other stuff too. So instead of just being a hash map from strings to strings, you can actually have other data types as values in the hash maps so those can be sets, you know strings but with atomic operations like appending to the string, maps and, lists and you can also even have transactions so if you want to make multiple writes to a single node and make sure that those are executed both serially and also as an atomic unit, you can do that. You can also even make range queries on a single partition and there's also a way to kind of go ahead and hash keys using only part of the key doing something called the hashtag which allows you to kind of have some control over where each key is going to be sent to in a partitioning scheme. Then finally there's also a concept of actual disk persistence which makes redis a little bit more viable as an actual database for your application as well and you can do disk persistence via checkpointing which is probably faster but obviously comes with the cost of losing some writes if you don't checkpoint everything or you can use a write ahead log where basically every single write is going to the disk before it's written in memory and this obviously comes at the cost of slower writes.
	- Redis Cluster
		- Description
			- Distributed version of Redis meant to provide high availability and consistency
			- Features:
				- Single leader replication with automatic failover
					- As a result, some writes can be lost if leader fails before replicating
					- Gossip protocol with heartbeats (which also convey which nodes hold which partitions) used to determine when leader is no longer up
					- Other master replicas vote on new master, election occurs when a quorum is received
				- 16,384 hash ranges, which can be moved between nodes
					- This is like the pre-generated partition ranges we discussed back in the partitioning video!
		- In terms of Redis cluster. Redis cluster is basically what Redis calls you know running a bunch of Redis nodes in a distributed manner. So basically the point here is that this provides both high availability and consistency. So how do they provide high ability well unlike Memcache they actually support replication out of the box so that uses single leader replication with an automatic failover. The thing with single leader replication here is that some writes can be lost. So if the leader has some writes and it's replicating them asynchronously, just some of its replicas and then the leader goes ahead and fails before all of those writes get properly sent out to all of the followers, then those writes are probably just going to be lost. So how do we actually do a failover, well there's a gossip protocol between all the nodes where you're basically sharing heartbeats that convey the you know kind of the state of the node as well as the partitions that it's holding and then uh in order now to basically you know put a new replica to the master what needs to happen is that a quorum of master nodes amongst all partitions need to basically go ahead and agree that this new follower is going to become the leader and they use an epoch number to do that and so this basically allows us to prevent split brain because obviously a quorum of nodes can't make a conflicting decision for a single epoch so that's pretty smart there how they make sure to prevent split brain. And then finally in order to kind of do partitioning, unlike a bunch of other database solutions which most of which we've kind of just seen using consistent hashing so far, this actually uses the fixed number of partition solution that i discussed from DDIA where there are exactly 16, 384 fixed partitions with fixed ranges and then your job is basically to make sure that you know you're putting the right number of partitions on each node such that there aren't too many hotspots and obviously you know due to the fact that there's replication, if there are certain hotkeys, hopefully the load won't be too great on them because you'll actually be able to serve a lot of requests from those replicas as opposed to just having to serve them all from one instance  
- ![[Screenshot 2024-10-10 at 3.00.02 PM.png]]
	- Memcached Redis Comparison
		- Description
			- Ultimately, when designing systems these are both very viable solutions, but it looks like Redis is effectively just Memcache with a bunch of features. Why would you ever not want to use Redis Cluster?
				- Need strongly consistent data (no lost writes on failover)
				- Want alternate replication patterns such as master-master (leaderless)
				- Prefer to use a coordination service for configuration/partition management as opposed to gossip
		- okay so in terms of a comparison between Memcached and Redis. As you can see um Redis is basically just Memcached with a bunch of additional features built in out of the box so why would you ever not want to use it. Well by virtue of having all these features built in it makes it harder to kind of diverge from that design pattern so let's say you needed strongly consistent data maybe you'd be better off just using memcache and then kind of building out your own system using something with like a coordination service in order to ensure strong consistency. Maybe you want alternate replication patterns like a leaderless replication schema which you know kind of resembles a dynamo database then perhaps you'd be better off using memcache and then you know kind of implementing that yourself. Or maybe even you want to use just a coordination service in general for all of that partition management as opposed to just using a gossip protocol because gossip protocol even though it does generally work, you know it's just a little bit harder to reason about sometimes, you know you can do that too  
	- Conclusion
		- Description
			- In real large scale systems, caching is used whenever possible to reduce database load and latency of the application. While caching is hugely beneficial, it certainly increases system complexity, especially when ensuring consistent data on writes. Nonetheless, it is generally a must-have and Redis and Memcached are two valid ways of implementing it.
		- So in conclusion both Redis and Memcache are super useful systems for implementing caching and in an interview i imagine it probably won't really come up if you just said yeah i'm going to use Redis or Memcache in order to implement my cache, but i think it's important to know the subtle differences between the two of them because that's kind of what this channel is all about. Is being able to you know hear all of the names of these different technology services and basically go and say okay well actually now i understand why one is different from the other. Obviously caching is hugely beneficial for any large scale distributed system and as a result of that you should basically be using it whenever you can until it pretty much prices you out so you know as long as you can afford it you should be using caching. That video i mentioned about caching at Facebook basically says that pretty much 99% of their read requests are handled by their cache in order to take load off their databases and allow them to keep operating. So okay i hope this video was useful sorry i couldn't post the drunk one but it was probably double as long and very incoherent but uh have a good one guys