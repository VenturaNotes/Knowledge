---
Source:
  - https://www.youtube.com/watch?v=c4F7Tfzl198
Reviewed: false
---
- ![[Screenshot 2024-11-13 at 4.40.52 AM.png]]
	- Long Polling, WebSockets, Server Side Events (Background)
		- Description
			- In a decent amount of system design interview questions, there is a need to provide real time updates from a database or server back to a client. While there are multiple options for doing this, each has their own benefits and drawbacks.
			- These things come up in chat applications, ride sharing applications (to continually see where your driver is located), and even things like notification services.
		- All right, so hopefully this video is going to be relatively quick and it's all going to be on the following three topics which are going to be polling, WebSockets, and Server Side Events. So if you haven't heard of these before, they all basically fall under the category of real time updates. In a lot of systems design interview questions, you're going to encounter a bunch of applications that are going to need you to be sending real-time updates to a client in one form or another. That includes things like chat applications, like messenger or whatsapp, ride-sharing applications like uber because you kind of have to know where your driver is at at all times, and so generally speaking, we have this need to be able to kind of propagate all of these updates from you know the server which is actually holding the state or perhaps the database but the server is pulling from it, and then going ahead and propagating that to our actual end user device which is either going to be a smartphone or a laptop or something like that. So anyway we have a few options of doing this and although generally there's probably a better solution for this answer, it's important that we understand why that's the best solution and kind of the differences between the options that we have here. 
	- Polling (Naive Implementation)
		- Description
			- Make a request to the server every few seconds from the client asking for new data.
			- This is bad because you will overload your servers with unnecessary requests!
		- Okay, so first off, we have polling. This is kind of the naive implementation, so as we know, there's something called making http requests and http request is basically anytime you're going to go ahead and from your client device, make any request to a server. So that request could be to get information or to give it new information to put into a database. So anyway, polling is basically saying i'm going to make a get request to the server every x amount of seconds. So you know every five seconds, you know, tell me if this baddie on instagram dm me back. Guess what, she didn't. I'm gonna be sitting there all day waiting. Obviously this is not good because if we have a ton of smartphones all polling one server, that is going to overload them. Especially if there's no new information. It's just going to be a waste of compute and we obviously don't want to be doing that. So kind of the next iteration of the strategy of getting real-time updates was going to be long polling.
	- Long Polling
		- Description
			- Make a typical HTTP request to the server for data, if the server does not have new data to respond with, it keeps the request open, and eventually responds once new data is present. At this point, the client will issue another long polling request. If the connection times out, also send another request.
			- Pros:
				- Easy to implement, universal support
			- Cons:
				- Only one directional, any information sent from client to server must be done through a normal HTTP request
				- Excess load on server by constantly tearing down connections HTTP connections and re-establishing them
				- Possible race condition of multiple requests from same client receiving messages out of order (two tabs open, deduplication needed)
		- So as opposed to the typical polling which just goes ahead and basically hammers your server every few seconds, long polling makes an http request in the same exact way that polling does. However, what the server basically will go ahead and do is say if I have new information, I'm going to return it and if I don't have new information, I'm going to basically store your request on the server for a little bit and if at some point new information comes in, I'm going to go ahead and respond to you. So in this way the client can basically make an http request and then not hear back for a decent amount of time. Once it does hear back, the client is then going to go ahead and kill that http connection it had made with the server. Now it has the information and if it wants more information as one often tends to do in these types of applications because it tends to be a repeat process, it's going to establish another long poll. Okay, so what are the pros and cons of this? Well, the pros are that this is pretty easy to implement because you're basically just issuing a get request as a long poll and most servers have support for this so that's pretty well taken care of. That being said, it also has a few cons. The biggest thing is that it's only one directional. If you want to go ahead and get that information from the server to the client, then send more information back, you have to actually issue a separate http request which really isn't a huge deal but it's just something to keep in mind. Another thing is that you are probably going to be putting a lot of excess load on the server. Why is that? Well every single time you have to re-establish a new http connection via a long polling, you are effectively taking up some resources on the server to do so and so as a result by kind of killing and then reestablishing these connections, this is a less efficient process than some of the other alternatives that we'll see afterwards. And then finally if you are long polling and you have a couple of browser tabs open at once, what may happen is that those two tabs might be you know doubly getting the information and that's either inefficient or it could lead to race conditions where you're getting information out of order. So there's something to keep in mind there. 
	- WebSockets
		- Description
			- WebSockets are a fully bidirectional communication channel between clients and servers. WebSockets are each registered to a port, so a given application service can have around 65,000 active connections before needing to be horizontally scaled.
				- Pros:
					- Bidirectional communication in real time (as opposed to near real time)
					- Lower network overhead due to headers only being sent once
				- Cons:
					- Lesser support for them on older browsers
					- Thundering herd problem due to overhead of establishing a WebSocket connection if the number of application servers changes
					- May be overkill for infrequent data changes
		- Okay moving on, we have WebSockets. So WebSockets unlike long polling are a fully bidirectional connection between the client and server. You basically go ahead and establish a typical http connection which then gets upgraded to a WebSocket connection and from there you can send information both from client to server and also server to client. So this has a few pros and cons and we're going to go through all of them. Keep in mind, another thing i should probably mention, is that WebSockets are each kind of corresponding to a port on the server, so server can hold about 65,000 WebSockets at one time because that's about how many free ports there are. So just keep that in mind if it ever comes up in an interview. So anyway, let's go through pros. The pros are that you have bidirectional communication which means i don't need to be making new http requests to go ahead and serve content back to my server. This is really great for something like a chat app where you're both going to be writing messages and reading messages and so obviously if you want that bi-directional communication, WebSockets are really nice for you. Additionally WebSockets do something cool where once you establish that additional WebSocket request with a certain amount of headers, the headers are not going to be sent again on every single message. So this lowers the network overhead that you're actually going to be having when messages are sent both from client to server and server back to the client. That being said there are a few cons here as well. First of all, there's lower support for WebSockets on older browsers. Obviously that being said though as you know they become more mature of a technology, that kind of becomes less and less of an issue. Another thing is that keeping all of these persistent connections with servers may be overkill for infrequent data changes. For example, instead of like facebook messenger, what if i was running a dashboard and I knew that information was probably only going to be coming in every 30 minutes. It would probably be overkill if i had all of my client devices keeping a persistent connection with our server as opposed to just using a polling once every 30 minutes. That would probably be better in that case. Another issue which is a bit more niche but i've come across it in some of the reading that i've done on this topic is the thundering herd problem and this is kind of basically saying that imagine we have you know who knows like um 500,000 WebSocket connections and those are spread across a bunch of application servers and then one of those application servers were to go down. Well now we have to go ahead and start rerouting all of our WebSocket connections to different application servers obviously trying to balance them relatively consistently but the issue is since there's a decent amount of overhead in actually establishing these WebSocket connections, we can end up basically you know hammering our servers and creating all of these initializations for WebSockets and as a result they can either you know take our servers down or just respond failures on trying to initialize all these WebSocket connections and it could lead to cascading failures. This doesn't happen with long polling for example because you know if you have a load balancer up between all of your application services and long polling is basically just saying, just route my request to one of the back ends, the load balancer is going to do that routing automatically for you. You don't have to kind of manually reroute everything like you might in a WebSocket configuration and that can kind of lead to issues and additional complexity.
- ![[Screenshot 2024-11-13 at 4.56.48 AM.png|500]]
	- Server Sent Events
		- Description
			- One way connection from servers to clients, client-side code registers for events from the server. Good for things like stock ticker updates or notifications
			- Pros:
				- Unlike long polling use persistent HTTP connection as opposed to killing and reconnecting
				- Unlike WebSockets re-establish failed connections automatically
			- Cons:
				- Single directional communication
				- A lot of concurrent connections can add load on server if they are not needed
		- Okay, finally we have server sent events. Service sent events basically, going back, web sockets were two directional, server sent events going back are now one directional only from servers to clients and what you do is the client goes ahead and registers for events from server. This is really useful for things where basically you only have one directional communication, but you just need it in real time. So stock ticker updates, you know, news feed updates from facebook or twitter, notifications all can be useful with um server sent events. So basically here um unlike long polling, server sent events actually you know also keeps a persistent connection and that's similar to web sockets but in addition to the functionality of web sockets as far as persistent connection goes, um server sent events will actually handle uh re-establishing you know closed connections if they were to go down for some reason so, you know it just takes a little bit of complexity away from the application as opposed to having to use something like a heartbeat to determine if a WebSocket connection is down and then manually trying to re-establish it. That being said, there are some cons. The main one being that it's only single directional communication. If you want to use server side events and then additionally send information back to the server, you would have to use separate http requests and then additionally like WebSockets, a lot of concurrent connections that are redundant if there aren't really many events being sent can just be additional load on a server if they're not needed. So basically server sent events are pretty useful. They're kind of a more limited set of options than web hooks, but i think they also are technically slightly lower overhead and a little bit easier to set up. So there is a case to be made for using them for kind of some of the examples that I gave on this slide. 
	- Conclusion
		- Description
			- While generally it is going to be enough in systems design interviews to mention using WebSockets for most real time applications, it is important to be able to distinguish some of the subtle differences between them and long polling or server side events. In actual tech companies, these latter two are still frequently used due to their widespread support, ease of understanding, and lower overhead
		- That being said, in conclusion, in an actual systems design interview, it's probably fine to just go ahead and say, oh we have real-time updates, I'm just going to use WebSockets. That being said, don't be surprised if your interviewer then says to you, well why web sockets as opposed to i don't know long polling or server sent events and this is kind of where these topics would come in where you can basically just go ahead and say well i want this bi-directional communication. I like that you're not resending all of these headers all the time so there should be lower overhead et cetera et cetera et cetera and so basically again i'm just trying to dive deeper into the trade-offs both for my own knowledge and yours in order to be able to kind of justify all the choices that you're making when doing a systems design interview