---
Source:
  - https://www.youtube.com/watch?v=a5pesP6ezRM
Reviewed: false
---
- ![[Screenshot 2024-11-13 at 7.08.51 PM.png]]
	- Introduction
		- All righty, I am back. Um two quick things, one you guys better get my subscribers up real quick cause i'm damn close to doing a day in the life of a google software engineer video. I swear. Don't make me do it. It'll be very cringy. Second of all is i have a nice big collaboration coming up with uh a decently big YouTuber which is sweet so hopefully that'll get some numbers up on here but, I don't know. It's not really a huge deal at the end of the day. I'm kind of just doing this to self-study and it's actually working out pretty well. I feel like i'm getting pretty good at this stuff. So anyway, let's go ahead and look into bloom filters because this is something i've mentioned for a while and i would kind of be a hypocrite if i just talked about them all the time and never explained how they actually worked. So let's go ahead and do all that.
	- Bloom Filters (Background)
		- Description
			- Bloom Filters are a data structure used to approximate the contents of a set of elements. They are known as a probabilistic algorithm
			- While Bloom Filters may be incorrect and say that an element is in the set (false positives), they are always correct when saying an element is not in the set (no false negatives)
		- Bloom filters. what are they? Basically bloom filters are just another data structure that you use to approximate the contents of a set. So i've kind of mentioned that before but basically they're a probabilistic algorithm that will tell you conclusively if something is not in the set so basically you don't ever have to worry about false negatives but that being said bloom filters may basically take an element and say this could be in the set so you may have to search this and then you have to do a little bit of unnecessary work to find out if it's actually in there. So let's go ahead and look at some use cases where bloom filters are used because i've mentioned one big one but there's another that seems to be pretty common in a lot of large scale systems
	- Bloom Filter use case - cache filtering
		- Description
			- Recall: Most cache has to evict one piece of data in order to load in another one
			- First - Search cuddling
				- Second - Evict Coding
			- Bad! We never meant to search cuddling, it was just an autocorrect. Wouldn't it be better to know that we've never searched cuddling before to help show the cache that it shouldn't evict a more relevant entry?
		- And that is going to be cache filtering. So imagine you know maybe we're just Google and we're going to be a search index and we are going to cache a bunch of the common results of search terms that our end client might use a lot. So imagine i'm on my phone or on my laptop or something and generally speaking i search the term coding a lot because i'm a nerd and i've been doing a lot of research on this. My phone, like the idiot that it is, goes and thinks that i'm talking about cuddling. So first, i'm going to search cuddling and maybe i do search that sometimes because i'm down bad but search cuddling and then this thing that's going to happen is that it's going to go to the cache. The cache is going to see that cuddling's not in there. The cache doesn't have that much space so, what's going to end up happening is it might evict a term that I use a lot more such as coding. This is bad obviously, i never even meant to search cuddling but it was just an autocorrect. So how can we actually go ahead and provide some layer of protection to not basically go ahead and cache terms that i've really never searched before. This would kind of be where a bloom filter would come in. So how would we go ahead and do this? 
	- Bloom Filter use case - cache filtering
		- Description
			- Recall: Most cache has to evict one piece of data in order to load in another one.
				- First: Check if cuddling in bloom filter
				- Second - Since it is not, we have never searched cuddling before, probably not relevant enough to cache so just hit the database
				- Bloom filters allow us to see if we have seen a given term before to estimate whether it is relevant enough to be cached!
		- Well, first you know on that search term cuddling, we would go ahead and check if that is in the bloom filter and basically if the bloom filter says no it's not, it means that i personally have never searched the word cuddling before and like i said, there are no false negatives so the balloon filter knows that for sure. If i haven't ever searched cuddling before, it's not only not going to probably be in the cache but more importantly we don't want to go ahead and pull results from that into the cache so we would just go ahead and reroute my request straight to the database because it's probably a pretty uncommon request and as a result it won't be a big deal if these uncommon requests go to the database because we're not hammering it. It's mostly the common request that it's mostly important that they go to the cache because that way it stops the database from having to handle most of the load. So anyways like i said, if that's not in the bloom filter, we go ahead and search the results for cuddling in the database of the search index or whatever it may be but the point is we are skipping around that cache. So in this sense, bloom filters are allowing us to get better cache performance.
	- Bloom Filter use case - SSTables
		- Description
			- Recall: When reading from an LSM tree based storage engine, we must check all the SSTables in order from newest to oldest until we find the key that we want.
				- Searching for key Jordan: we can quickly skip over binary searching SSTables 1 and 2 because their bloom filters (probably) return "no" for Jordan
		- Another common use case that i've talked about in the past are SSTables. So recall that for LSM based storage engines, we first on reads check the LSM-tree which is an in-memory tree like a red black tree or something and then we go ahead and search every single SSTable in order from newest to oldest to try and see if we can go ahead and find that key. However, that's really bad because we can actually go ahead and have to search every single SSTable and actually searching an SSTable means running a binary search on it because it's sorted from basically the entire bounds of the table from the beginning to the end but what if instead we were to use bloom filters on each SSTable so that we could basically very efficiently tell if a key was not in that SSTable and if so skip over it. Obviously, we don't have a 100% success rate here. They're going to be times where the bloom filter says well actually we think the key is in here, so you're still going to have to check it, and then it turns out it's not and you go forwards but even still generally speaking this saves a lot of time. So if you see my example below, basically I would check the bloom filters for SSTable 1 and 2 for the key Jordan and hopefully the bloom filter would tell me Jordans not in there and as a result, I would then look at the bloom filter for SSTable 3. It would say Jordan might be in here and then i would go ahead and run binary search and find my proper key. The point is though just remember that like i said it's possible that the bloom filter for either SSTable 1 or 2 would say that Jordan is actually in there and if so i would waste some time searching those tables to no avail. So why is it that bloom filters actually work this way. Well let's go ahead and break down the algorithm for them. 
- ![[Screenshot 2024-11-13 at 7.22.38 PM.png]]
	- Bloom Filter Algorithm
		- Description
			- Start with array of m bits initialized to 0s
		- So basically, the way that bloom filters work is the following. You start with a single array of `m` bits initialized to zeros. So bits can basically just be zeros or ones and we have this array of length m. 
	- Bloom Filter Algorithm
		- Description
			- Choose k different hash functions: if key "poop" is in the set, get the result of each of the k hash functions for poop mod m
		- Okay, so now what we're going to do is choose k different hash functions and obviously we want these to be good hash functions in the sense that they distribute our data relatively uniformly and they're random. So imagine i have the key poop. Whatever that's what i chose. That's right. I'm not mature. Basically, we're going to go ahead and take each of the k hash functions. So imagine here that k is 3. So i have these three hash functions and take the result of them mod m. So imagine i hashed poop three times with these three functions and the results i get are 0, 2 and m-1. What we're going to do is say if i wanted to add poop to this set, the bloom filter that i would use to represent this set, now i have to set all of these bits from the hashes of poop to 1. 
	- Bloom Filter Algorithm
		- Description
			- Change all the bits corresponding to the results of the previous equation to 1 in the Bloom Filter
		- So you can see now that in the array, I've set the zeroth bit to one, the second bit to one, and the `m-1` bit to 1. So this is kind of how i would go ahead and add a term. If i were to add more terms, you know, if i wanted to add p or something, I would go ahead and do the same exact hashes and i would continue to add the bits. It would be on the same array by the way. Not a different array so keep that in mind. We just have one array and every single time we're adding a term, we're setting the corresponding bits in that single array. So you can see how that might be a problem later, but we'll talk about that in a bit.
	- Bloom Filter Algorithm - Continued
		- Description
			- Bloom filter for s = {poop}
			- Get hash results for key = Jordan
		- So now to continue the actual algorithm, we now have this set that just contains poop and we have the corresponding bits from the hashes of poop that are all set. So now imagine if i wanted to get the hash results for the key Jordan. So i would go ahead and use those same k hash functions and go ahead and get the results. So hash function 1 of Jordan mod m return 0 hash 2 gets 2, so as you can see Jordan and poop are actually pretty similar in the way they're hashed. Uh you know random i guess luck but even still, the fact that hash function three mod m returns three as opposed to m-1 means that Jordan and poop differ in one bit from those three hashes. So since the fact that filter three equals zero, we know that Jordan can't be in the set because if Jordan was in the set, that bit would have been set to one. As a result, we can basically conclusively say that we are able to basically in constant time determine if something is in the set and in this case we know that Jordan is not. So now you might be thinking to yourself, well what if we've added so many elements to the set that basically we just get unlucky and um you know it just so happens that bits zero two and three have already been set to one and now we just think that Jordan is in the set even though it's not. 
	- Bloom Filter - Caveats
		- Description
			- As we add more elements to the set, more of the bits are going to start switching to 1s
			- This means that sometimes we will get unlucky and it will seem like certain keys are in a set even though they are not (false positives)
			- Occasionally, it makes sense to reset a bloom filter to all 0s in order to lower the rate of false positives, at the cost of losing the data already in the filter
		- Well in this case we're out of luck. So basically like i said, as we add more elements to the set, more of the bits in that array are going to start being set to 1s and sometimes we're going to get false positives. Obviously there's not really much we can do here. There is math basically you know getting values for m and k where m is the length of that array and k are the number of hash functions you know to try and avoid a good number of false positives but at the end of the day, after a while when there are too many things in the set, occasionally we're just going to have to go ahead and reset that bloom filter to all zeroes to avoid getting so many false positives because eventually it's just going to even stop being useful and if every single time is an error, then it doesn't even help us to go ahead and check that out. We may as well just reset it to zero, incur the penalty of you know having to re-add some things to the set and then eventually start getting useful bloom filter results again.
	- Conclusion
		- Description
			- Bloom filters are a very interesting and clever algorithm based on hashing that can be useful in both competitive programming and systems design. They are employed in many LSM based storage engines and are largely responsible for their respectable read performance compared to B-Trees
		- Okay, so in conclusion bloom filters are super useful in terms of both that cache filtering that i mentioned and also LSM reads. Um there's something that i've mentioned a lot and i've put an emphasis in this channel of trying to explain every single thing that i can, you know within reason and so i think it's really useful to kind of be able to actually go ahead and break this down and see this technique that's used in so many modern database systems in order to greatly improve the speed of reads. In the past i've kind of acted like this was some sort of you know probabilistic algorithm where you know it can almost get things wrong sometimes and the truth of the matter is, no it can't really get things wrong. If a bloom filter says something is not in a set, it's right about that and so you may have to end up doing you know a similar amount of work because you're just going to falsely search a set for something that's not there but it can still speed things up a lot by telling you that some element is not in a set and that is hugely important for a variety of reasons and i kind of went through those use cases in this video. So i think that being able to talk about bloom filters in a systems design interview is pretty useful.