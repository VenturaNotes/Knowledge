---
Source:
  - https://www.youtube.com/watch?v=VBFAphx6kkM
---
- ![[Screenshot 2024-11-12 at 8.29.29 PM.png]]
	- Introduction
		- Today we're gonna be covering [[AWS Aurora]] which is another [[NewSQL]] type of database. I figure it kind of fits in nicely since we just spoke about spanner so yeah let's go over that and I think it makes for a pretty interesting concept. It applies some of the stuff that we've learned in the past, so let's go ahead and do a deep dive.
	- Aurora (Background)
		- Description
			- AWS Aurora is another NewSQL database which claims to gain a 35x performance boost over running traditional MySQL in the cloud. It uses some interesting concepts that involve much of what we have spoken about in the past, such as quorum writes for replicated logs as well as using caching in a clever way
		- Okay so Aurora. What is it? Well like i mentioned, Aurora is another type of these NewSQL databases which basically means it's got a SQL interface but a much different approach to actually implementing SQL on a cloud computing or distributed level scale than you know typical MySQL or Postgres. It's apparently boasting a 35 times improvement over traditional SQL solutions and as a result, I think it's worth taking a dive into how that actually goes ahead and works. 
	- Traditional RDMBS Design
		- Description
			- Traditionally, pages from the disk that need to be read or modified are first loaded from disk into memory. If the page is modified in memory, first an entry is appended to the write ahead log and then the changes in memory are eventually written back to disk (does not necessarily have to be done right away as long as the write is in the log).
			- Memory (Page Cache)
				- Disk (B-Tree)
		- Okay so what is the traditional RDBMS design? Basically and I've mentioned this in the past, especially on the time series video. This was the most relevant. Especially for B-tree-based solutions, most databases look something like this where we have this b-tree on the disk and then we have this layer of memory. So obviously that's going to be smaller and that is called a page cache. So the point of the page cache is to load in relevant parts of the b-tree that are either being accessed frequently for reads or if you know there's a write and we have to modify a part of the b-tree. What first happens is the b-tree is loaded into memory, that page is going to go ahead and be modified and then a change is going to be written into the write ahead log basically saying, okay we've made this change right here, now it's going to be persistent by virtue of being in that write ahead log. You know it's not necessarily important that we write the page back to disk just yet because it's in the write ahead log. If things were to crash, we could just go ahead and use that write ahead log to recover from that and make sure that everything was in disk as it's supposed to be. So this way is kind of how we can buffer some of those writes to memory, but whatever. That's kind of irrelevant for now. The point is though the change that Aurora makes is the following: So it actually decouples the memory and that disk into two different servers. 
	- Aurora Design
		- Description
			- Aurora decouples the cache and disk on two different servers!
			- Takes too long to send entire modified page over network to disk (typically 8kb), instead just send new write ahead log entries to in, let disk server derive state locally
			- Both disk and memory can be replicated independently!
			- Memory (Page Cache) $\to$ Disk (B-Tree)
		- So we have now is we have a server basically acting solely as the page cache and then we have a server that is going to be just acting as the actual storage itself. The thing to note here is that it generally takes too long to send an entire modified page from the page cache over network to the disk. Why would we be sending a modified page from the page cache to the disk? Well every single time we make a write. So typically pages are about eight kilobytes and that's not really feasible here. So what Aurora has instead uh decided to do is instead of going ahead and sending back the whole page, it's just going to send the corresponding write ahead log entry and as a result that write ahead log entry is going onto the disk and now things are going to be persistent. The disk can kind of in the background go ahead and make those updates locally but it doesn't really have to do it in any timely fashion as long as things are in the write ahead log, a write is considered persistent. Another nice thing about this is that it means that both disk and memory can be replicated and scaled independently. So we're going to see how that would actually go ahead and happen.
	- Replication of Storage
		- Description
			- Availability Zone 1
				- Memory (Page Cache)
					- Disk (B-tree)
					- Protection Group (like a shard)
			- Availability Zone 2
			- Availability Zone 3
		- In terms of replication of storage, so this is kind of what we would do for the disk. Typically what happens is we have, you know, a memory server. So this is kind of like our database server which i'll call the database server, the cache server, and then we also have something called a protection group. So in Aurora, a protection group is a group of six disk servers which comprise three availability zones which means different data centers and the reason you do this is obviously so that if one of those availability zones goes down, you still have replicated data hopefully at least on the other two. So we're going to see now how writes actually go ahead and work because they're actually pretty interesting in this type of system. 
- ![[Screenshot 2024-11-12 at 8.41.18 PM.png]]
	- Writes
		- Description
			- Require a quorum of nodes in order to be successful!
				- In this case, it is 4 out of 6 nodes
				- Ensures high availability if an entire availability zone goes down
		- So what does a write do? It basically requires a quorum of nodes in order for this to work. So the database node is going to receive a write that's on the caching layer and it's going to basically go ahead and say okay, I have my entry from the write ahead log, I'm going to go ahead and send that to all six of those nodes in the protection group and once i get positive responses out of four of them i'm going to say this write is committed. So that's basically all it comes down to and then like i mentioned, this ensures high availability if one of those zones goes down. 
	- Reads
		- Description
			- Reads do not have to use a quorum! The caching layer (database node) can simply look at its log to see what the log position is at the time the read was issued, and then only issue a log from an up to date replica
		- In terms of reads, they actually don't need to use a quorum. We'll see where quorum reads come in a little bit, but for now just in terms of getting strong consistent reads out of that database node, it's actually pretty easy. All the database layer has to do or the caching layer has to go ahead and take the read request, look at its log which we know is up to date because as of now it's kind of the single caching layer, it says I have an up to date log. I know the current position of the log, so i'm going to now check out all of these other replica storage nodes, find the one that is up to date as of the point of this log and go ahead and make a read of that. In that sense, we can actually get strongly consistent reads out of this kind of leader database caching mode. 
	- Replication of Caching Layer
		- Description
			- Can also add some read only cache replicas, main leader cache replica asynchronously propagates log changes to each of them. Each read-only replica can issue eventually consistent reads using its log in the same way that the main replica would (but since log is itself being propagated asynchronously, reads can be stale).
		- Okay, additionally, you can actually replicate the caching layer itself. Like i said, we can scale these replicas independently of one another. The protection group storage is scaled to six nodes and then the caching layer itself can be scaled i believe up to actually 15 nodes. But keep in mind that only one of them can be making writes. The rest are actually going to be read only in kind of like a primary backup replication schema. So basically, what happens is as that main leader cache gets writes, it's going to go ahead and asynchronously replicate its write ahead log over to all of those other read-only replicas and then the read-only replicas can go ahead and use their local copy of the write ahead log in order to serve read requests by using the same process that i just mentioned. Namely, check the write ahead log, see what the current position is, issue a request to one of the storage replicas that is up to date as of that write ahead log. The thing to note though is that since the write ahead log is being asynchronously propagated from the main cache replica to the other cache replicas, all of those logs are going to be a little bit out of date on all of the cache replicas and so they are going to issue reads that are going to be eventually consistent, namely, they can return stale data. Generally speaking though in most applications it's not a huge deal and if it is a huge deal, you can always just go perform reads from the actual leader itself. So then why are we doing this quorum because i mentioned we're doing a quorum of writes but we're not making quorum reads and as a result of that, we can't necessarily ensure strongly consistent reads. Well actually, quorum writes are very important for ensuring fault tolerance and ensuring that everything stays consistent on failures. 
	- Failure of Database Node
		- Description
			- If a new node needs to take over as leader database node, it needs to ensure that any uncommitted writes issued by the last leader are reverted. It uses a quorum read to figure out the greatest committed log position (pictured above, 100), and reverts all log entries with a greater index on all of the replicas.
		- So let's look at the case of the failure of the database node. So keep in mind or think of the the following case where a database node issues a couple of writes and then it fails before it can issue the rest of the writes to the rest of the storage nodes of the protection group. So now we have this inconsistency where as you can see, out of all of these disk nodes, two of them have different write ahead log positions and obviously 101 and 102 couldn't possibly be committed. So now what's going to happen is that when the database node goes ahead and fails, these storage nodes are going to be out of sync with one another, and they're not going to converge because the database node isn't there to kind of propagate those writes to them. So instead what's going to happen is this. A new node is going to take over as the database node and it's going to perform a quorum read which means it's going to perform a read from four out of the six replicas. So once you read from those four replicas, it doesn't really matter which ones we get. It is necessarily going to be the case that you can't get a majority of nodes with one of those higher values, but instead, it's going to be the case that the highest or basically the quorum read is going to tell us what the highest accepted value is out of all of the nodes there and we're going to see that 100 is the highest committed log value and as a result of that, we can just go ahead and revert the rest of the writes that were kind of beyond 100. So the the 101 write and the 102 write get thrown away. 
- ![[Screenshot 2024-11-12 at 8.49.12 PM.png]]
	- Failure of a Storage Node
		- Description
			- If a server holding 10gb storage partition fails, it is likely that it was holding hundreds or perhaps even thousands of these partitions. In order to avoid massive network overhead of copying each partition to one other storage node, the shards on that storage node are sent to a variety of different storage nodes to parallelize the process of copying over the network.
		- If a storage node were to fail, so this is going to be one of those yellow nodes in the protection group, then we have to think of the following. So, I haven't mentioned this yet but basically every single database table in Aurora is partitioned into 10 gigabyte segments and those 10 gigabyte segments are what make up a protection group. However, imagine you have, you know, a terabyte large table which means that you're going to have a 110 gigabyte segments and you know if multiple users or multiple you know companies are using the same Aurora servers, it means that you might have a bunch of these 10 gigabyte segments on a single node or a single server basically and as a result, it's going to be a real pain if you have to go ahead and copy over 100 segments in a sequential manner over the network from you know one replica to another. So instead of what Aurora does to go ahead and mitigate this issue is they kind of take a consistent hashing approach where you split up all of those chunks of that failed server and then you know using the replicas obviously, you're copying over the chunks to a variety of different servers in order to actually parallelize the network IO as opposed to sending everything in order and that way overloading the network. So by parallelizing these individual failures of storage nodes are not a huge deal. 
	- Conclusion
		- Description
			- AWS Aurora is yet another example of clever engineering in order to help scale out the traditional relational data model. It acts as an interesting application of decoupling storage and caching, while also maintaining high availability and strong consistency (in some cases).
			- While it is not overly necessary to know all of the intricacies of Aurora, being able to mention it in a SQL vs. NoSQL interview discussion could be very useful, as it falls under the category of NewSQL.
		- Okay, so I know this was a pretty quick video, but in conclusion basically, Aurora is another really cool NewSQL system and it has big implications in terms of making relational databases viable again. Obviously if you can compete with NoSQL performance but then get these type of guarantees in terms of you know the validity of your data using normalization as opposed to denormalization, having these cross-shared transactions, that's actually super useful. That being said, it's probably not going to be overly useful to know about the specifics of something like Aurora or Spanner in an interview, however, I personally think that "A", this channel is about going in depth on systems design and "B", if you are able to kind of work something like an Aurora or a Spanner into your systems design conversation, it can really show that you've done your research and you've done a lot of significant studying into all of these different types of storage systems. So in that sense, I think it's useful. I'll probably do one more NewSQL system known as VoltDB at some point in the near future, but at this point, I'm kind of going in more of a free form order so we'll see what i get to next.