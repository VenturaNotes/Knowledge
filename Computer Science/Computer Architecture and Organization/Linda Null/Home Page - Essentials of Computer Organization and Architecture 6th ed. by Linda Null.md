---
Source:
  - zotero://open-pdf/library/items/ZWLVXRKV?page=7&annotation=B35U3DAZ
Length: "1700"
Progress: "0"
tags:
  - status/incomplete
  - type/textbook
Year: 2023-04-27
---
## Preface
- “Computing systems are presented as a series of <mark style="background: #FFF3A3A6;">layers</mark>, starting with [[low-level hardware]] and progressing to [[higher-level software]], including assemblers and operating systems.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=23&annotation=YBVHMIND))
- “study of computer architecture focuses on the interface between hardware and software,” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=24&annotation=URAENGHG))
- “infamous segmentation fault or bus error.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=24&annotation=5NDNFHSX))
- “Association for Computing Machinery (ACM) and the Institute of Electrical and Electronic Engineers (IEEE).” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=25&annotation=5Z7QGRMG))
	- “[[Science Curricula 2013]] (CS2013).” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=27&annotation=RGL6TQXN))
		- “[[Core Tier-1 topics]] are those that should be part of every computer science curriculum. [[Core Tier-2 topics]] are those that are considered essential enough that a computer science curriculum should contain 90–100% of these topics.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=27&annotation=82MCYGJM))
		- Elective topics allow curricula to provide breadth and depth
	- This textbook is in direct correlation with the ACM/IEEE CS2013 guidelines for computer organization and architecture
### Relationship to CS2013
- AR - [[Architecture]]
	- [[Digital Logic and Digital Systems]]
	- [[Machine-Level Representation of Data]]
	- [[Assembly-Level Machine Organization]]
	- [[Memory System Organization and Architecture]]
	- [[Interfacing and Communication]]
	- [[Functional Organization]]
	- [[Multiprocessing and Alternative Architectures]]
	- [[Performance Enhancements]]
- NC - [[Networking and Communication]]
	- Introduction
	- [[Networked Applications]]
	- [[Reliable Data Delivery]]
	- [[Routing and Forwarding]]
- OS - [[Operating Systems]]
	- [[Overview of Operating Systems]]
	- [[Memory Management]]
	- [[Virtual Machines]]
	- [[File Systems]]
	- [[Real-Time and Embedded Systems]]
	- [[System Performance Evaluations]]
- PD - [[Parallel and Distributed Computing]]
	- [[Parallel Architecture]]
	- [[Distributed Systems]]
	- [[Cloud Computing]]
- SF - [[Systems Fundamentals]]
	- [[Computational Paradigms]]
	- [[State and State Machines]]
	- [[Parallelism]]
	- [[Evaluation]]
	- [[Proximity]]
- SP - Social Issues and Professional Practice
	- History
### Relationship to CC2022
- “ACM/IEEE task force released CC2020, Paradigms for Global Computing Education.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=31&annotation=LT3UHES9))
- “For computer science, the main knowledge areas are listed as [[software development fundamentals]], [[algorithms and complexity]], [[software engineering]], [[programming languages]], [[discrete structures]], [[systems fundamentals]], and [[computer architecture and organization]].” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=31&annotation=MUWYPW7Z))
- Architecture and Organization
	- CAD tools
	- Timing diagram behavior
	- Processor
	- Logic Circuit level
	- assembly/machine level
		- String processing and manipulation
		- Convert numerical data to hexadecimal form
	- High-level construct
		- Machine and assembly languages
	- Average memory access time
		- cache and memory configurations
- Networking and Communication
	- Industry network
		- Network's performance
	- Fixed and dynamic allocation techniques
		- Approaches to congestion
- Operating Competency Systems
	- Software solutions
		- Target system (consider abilities and constraints)
	- Behavior of systems under random events
		- Probability and expectation
- Parallel and Distributed Computing
	- Architecture and Organization
		- Scalable parallel algorithm
			- [[task-based decomposition]]
			- [[data-parallel decomposition]]
		- Identify Independent tasks
			- Parallelized and determine [[critical path]] for a [[parallel execution diagram]]
	- Systems Fundamentals
		- Design simple sequential problem
			- parallel  version of same problem
			- logic design
			- Evaluate design for a commercial organization
		- Local organization
			- error detection and recovery
			- Program tracing and debugging
		- Average memory access time
			- Tradeoffs in memory hierarchy performance
				- capacity, miss/hit rate, access time
		- Performance of two application instances running on separate virtual machines
			- Determine effect of performance isolation
	- Social Issues and Professional Practice
		- Document industry trends, innovations, new technologies
		- Document addresses effect of societal change due to technology
		- Compare error detection and correction methods
			- Data overhead
			- Implementation complexity
			- Relative execution time for encoding, detecting and correcting errors
			- Ensure error does not affect humans adversely
### Why Another Text?
- “written from a computer science point of view, written without machine-specific terminology,” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=34&annotation=5PCFFDT2))
	- For engineering and computer science students
- “I offer examples for personal computers, enterprise systems, and mainframes, as these are the types of systems most likely to be encountered.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=34&annotation=PATQJ4NG))
- “differences and similarities between various platforms” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=34&annotation=BD7I5ZY3))
### Features
- Has answers to selected exercises
- Has appendix, glossary, and index
### About the Author
- “Linda Null brings to this textbook over 45 years of teaching experience.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=36&annotation=MRXZSNAX))
### Prerequisites
- High-level procedural language
- Calculus or discrete mathematics
- No prior knowledge of computer hardware needed
- “customarily a prerequisite for an undergraduate [[operating systems]] class (students must know about the [[memory hierarchy]], [[concurrency]], [[exceptions]], and [[interrupts]]), [[compilers]] (students must know about [[instruction sets]], [[memory addressing]], and [[linking]]),” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=36&annotation=8ZTR9XQQ))
### General Organization and Coverage
- “I have taken a bottom-up approach, starting with the digital logic level and building to the [[application level]],” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=37&annotation=RTLQMRIF))
- “text is divided into 13 chapters and an appendix” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=37&annotation=ZNEGMFUZ))
- Key Terms of each chapter
	- Chapter 1
		- [[Computer system]], [[logical levels]], [[von Neumann computer model]], [[high-level view]], 
	- Chapter 2
		- [[Numerical Information]], [[Character information]], [[Addition]], [[Subtraction]], [[Multiplication]], [[Division]], [[number bases]], [[numeric representation techniques]], [[one's complement]], [[two's complement]], [[BCD]], [[EBCDIC]], [[ASCII]], [[Unicode character representations]], [[fixed representation]], [[floating-point representation]], [[data recording]], [[error detection and correction]]
	- Chapter 3
		- [[Digital Logic]]
		- [[Boolean algebra]]
		- [[Combinational logic]]
		- [[Sequential Logic]]
		- [[medium-scale integration]] (MSI)
		- [[circuits]]
			- [[decoders]]
			- [[buses]]
			- [[memory]]
	- Chapter 4
		- [[Fetch-decode-execute cycle]]
		- [[data path]]
		- [[clocks and buses]]
		- [[register transfer notation]]
		- [[Central Processing Unit|CPU]]
		- [[MARIE]]
			- [[Program counter]]
			- [[accumulator]]
			- [[instruction register]]
			- [[addressing modes]]
		- [[Instruction set architecture|ISA]]
		- [[Assembly language programming]]
			- [[instruction format]]
			- [[instruction mode]]
			- [[data format]]
			- [[control]]
		- Two methods of
			- [[Control]]
			- [[hardwiring and micropro-gramming]]
		- [[Intel architectures]]
		- [[MIPS architectures]]
	- Chapter 5
		- [[Instruction set architecture|Instruction set architectures]]
			- [[instruction format|instruction formats]]
			- [[instruction types]]
			- [[addressing modes]]
		- [[Instruction-level pipelining]]
		- [[Real-world ISAs]]
			- [[Intel]]
			- [[MIPS Technologies]]
			- [[ARM]]
			- [[Java]]
	- Chapter 6
		- [[Memory concepts]]
			- [[RAM]]
		- [[memory devices]]
		- [[Memory hierarchy]]
			- [[cache memory]]
			- [[virtual memory]]
		- [[Direct mapping]]
		- [[Associative mapping]]
		- [[set-associative mapping techniques]](for cache)
		- [[paging]]
		- [[segmentation]]
		- [[TLBs]]
	- Chapter 7
		- [[I-O fundamentals]]
		- [[bus communication and protocols]]
		- [[external storage devices]]
			- [[magnetic disks]]
			- [[optical disks]]
		- [[DMA]]
		- [[Programmed I-O]]
		- [[interrupts]]
		- [[RAID architectures]]
	- Chapter 8
		- [[RISC]]
		- [[Flynn's Taxonomy]]
		- [[Parallel processors]]
		- [[Instruction-level parallelism]]
		- [[Multiprocessors]]
		- [[Interconnection networks]]
		- [[Shared memory systems]]
		- [[Cache coherence]]
		- [[Memory models]]
		- [[Superscalar machines]]
		- [[neural networks]]
		- [[systolic architectures]]
		- [[dataflow computers]]
		- [[quantum computing]]
		- [[distributed architectures]]
	- Chapter 9
		- [[embedded hardware and components]]
		- [[embedded system design]]
		- [[embedded software construction]]
		- [[embedded operating systems features]]
	- Chapter 10
		- [[performance analysis]]
		- [[management issues]]
		- [[MIPS]]
		- [[FLOPS]]
		- [[benchmarking]]
		- [[Optimization issues]]
			- [[branch prediction]]
			- [[speculative execution]]
			- [[loop optimization]]
	- Chapter 11
		- [[compilers]]
		- [[assemblers]]
		- [[operating systems]]
			- [[resource use and protection]]
			- [[traps]]
			- [[interrupts]]
	- Chapter 12
		- [[Network organization]]
		- [[Architecture]]
		- [[Network components]]
		- [[Network protocols]]
		- [[OSI model]]
		- [[TCP-IP suite]]
		- [[Computer architecture]]
	- Chapter 13
		- [[I-O architectures]]
			- [[SCSI]]
			- [[ATA]]
			- [[IDE]]
			- [[SATA]]
			- [[PCI]]
			- [[USB]]
			- [[IEEE 1394]]
		- [[Storage area networks]]
		- [[Cloud computing]]
	- Appendix A
		- [[Data structures]]
		- [[stacks]]
		- [[queues]]
		- [[linked lists]]
### What's New in the Sixth Edition
- Chapter 1
	- [[exa-scale computing]]
	- [[historical computing devices]]
	- [[DVDs]]
	- [[CDs]]
	- [[5G]]
	- [[6G]]
	- [[Blu-ray discs]]
- Chapter 2
	- [[Double dabble]] (dropped from this section)
	- [[Number systems]]
	- [[nanosatellites]]
	- [[error correction]]
	- [[error detection]]
- Chapter 3
	- [[Gates]]
	- [[Circuits]]
	- [[Kmaps]]
	- [[PLDs]]
	- [[FPGAs]]
- Chapter 5
	- [[Raspberry Pi computer]]
- Chapter 7
	- [[I-O Process]]
	- [[serial transmissions]]
	- [[solid-state drives]]
	- [[regular hard drives]]
	- [[flash memory]]
### Intended Audience
- For computer science majors but also IS and IT majors
### Support Materials
- “An Introduction to MIPS Assembly Language.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=47&annotation=MCX6R33M))
- “Intel Assembly Language.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=47&annotation=2A956U9K))
### The Instructional Model: MARIE
- “Real architectures, although interesting, often have far too many peculiarities to make them usable in an introductory class.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=48&annotation=MS2BICB8))
- “I have designed my own simple architecture, MARIE, specifically for pedagogical use.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=48&annotation=596XJFLR))
- “MARIE (Machine Architecture that is Really Intuitive and Easy) allows students to learn the essential concepts of computer organization and architecture, including assembly language” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=48&annotation=GUTYQ4FV)) 
	- Simulates a functional system
	- “MarieSim was written in the Java language so that the system would be portable to any platform for which a Java Virtual Machin e (JVM) is available.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=49&annotation=JKU2IJI3))
- “The MARIE simulator illustrates the process of assembly, loading, and execution, all in one simple environment.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=50&annotation=7Y4LG6EF))
### If you Find an Error
- Comments and suggestions always welcome
### Credits and Acknowledgements
- “I would also like to thank the individuals at Jones & Bartlett Learning who worked closely with me to make this sixth edition possible.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=51&annotation=V8S5SMHU))
	- Seems like the website is down?

## (1) Chapter 1 Introduction

### (1.1) Overview
- “These kinds of algorithms are considered [[computationally infeasible]].” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=55&annotation=MVNMGRI2))
	- “Some algorithms are so complicated that they would take too long to run on today’s systems” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=55&annotation=74X6EGZ5))
- To write [[compilers]]
	- Must understand [[hardware environment]] within which the compiler will function
	- Best compilers leverage hardware features ([[pipelining]])
		- for greater speed and efficiency
- Need to understand [[floating-point arithmetic]]
- [[Peripheral equipment]]
	- Need to understand every detail of how a particular computer deals with its [[input-output]] (I-O)
- [[embedded systems]]
	- Usually resource constrained
	- time, space, price trade-offs and I-O architectures essential to career
- [[Benchmarking]]
	- People researching in hardware systems, networks or algorithms find benchmarking techniques crucial
	- Technical managers use benchmarks to buy best system
		- Must keep in mind the ways in which performance benchmarks can be manipulated
- [[Computer organization]]
	- “Addresses issues such as [[control signals]] and [[memory types]], and encompasses all physical aspects of computer systems.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=1389&annotation=ZF9EAPDD))
	- Control signals
		- How computer is controlled
	- [[Signaling methods]]
	- “It helps us to answer the question: How does a computer work?” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=56&annotation=MCET3H8J))
- [[Computer architecture]]
	- “Focuses on the structure and behavior of the computer system and refers to the logical \[and abstract aspects] of system implementation as seen by the programmer. Includes elements such as [[instruction sets]] and [[instruction formats]], [[operation codes]], [[data types]], the number and types of [[registers]], [[addressing modes]], and [[main memory access methods]], as well as various [[input-output mechanisms]].” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=1389&annotation=H5LGL9N3))
	- “The architecture of a system directly affects the logical execution of programs.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=57&annotation=N5UNINHI))
	- “Studying computer architecture helps us to answer the question: How do I design a computer?” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=57&annotation=E2UBT3R4))
- Computer architecture for a given machine is the combination of hardware components plus its [[instruction set architecture]] (ISA)
	- “The agreed-upon interface between all the software that runs on the machine and the hardware that executes it. It specifies the instructions that the computer can perform and the format for each instruction.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=1400&annotation=LV4V4MGE))
		- ISA allows you to talk to machine
- Computer architecture and computer organization are interrelated and interdependent
	- Their distinction is not clear-cut
### (1.2) Computer Systems
#### (1.2.1) The Main Components of a Computer
- “Computer scientists design [[algorithms]] that usually are implemented as [[Program|programs]] written in some computer language, such as Java or C++ .” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=58&annotation=2RKRBI6H))
- Machine level can be thought of as an algorithm implemented as an electronic device
- Modern computers are implementations of algorithms that execute other algorithms. Chain of nested algorithms leads to following principle
	- [[Principle of equivalence of hardware and software]]
		- The principle that anything that can be done with software can also be done with hardware, and anything that can be done with hardware can also be done with software
			- The principle does not address speed with which equivalent tasks are carried out. Hardware implementations are almost always faster
		- Any task done by software can also be done using hardware, and any operation performed directly by hardware can be done using software
		- “any task performed directly in hardware can be done using software, and anything done using hardware can be simulated using software.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=58&annotation=49E4VDGD))
			- Should minimize cost and size while maximizing performance
		- A simple embedded system can give us much better performance than a computer program and vice versa.
- Programs can be written to carry out the functions of special-purpose computers such as embedded systems situated in car or microwave
- [[Computer hardware]]
	- Components necessary to build a computing system
		- A [[processor]] (CPU, or [[Central Processing Unit|central processing unit]]) to interpret and execute programs
		- A [[memory]] to store both data and programs
		- A mechanism for transferring data to and from the outside world
- [[Central Processing Unit|CPU]] is computer's brain
- [[Processor]] consists of
	- [[Arithmetic Logic Unit|Arithmetic logic unit]]
		- To perform computations and make decisions
	- [[Control unit]]
		- to act as a "traffic police officer" directing data to correct locations 
	- [[registers]]
		- Special storage location
		- Holds data that the CPU needs to access very quickly
- When a program is running, [[Central Processing Unit|CPU]] executes instructions found in [[memory]]
	- “[[Memory]] is used to store anything that the computer needs.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=59&annotation=RXXZXWAD))
- Two types of memory
	- [[Long-term memory]]
		- Examples include [[disk drives]] and [[flash drives]] which stores data even when the power is off
		- Long-term memory is pretty much space to store data needed in the future
	- [[Temporary memory]]
		- “Loses data when it loses power, and includes [[registers]] and [[RAM]].” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=59&annotation=PQTXUDYP))
		- Temporary memory is basically the space needed by the processor to store information it's currently working on
- Memory is "hierarchical". There are different levels of memory varying in size and speed.
	- Goal is to give best performance at the lowest cost
	- A [[hard drive]] provides a large, inexpensive place to store long-term data.
	- [[Cache]] is a small, but fast and expensive type of memory that stores data being used most often. 
		- By accessing the [[cache]], the [[Central Processing Unit|CPU]] can read and write data quickly without bogging down the entire system. 
- [[Arithmetic Logic Unit|ALU]] must be connected to the [[registers]] and both must be connected to the [[memory]]. This is done by a special pathway called a [[bus]].
	- Collection of ALU, registers, and bus is called a [[datapath]] (important component of any computer because it is the hardware that is ultimately responsible for running programs)
- [[Input-Output components]], such as keyboards, mice, monitors, printers, web cameras, scanners, graphics tablets, and thumb drives, are all examples of devices that allow us to communicate with the computer.
- How a student exhibits the three components of a computer
	- Student's brain = processor
	- Notes taken = memory
	- pencil = I/O mechanism
- "Keep in mind that your abilities far surpass those of any computer in the world today, or any that can be built in the foreseeable future"
	- #comment Weird that this book was published in 2023 but ChatGPT is definitely something that can solve more problems than we can.
#### (1.2.2) System Components
- Combination of hardware and software is a [[computer system]]
- Most important [[software]] is [[system software]], which includes the [[operating system]]
- “[[System software]] is the collection of programs that allow you to use your computer.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=60&annotation=LPUXQXIE))
	- Integrates closely with hardware on system
	- The interface between you and computer hardware
- Other types of software
	- [[application software]]
		- programs for email or word processing
	- [[Utility software]]
		- Programs designed to clean hard drive or software designed to protect computer while on Internet
	- Both application and utility software use system software to communicate with the hardware
##### (1.2.2.1) Null Pointers: Tips and Hints
- These are tips and helpful hints regarding concepts that can be potential pitfalls
- [[Principle of equivalence of hardware and software]]
	- Important concept when it comes to the design of [[computer architecture]]
- The cost and speed are the determining factors when making design decisions regarding whether to implement something in hardware or software.
	- Frequently a hardware/software design trade-off
- If goal is performance, functionality will typically be moved to hardware as much as possible
- If goal is to achieve compatibility for future, software is used because it is easy to update
- By "equivalent", we mean "functionally equivalent".
- In principle, any function performed by one can be performed by the other. However, at the lowest level, we must have hardware. 
- Interesting detail is the patent vs copyright problem
	- If someone has a hardware device that provides a specific function, the device is eligible for a [[patent]]
		- However, the principle says that this machine can be exactly duplicated in software, yet patent status is often denied for software
		- Therefore, choices made for implementation in hardware vs. software is based on which is more
			- practical, efficient, profitable or provides better performance
#### (1.2.2) System Components (Continued)
- When discussing computer systems, important to consider [[peripheral devices]] connected to main computer hardware as part of that system
- “Keyboards, mice, printers, monitors, scanners, and speakers are examples of peripherals” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=62&annotation=CD8VDC6L))
- “[[tablet]], [[smartphone]], and [[smart-watch]] can be considered peripherals as well, because they can connect easily to your computer and become part of the system.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=62&annotation=QD5KIDGD))
	- Difference is that tablet, phone and watch can run without being connected to anything else
- Even though we often refer a [[computer system]] to simply a computer, technically, the term [[computer]] refers to the hardware only. 
	- It has become quite common to refer to the combination of hardware and software as a computer though
#### (1.2.3) Classification of Computing Devices
- Laptop, tablet, desktop, phone, smartwatch, TV, video game system, car are all different classifications of computers, and thus computer systems
- Car contains an [[embedded computer]]; these are computer systems that perform dedicated tasks specifically designed for the product in which they are enclosed.
	- Systems can be programmable or not depending on application, and their main goals are speed, low power usage, size, and reliability
- Mobile devices have internet capabilities allowing you to download various programs and "apps" to assist you with day-to-day activities
- [[Computer system|computer systems]] are classified into five different categories
	- [[Supercomputers]]
	- [[mainframes]]
	- [[personal computers]]
	- [[mobile devices]]
	- [[embedded systems]]
- Smartwatch could be both a mobile device and an embedded system.
- “Supercomputers are simply very powerful mainframes that are used for compute-intensive applications, such as weather calculations, advanced biological modeling, and genetic research.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=63&annotation=9PF4DI2E))
	- Can operate at speeds of a quadrillion calculations per second and more
- Research to develop computers that can operate at a quintillion operations per second is currently being funded by various countries around the world and has been achieved in 2022.
##### (1.2.3.1) The Final Frontier
- [[exascale computer]] can calculate at least $10^{18}$ 64-bit floating-point operations per second (or [[exaFLOPs]]), which is very similar to what the human brain can do with its roughly 86 billion neurons. 
- “In early 2022, the [[Hewlett-Packard Frontier supercomputer]] was introduced as the fastest supercomputer in the world, beating out the [[Fugaku system]] from Japan that had held that top spot for two years..” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=63&annotation=8RX7WPTB))
	- Consists of 9400 CPUs, 37,000 [[GPUs]]. It is a liquid-cooled computer that has a total core count of 8,720,112, is capable of [[parallel processing]], has 9.2 petabytes of memory and has reached 1.1 exaFLOPs of performance
	- does 1 quintillion calculations a second
		- If each human on Earth did one calculation per second, it would take four years for this "human computer" to do what Frontier can do in one second
- Common Prefixes Associated with Computer Organization and Architecture
	- Larger
		- Kilo (K)
		- Mega (M)
		- Giga (G)
		- Tera (T)
		- Peta (P)
		- Exa (E)
		- Zetta (Z)
		- Yotta (Y)
	- Smaller
		- [[Milli]] (m)
		- [[Micro]] ($\mu$)
		- [[Nano]] (n)
		- [[Pico]] (p)
		- [[Femto]] (f)
		- [[Atto]] (a)
		- [[Zepto]] (z)
		- [[Yocto]] (y)
- Frontier has 74 cabinets, each weighing 8000 pounds. 
- “[[in-system storage layer]] can achieve peak read speeds of 75 terabytes per second and write speeds of 35 terabytes per second, enabling the Frontier supercomputer to achieve more than 15 billion I/O operations per second.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=64&annotation=QZ8CX3KJ))
	- Frontier supercomputer has a huge amount of storage in external file system of 700 petabytes (35 times the amount of data stored in [[Library of Congress]])
- Applications include
	- “quantum circuit simulation, weather forecasting and climate models, fusion power, particle physics and studying the universe, and human brain research.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=64&annotation=QPTUNNFF))
	- “[[Human Brain Project]] has been endeavoring to understand the complexities of the brain, which requires working with significant amounts of data.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=64&annotation=4NNQRJH9))
- New supercomputer will allow researchers to simulate human brain and hopefully gain more insight into how neurons connect with each other to form cognitive pathways.
	- Could result in cures for many [[neurological diseases]]
- “Keeping this computer cool requires 6000 gallons of water, circulated using four 350 horsepower pumps, to be pumped through the system every minute!” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=64&annotation=CYYK3TWY))
- “computer has taken first place on the [[Green500]] list as the most power-efficient supercomputer architecture in the world.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=64&annotation=7LURK3AC))
- “U.S. Department of Energy has installed a Frontier supercomputer at [[Oak Ridge National Laboratory]] in Tennessee, with full science access beginning in 2023.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=65&annotation=LVNFXIWC))
#### (1.2.3) Classification of Computing Devices (Continued)
- [[Mainframe computers]] used by companies for specific applications such as data processing (such as systems used by airlines for ticket reservations) and financial transactions (such as those at banks)
- Desktop and laptop computers considered [[personal computers]]
- Laptops and tablets popular, but desktops yield better performance for less money and more "worker-friendly" (better keyboard, larger screen, etc.)
- Choices of desktops
	- Full-sized computer
	- Compact computer
	- All-in-one
	- Gaming computer
- [[Mobile devices]] include any handheld portable computing device
	- Examples
		- [[smartphone]]
		- [[e-reader]]
		- [[tablet]]
	- Uses include photos, phone calls, sending text messages, accessing calendars, surfing web-pages
### (1.3) An Example System: Wading Through the Jargon
- ![[Screenshot 2024-10-21 at 2.06.41 AM.png]]
- Provided a “facsimile computer advertisement” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=66&annotation=TF3BPYQ5))
- Phrases
	- 32GB DDR4 SDRAM
	- PCIe sound card
	- 128KB L1 cache
- “measurement terminology you will encounter throughout your study of computers.” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=67&annotation=DHKRMMGG))
- $2^{10}$ is close to $10^3$, so kilo is used to refer to them both.
- “Power-of-10 prefixes are ordinarily used for power, electrical voltage, frequency (such as computer clock speeds), and multiples of bits (such as data speeds in number of bits per second).” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=68&annotation=DXQPIKIV))
- “If your antiquated modem transmits at 28.8kb/s, then it transmits 28,800 bits per second (or ).” ([pdf](zotero://open-pdf/library/items/ZWLVXRKV?page=68&annotation=YDTNZWV6))
### (1.4) Standards Organizations
### (1.5) Historical Development
#### (1.5.1) Generation Zero: Mechanical Calculating Machines (1642-1945)
#### (1.5.2) The First Generation: Vacuum Tube Computers (1945-1953)
#### (1.5.3) The Second Generation: Transistorized Computers (1954-1965)
#### (1.5.4) The Third Generation: Integrated Circuit Computers (1965-1980)
#### (1.5.5) The Fourth Generation: VLSI Computers (1980-????)
#### (1.5.6) Moore's Law
### (1.6) The Computer Level Hierarchy
### (1.7) Cloud Computing: Computing as a Service
### (1.8) The Fragility of the Internet
### (1.9) The von Neumann Model
### (1.10) Non-von Neumann Models
### (1.11) Parallel Processors and Parallel Computing
### (1.12) Chapter Summary
### (1.13) Further Reading
### (1.14) References
### (1.15) Review of Essential Terms and Concepts
### (1.16) Exercises
## (2) Chapter 2: Data Representation in Computer Systems
### (2.1) Introduction
### (2.2) Positional Numbering Systems
### (2.3) Converting Between Bases
#### (2.3.1) Converting Unsigned Whole Numbers
#### (2.3.2) Converting Fractions
#### (2.3.3) Converting Between Power-of-2 Radices
### (2.4) Signed Integer Representation
#### (2.4.1) Signed Magnitude
#### (2.4.2) Complement Systems
#### (2.4.3) Excess-M Representation for Signed Numbers
#### (2.4.4) Unsigned Versus Signed Numbers
#### (2.4.5) Computers, Arithmetic, and Booth's Algorithm
#### (2.4.6) Carry Versus Overflow
#### (2.4.7) Binary Multiplication and Division Using Shifting
### (2.5) Floating-Point Representation
#### (2.5.1) A Simple Model
#### (2.5.2) Floating-Point Arithmetic
#### (2.5.3) Floating-Point Errors
#### (2.5.4) The IEEE-754 Floating-Point Standard
#### (2.5.5) Range, Precision, and Accuracy
#### (2.5.6) Additional Problems with Floating-Point Numbers
### (2.6) Character Codes
#### (2.6.1) Binary-Coded Decimal
#### (2.6.2) EBCDIC
#### (2.6.3) ASCII
#### (2.6.4) Unicode
### (2.7) Error Detection and Correction
#### (2.7.1) Cyclic Redundancy Check
#### (2.7.2) Hamming Codes
### (2.8) Chapter Summary
### (2.9) Further Reading
### (2.10) References
### (2.11) Review of Essential Terms and Concepts
### (2.12) Exercises
## (3) Chapter 3 Boolean Algebra and Digital Logic
### (3.1) Introduction
### (3.2) Boolean Algebra
#### (3.2.1) Boolean Expressions
#### (3.2.2) Boolean Identities
#### (3.2.3) Simplification of Boolean Expressions
#### (2.2.4) Complements
#### (2.2.5) Representing Boolean Functions
### (3.3) Logic Gates
#### (3.3.1) Symbols for Logic Gates
#### (3.3.2) Universal Gates
#### (3.3.3) Multiple Input Gates
### (3.4) Karnaugh Maps
#### (3.4.1) Introduction
#### (3.4.2) Description of Kmaps and Terminology
#### (3.4.3) Kmap Simplification for Two Variables
#### (3.4.4) Kmap Simplification for Three Variables
#### (3.4.5) Kmap Simplification for Four Variables
#### (3.4.6) Don't Care Conditions
#### (3.4.7) Summary
### (3.5) Digital Components
#### (3.5.1) Digital Circuits and Their Relationship to Boolean Algebra
#### (3.5.2) Integrated Circuits
#### (3.5.3) Putting it All Together: From Problem Description to Circuit
### (3.6) Combinational Circuits
#### (3.6.1) Basic Concepts
#### (3.6.2) Examples of Typical Combinational Circuits
### (3.7) Sequential Circuits
#### (3.7.1) Basic Concepts
#### (3.7.2) Clocks
#### (3.7.3) Flip-Flops
#### (3.7.4) Finite-State Machines
#### (3.7.5) Examples of Sequential Circuits
#### (3.7.6) An Application of Sequential Logic: Convolutional Coding and Viterbi Detection
### (3.8) Designing Circuits
### (3.9) Chapter Summary
### (3.10) Further Reading
### (3.11) References
### (3.12) Review of Essential Terms and Concepts
### (3.13) Exercises
## (4) Chapter 4 Marie: An Introduction to a Simple Computer
### (4.1) Introduction
### (4.2) CPU Basics and Organization
#### (4.2.1) The Registers
#### (4.2.2) The ALU
#### (4.2.3) The Control Unit
### (4.3) The Bus
### (4.4) Clocks
### (4.5) The Input/Output Subsystem
### (4.6) Memory Organization and Addressing
### (4.7) MARIE
#### (4.7.1) The Architecture
#### (4.7.2) Registers and Buses
#### (4.7.3) Instruction Set Architecture
#### (4.7.4) Register Transfer Notation
### (4.8) Instruction Processing
#### (4.8.1) The Fetch-Decode-Execute Cycle
#### (4.8.2) Interrupts and the Instruction Cycle
#### (4.8.3) MARIE's I/O
### (4.9) A Simple Program
### (4.10) A Discussion on Assemblers
#### (4.10.1) What Do Assemblers Do?
#### (4.10.2) Why Use Assembly Language?
### (4.11) Extending Our Instruction Set
### (4.12) A Discussion on Decoding: Hardwired Versus Microprogrammed Control
#### (4.12.1) Machine Control
#### (4.12.2) Hardwired Control
#### (4.12.3) Microprogrammed Control
### (4.13) Real-World Examples of Computer Architectures
#### (4.13.1) Intel Architectures
#### (4.13.2) MIPS Architectures
### (4.14) Chapter Summary
### (4.15) Further Reading
### (4.16) References
### (4.17) Review of Essential Terms and Concepts
### (4.18) Exercises
### (4.19) True or False

## (5) Chapter 5: A Closer Look at Instruction Set Architectures
### (5.1) Introduction
### (5.2) Instruction Formats
#### (5.2.1) Design Decisions for Instruction Sets
#### (5.2.2) Little Versus Big Endian
#### (5.2.3) Internal Storage in the CPU: Stacks Versus Registers
#### (5.2.4) Number of Operands and Instruction Length
#### (5.2.5) Expanding Opcodes
### (5.3) Instruction Types
#### (5.3.1) Data Movement
#### (5.3.2) Arithmetic Operations
#### (5.3.3) Boolean Logic Instructions
#### (5.3.4) Bit Manipulation Instructions
#### (5.3.5) Input/Output Instructions
#### (5.3.6) Instructions for Transfer of Control
#### (5.3.7) Special-Purpose Instructions
#### (5.3.8) Instruction Set Orthogonality
### (5.4) Addressing
#### (5.4.1) Data Types
#### (5.4.2) Address Modes
### (5.5) Instruction Pipelining
### (5.6) Real-World Examples of ISAs
#### (5.6.1) Intel
#### (5.6.2) MIPS
#### (5.6.3) Java Virtual Machine
#### (5.6.4) ARM
### (5.7) Chapter Summary
### (5.8) Further Reading
### (5.9) References
### (5.10) Review of Essential Terms and Concepts
### (5.11) Exercises
### (5.12) True or False
## (6) Chapter 6 Memory
### (6.1) Introduction
### (6.2) Types of Memory
### (6.3) The Memory Hierarchy
#### (6.3.1) Locality of Reference
### (6.4) Cache Memory
#### (6.4.1) Cache Mapping Schemes
#### (6.4.2) Replacement Policies
#### (6.4.3) Effective Access Time and Hit Ratio
#### (6.4.4) When Does Caching Break Down?
#### (6.4.5) Cache Write Policies
#### (6.4.6) Instruction and Data Caches
#### (6.4.7) Levels of Cache
### (6.5) Virtual Memory
#### (6.5.1) Paging
#### (6.5.2) Effective Access Time Using Paging
#### (6.5.3) Putting It All Together: Using Cache, TLBs, and Paging
#### (6.5.4) Advantages and Disadvantages of Paging and Virtual Memory
#### (6.5.5) Segmentation
#### (6.5.6) Paging Combined with Segmentation
### (6.6) Real-World Examples of Memory Management
### (6.7) Chapter Summary
### (6.8) Further Reading
### (6.9) References
### (6.10) Review of Essential Terms and Concepts
### (6.11) Exercises
## (7) Chapter 7: Input/Output Systems
### (7.1) Introduction
### (7.2) I/O and Performance
### (7.3) Amdahl's Law
### (7.4) I/O Architectures
#### (7.4.1) I/O Control Methods
#### (7.4.2) Character I/O Versus Block I/O
#### (7.4.3) I/O Bus Operation
#### (7.4.4) I/O Buses and Interfaces
### (7.5) Data Transmission Modes
#### (7.5.1) Parallel Data Transmission
#### (7.5.2) Serial Data Transmission
### (7.6) Disk Technology
#### (7.6.1) Hard Disk Drives
#### (7.6.2) Solid-State Drives
### (7.7) Optical Disks
#### (7.7.1) CD-ROM
#### (7.7.2) DVD
#### (7.7.3) Blue-Violet Laser Discs
### (7.8) RAID
#### (7.8.1) RAID Level 0
#### (7.8.2) RAID Level 1
#### (7.8.3) RAID Level 2
#### (7.8.4) RAID Level 3
#### (7.8.5) RAID Level 4
#### (7.8.6) RAID Level 5
#### (7.8.7) RAID Level 6
#### (7.8.8) RAID DP
#### (7.8.9) Hybrid RAID Systems
### (7.9) The Future of Data Storage
### (7.10) Chapter Summary
### (7.11) Further Reading
### (7.12) References
### (7.13) Review of Essential Terms and Concepts
### (7.14) Exercises
## (8) Chapter 8: Alternative Architectures
### (8.1) Introduction
### (8.2) RISC Machines
### (8.3) Flynn's Taxonomy
### (8.4) Parallel and Multiprocessor Architectures
#### (8.4.1) Superscalar and VLIW
#### (8.4.2) Vector Processors
#### (8.4.3) Interconnection Networks
#### (8.4.4) Shared Memory Multiprocessors
#### (8.4.5) Distributed Computing
### (8.5) Alternative Parallel Processing Approaches
#### (8.5.1) Dataflow Computing
#### (8.5.2) Neural Networks
#### (8.5.3) Systolic Arrays
### (8.6) Quantum Computing
### (8.7) Chapter Summary
### (8.8) Further Reading
### (8.9) References
### (8.10) Review of Essential Terms and Concepts
### (8.11) Exercises
## (9) Chapter 9: Topics in Embedded Systems
### (9.1) Introduction
### (9.2) An Overview of Embedded Hardware
#### (9.2.1) Off-the-Shelf Embedded System Hardware
#### (9.2.2) Configurable Hardware
#### (9.2.3) Custom-Designed Embedded Hardware
### (9.3) An Overview of Embedded Software
#### (9.3.1) Embedded Systems Memory Organization
#### (9.3.2) Embedded Operating Systems
#### (9.3.3) Embedded Systems Software Development
### (9.4) Chapter Summary
### (9.5) Further Reading
### (9.6) References
### (9.7) Review of Essential Terms and Concepts
### (9.8) Exercises
## (10) Chapter 10: Performance Measurement and Analysis
### (10.1) Introduction
### (10.2) Computer Performance Equations
### (10.3) Mathematical Preliminaries
#### (10.3.1) What the Means Mean
#### (10.3.2) The Statistics and Semantics
### (10.4) Benchmarking
#### (10.4.1) Clock Rate, MIPS, and FLOPS
#### (10.4.2) Synthetic Benchmarks: Whetstone, Linpack, and Dhrystone
#### (10.4.3) Standard Performance Evaluation Corporation Benchmarks
#### (10.4.4) Transaction Processing Performance Council Benchmarks
#### (10.4.5) System Simulation
### (10.5) CPU Performance Optimization
#### (10.5.1) Branch Optimization
#### (10.5.2) Use of Good Algorithms and Simple Code
### (10.6) Disk Performance
#### (10.6.1) Understanding the Problem
#### (10.6.2) Physical Considerations
#### (10.6.3) Logical Considerations
### (10.7) Chapter Summary
### (10.8) Further Reading
### (10.9) References
### (10.10) Review of Essential Terms and Concepts
### (10.11) Exercises
## (11) Chapter 11: System Software (Available in the eBook)
### (11.1) Introduction
### (11.2) Operating Systems
#### (11.2.1) Operating Systems History
#### (11.2.2) Operating System Design
#### (11.2.3) Operating System Services
### (11.3) Protected Environments
#### (11.3.1) Virtual Machines
#### (11.3.2) Subsystems and Partitions
#### (11.3.3) Protected Environments and the Evolution of Systems Architectures
### (11.4) Programming Tools
#### (11.4.1) Assemblers and Assembly
#### (11.4.2) Link Editors
#### (11.4.3) Dynamic Link Libraries
#### (11.4.4) Compilers
#### (11.4.5) Interpreters
### (11.5) Java: All of the Above
### (11.6) Chapter Summary
### (11.7) Further Reading
### (11.8) References
### (11.9) Review of Essential Terms and Concepts
### (11.10) Exercises
## (12) Chapter 12: Network Organization and Architecture (Available in the eBook)
### (12.1) Introduction
### (12.2) Early Business Computer Networks
### (12.3) Early Academic and Scientific Networks: The Roots and Architecture of the Internet
### (12.4) Network Protocols: I: ISO/OSI Protocol Unification
#### (12.4.1) A Parable
#### (12.4.2) The OSI Reference Model
### (12.5) Network Protocols II: TCP/IP Network Architecture
#### (12.5.1) The IP Layer for Version 4
#### (12.5.2) The Trouble with IP Version 4
#### (12.5.3) Transmission Control Protocol
#### (12.5.4) The TCP Protocol at Work
#### (12.5.5) IP Version 6
### (12.6) Network Organization
#### (12.6.1) Physical Transmission MEdia
#### (12.6.2) Interface Cards
#### (12.6.3) Repeaters
#### (12.6.4) Hubs
#### (12.6.5) Switches
#### (12.6.6) Bridges and Gateways
#### (12.6.7) Routers and Routing
### (12.7) Chapter Summary
### (12.8) Further Reading
### (12.9) References
### (12.10) Review of Essential Terms and Concepts
### (12.11) Exercises
## (13) Chapter 13: Selected Storage Systems and Interfaces (Available in the eBook)
### (13.1) Introduction
### (13.2) SCSI Architecture
#### (13.2.1) "Classic" Parallel SCSI
#### (13.2.2) The SCSI Architecture Model-3
### (13.3) Internet SCSI
### (13.4) Storage Area Networks
### (13.5) Other I/O Connections
#### (13.5.1) Parallel Buses: XT to ATA
#### (13.5.2) Serial ATA and Serial Attached SCSI
#### (13.5.3) Peripheral Component Interconnect
#### (13.5.4) A Serial Interface: USB
### (13.6) Cloud Storage
### (13.7) Chapter Summary
### (13.8) Further Reading
### (13.9) References
### (13.10) Review of Essential Terms and Concepts
### (13.11) Exercises
## (A) Appendix: A Data Structure and the Computer (Available in the eBook)
### (A.1) Introduction
### (A.2) Fundamental Structures
#### (A.2.1) Arrays
#### (A.2.2) Queues and Linked Lists
#### (A.2.3) Stacks
### (A.3) Trees
### (A.4) Network Graphs
### (A.5) Summary
### (A.6) Further Reading
### (A.7) References
### (A.8) Exercises
## Glossary
## Answers and Hints for Selected Exercises
## Index
