## Synthesis
- 
## Source [^1]
- A method of estimating parameters in a model by minimizing the sum of squares of differences between observed and theoretical values of a variable. If$$y_{i}, i=1, \ldots, n$$is a sample of $n$ observations, and $\mu_{i}$ is a set of theoretical values corresponding to a set of unknown parameters, $\theta$, and a set of known associated observations, $x_{i}$, then the criterion to be minimized with respect to variations in $\theta$ is the sum of squares,$$\Sigma\left(y_{i}-\mu_{i}\right)^{2}$$The values of $\theta$ at which the minimum occurs are known as least squares estimates. The method of weighted least squares is used when each observation is associated with a weight, $w_{i}$ (see MEASURES OF LOCATION), and the criterion to be minimized is$$\Sigma w_{i}\left(y_{i}-\mu_{i}\right)^{2}$$See also LIKELIHOOD, REGRESSION ANALYSIS.
## References

[^1]: [[Home Page - A Dictionary of Computer Science 7th Edition by Oxford Reference]]