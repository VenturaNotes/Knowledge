## Synthesis
- 
## Source [^1]
- An early type of single-layer neural network. An input array is covered by a set of feature detectors whose outputs are weighted, summed, and then thresholded to give a single binary output. A perceptron learning algorithm can be used to adjust the weights during training on examples from pattern classes so that new inputs may be correctly classified. Mathematical analyses of perceptrons in the 1970s exposed severe limitations and halted research on neural networks. Now, however, perceptrons have been superseded by multilayer neural networks that do not suffer from those limitations.
## Source[^2]
- $n$. In artificial intelligence, a pattern-recognition machine into which distinctive features (1) of a target pattern are input with weights reflecting their relative importance. The machine is programmed to signal a decision that the target pattern is present whenever the sum of the weights of features in a test pattern presented to it exceeds a critical level, and a process of learning takes place as the weights of features present in a test pattern are increased after every hit and decreased after every false negative. The first version was introduced in an article in the journal Psychological Review in 1958 by the US psychologist Frank Rosenblatt (1928-71) and is an early example of a neural network. See also COMPUTER VISION, PATTERN RECOGNITION. \[From Latin percipere, perceptum to perceive, from per through + capere, ceptum to take + Greek -tron denoting an instrument, from arotron a plough]
## References

[^1]: [[(Home Page) A Dictionary of Computer Science 7th Edition by Oxford Reference]]
[^2]: [[(Home Page) A Dictionary of Psychology 4th Edition by Oxford Reference]]