## Synthesis
- 
## Source [^1]
- (neural net) A form of computation inspired by the structure and function of the brain. One version of this is as follows. The topology is a weighted directed graph. Nodes in the graph can be on or off. Time is discrete. At each time instant all the on nodes send an impulse along their outgoing arcs to their neighbor nodes. All nodes sum their incoming impulses, weighted according to the arc. All the nodes at which this sum exceeds a threshold turn on at the next time instant; all the others turn off. Computation proceeds by setting some input nodes, waiting for the network to reach a steady state, and then reading some output nodes. Nodes can be trained, using examples, to recognize certain patterns, for instance to classify objects by features. See also BACK PROPAGATION, CONNECTIONISM, PERCEPTION.
## Source[^2]
- $n$. A system of interconnected neurons, as in the brain or nervous system, or (especially in cognitive science and artificial intelligence) an analogous system of interconnected neurochips constituting a neurocomputer designed to simulate the human brain, or a design for such a system. According to neural network theorists, mental experiences arise from the interaction of many interconnected computing units (or neurons), each in a specified state of activation (or firing rate), and each having the capacity to affect others by either excitatory or inhibitory connections (or synapses), the entire system being activated by a stimulus that affects a subset of the units, activation then propagating through the network until an equilibrium state of minimum energy is attained. The concept of a neural network was foreshadowed by the US psychologist William James (1842-1910) in his Principles of Psychology (1890, volume 2, pp. 563-6), and the first neural logic circuit based on a binary code was proposed in 1938 by the Russian-born US mathematical biologist Nicolas Rashevsky (1899-1972). The first detailed neural network was developed in 1943 by the US neurolophysiologist Warren S(turgis) McCulloch (1898-1968) and the self-taught US logician Walter Pitts (1923-69), but that early version lacked the ability to learn, which was introduced in 1948 in an article on 'Intelligent Machinery' by the English mathematician Alan Mathison Turing (1912-54) and independently in 1949 by the Canadian psychologist Donald O(lding) Hebb (1904-85). The concept of the neural network became popular only after the publication in 1981 of a connectionist model of human memory developed by the US cognitive scientist James L(loyd) McClelland (born 1948). Still more advanced neural networks often make use of fuzzy logic. Also called an artificial neural network (drawing attention to the fact that it consists of artificial rather than natural structures) or a neural net. See also CONNECTIONISM (1), NETWORK MODEL, PARALLEL DISTRIBUTED PROCESSING, PERCEPTRON, SPREADING ACTIVATION. ANN, CNN, or PDP-CNN abbrev.
## References

[^1]: [[(Home Page) A Dictionary of Computer Science 7th Edition by Oxford Reference]]
[^2]: [[(Home Page) A Dictionary of Psychology 4th Edition by Oxford Reference]]