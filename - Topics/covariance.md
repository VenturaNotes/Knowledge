## Synthesis
- 
## Source [^1]
- A measure of the joint variation of two random variables, analogous to variance (see MEASURES OF VARIATION). If the variables are $x$ and $y$ then the covariance of $x$ and $y$ is $$\sum(x_i-\overline x)(y_i - \overline y)$$
- The analysis of covariance is an extension of the analysis of variance in which the variables to be tested are adjusted to take account of assumed linear relationships with other variables. See also CORRELATION

## Source[^2]
- A measure of the degree of linear relationship between two random variables, say, $X$ and $Y$, defined by$$\operatorname{Cov}(X, Y)=E[(X-E[X])(Y-E[Y])]$$Positive (negative) covariance means that large values of $X$ are likely to be observed with large (small) values of $Y$.
## Source[^3]
- $n$. In descriptive statistics, an index of the degree of association between two variables, defined as the expected (average) value of the product of the deviations of the two variables from their means, calculated in samples by transforming the scores in both groups to deviations from their respective group means, multiplying pairs of scores from each group together, and calculating the mean of these products. The covariance of variables $X$ and $Y$ is written $\operatorname{Cov}(X, Y)$. See also product-moment CORRELATION COEFFICIENT. Compare VARIANCE.
## References

[^1]: [[(Home Page) A Dictionary of Computer Science 7th Edition by Oxford Reference]]
[^2]: [[(Home Page) A Dictionary of Economics 5th Edition by Oxford Reference]]
[^3]: [[(Home Page) A Dictionary of Psychology 4th Edition by Oxford Reference]]