## Synthesis
- 
## Source [^1]
- It is a set of all characters, numbers, currencies, and symbols in the world. It goes beyond the ASCII standard for character representation and is necessary to support different languages

## Source[^2]
- Unicode A standard for storing, manipulating, and displaying textual data. The Unicode character set currently (2014) allows for 1,114,112 code points, of which over 110000 have been assigned characters. Its contents are the same as the Universal Character Set (see UCS), with which its revisions are coordinated. Unicode also specifies various normative classifications for each character (upper-case letter, lower-case letter, decimal number, etc.), rules (e.g. how to decompose a composite character, such as an accented letter, into its component characters), and algorithms (e.g. for collation) as well as reference charts showing the visual form of each character. For backward compatibility the characters assigned to codepoints 0 to 127 are the same as ASCII character set; and those assigned to 0 to 255 Unicode are the same as ISO-8859-1, a superset of Latin alphabet no. 1.
- http://www.unicode.org/ (redirected [here](https://home.unicode.org/))
	- The Unicode Consortium home page
## Source[^3]
- In computing, a coding standard in which one or more bytes are used to represent each character. Unicode allows unique definition of symbols, foreign alphabets, Chinese ideographs, etc. To date over 110,000 have been defined.
## References

[^1]: https://lokalise.com/blog/beginners-guide-to-python-i18n/
[^2]: [[Home Page - A Dictionary of Computer Science 7th Edition by Oxford Reference]]
[^3]: [[Home Page - A Dictionary of Business and Management 6th Edition by Oxford Reference]]