## Synthesis
- 
## Source [^1]
- Numerical methods that are based on or utilize the idea of iteration. Such methods are widely used in the solution of many different types of problem, ranging from linear and nonlinear optimization to discretized systems of partial differential equations. Starting from an initial estimate $x_{0}$ of the solution $x^{*}$, the methods generate a sequence of approximations $x_{0}, x_{1}, x_{2}, \ldots$. The main objectives are to design methods that will converge from poor initial estimates and also converge rapidly in the vicinity of $x^{*}$. Different ideas may be employed in these two phases. Newton's method, together with its variants, is of fundamental importance for all types of nonlinear equations.
- For the linear system $\mathrm{A} x=b$ where A is large and perhaps sparse (see SPARSE MATRIX), or has some other special structure, an important class of iterative methods is obtained by 'splitting' A into the form $\mathrm{A}=\mathrm{M}-\mathrm{N}$. The splitting is such that systems of the form $\mathrm{Mz}=$ $d$ are 'easy' to solve, e.g. M could be lower triangular. The iteration then takes the form$$\mathrm{M} x_{k+1}=\mathrm{N} x_{k}+d, k=0,1,2, \ldots$$where $x_{0}$ is an approximation to the solution. Convergence for any $x_{0}$ is guaranteed if all the eigenvalues (see EIGENVALUE PROBLEMS) of $\mathrm{M}^{-1} \mathrm{~N}$ have modulus less than one. The objective is to choose splittings for which each step is efficient and the convergence is rapid.
- In partial differential equations, linear systems arise for which the method of successive over-relaxation is particularly suitable. This is given by$$(\mathrm{D}+\omega \mathrm{L}) x_{k+1}=\{(1-\omega) \mathrm{D}-\omega \mathrm{U}\} x_{k}+\omega b$$where $\mathrm{A}=\mathrm{D}+\mathrm{L}+\mathrm{U}, \mathrm{D}$ consists of the diagonal elements of A , and $\mathrm{L}, \mathrm{U}$ are respectively the strictly lower and upper triangular parts. The scalar $\omega$ is a free parameter and is chosen to try to maximize the rate of convergence. For special problems in partial differential equations, optimal values of $\omega$ can be computed. More recently the successive over-relaxation method is an important technique in the multigrid method.
## References

[^1]: [[Home Page - A Dictionary of Computer Science 7th Edition by Oxford Reference]]